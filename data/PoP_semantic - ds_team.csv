Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
365,"James Max Kanter, K. Veeramachaneni","Deep feature synthesis: Towards automating data science endeavors",2015,"2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","","https://www.semanticscholar.org/paper/97a3726b3f9395c8919c6271540d87d1c44e10ac","",1,"2025-02-06 14:32:15","JournalArticle","10.1109/DSAA.2015.7344858","","",,,1,10,365,36.50,183,2,10,"In this paper, we develop the Data Science Machine, which is able to derive predictive models from raw data automatically. To achieve this automation, we first propose and develop the Deep Feature Synthesis algorithm for automatically generating features for relational datasets. The algorithm follows relationships in the data to a base field, and then sequentially applies mathematical functions along that path to create the final feature. Second, we implement a generalizable machine learning pipeline and tune it using a novel Gaussian Copula process based approach. We entered the Data Science Machine in 3 data science competitions that featured 906 other data science teams. Our approach beats 615 teams in these data science competitions. In 2 of the 3 competitions we beat a majority of competitors, and in the third, we achieved 94% of the best competitor's score. In the best case, with an ongoing competition, we beat 85.6% of the teams and achieved 95.7% of the top submissions score.","http://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/uploads/Site/DSAA_DSM_2015.pdf",""
234,"Amy X. Zhang, Michael J. Muller, Dakuo Wang","How do Data Science Workers Collaborate? Roles, Workflows, and Tools",2020,"Proceedings of the ACM on Human-Computer Interaction","","https://www.semanticscholar.org/paper/ab8ba0f2d290a8e56eb61e10027d0b2e57d2d544","",2,"2025-02-06 14:32:15","JournalArticle","10.1145/3392826","","",4,,1,23,234,46.80,78,3,5,"Today, the prominence of data science within organizations has given rise to teams of data science workers collaborating on extracting insights from data, as opposed to individual data scientists working alone. However, we still lack a deep understanding of how data science workers collaborate in practice. In this work, we conducted an online survey with 183 participants who work in various aspects of data science. We focused on their reported interactions with each other (e.g., managers with engineers) and with different tools (e.g., Jupyter Notebook). We found that data science teams are extremely collaborative and work with a variety of stakeholders and tools during the six common steps of a data science workflow (e.g., clean data and train model). We also found that the collaborative practices workers employ, such as documentation, vary according to the kinds of tools they use. Based on these findings, we discuss design implications for supporting data science team collaborations and future research directions.","https://arxiv.org/pdf/2001.06684",""
192,"Samir Passi, Solon Barocas","Problem Formulation and Fairness",2019,"Proceedings of the Conference on Fairness, Accountability, and Transparency","","https://www.semanticscholar.org/paper/332487f33e3decaa1b613dfd4afdc68c92160de0","",3,"2025-02-06 14:32:15","Book","10.1145/3287560.3287567","","",,,,,192,32.00,96,2,6,"Formulating data science problems is an uncertain and difficult process. It requires various forms of discretionary work to translate high-level objectives or strategic goals into tractable problems, necessitating, among other things, the identification of appropriate target variables and proxies. While these choices are rarely self-evident, normative assessments of data science projects often take them for granted, even though different translations can raise profoundly different ethical concerns. Whether we consider a data science project fair often has as much to do with the formulation of the problem as any property of the resulting model. Building on six months of ethnographic fieldwork with a corporate data science team---and channeling ideas from sociology and history of science, critical data studies, and early writing on knowledge discovery in databases---we describe the complex set of actors and activities involved in problem formulation. Our research demonstrates that the specification and operationalization of the problem are always negotiated and elastic, and rarely worked out with explicit normative considerations in mind. In so doing, we show that careful accounts of everyday data science work can help us better understand how and why data science problems are posed in certain ways---and why specific formulations prevail in practice, even in the face of what might seem like normatively preferable alternatives. We conclude by discussing the implications of our findings, arguing that effective normative interventions will require attending to the practical work of problem formulation.","https://dl.acm.org/doi/pdf/10.1145/3287560.3287567",""
100,"Samir Passi, S. Jackson","Trust in Data Science",2018,"Proceedings of the ACM on Human-Computer Interaction","","https://www.semanticscholar.org/paper/140a6476f7b8dde9e7bbcd199d248fc629721faa","",4,"2025-02-06 14:32:15","JournalArticle","10.1145/3274405","","",2,,1,28,100,14.29,50,2,7,"The trustworthiness of data science systems in applied and real-world settings emerges from the resolution of specific tensions through situated, pragmatic, and ongoing forms of work. Drawing on research in CSCW, critical data studies, and history and sociology of science, and six months of immersive ethnographic fieldwork with a corporate data science team, we describe four common tensions in applied data science work: (un)equivocal numbers, (counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We show how organizational actors establish and re-negotiate trust under messy and uncertain analytic conditions through practices of skepticism, assessment, and credibility. Highlighting the collaborative and heterogeneous nature of real-world data science, we show how the management of trust in applied corporate data science settings depends not only on pre-processing and quantification, but also on negotiation and translation. We conclude by discussing the implications of our findings for data science research and practice, both within and beyond CSCW.","https://dl.acm.org/doi/pdf/10.1145/3274405",""
69,"H. Harris, Sean P. Murphy, Marck Vaisman","Analyzing the Analyzers: An Introspective Survey of Data Scientists and Their Work",2013,"","","https://www.semanticscholar.org/paper/5ad8d42e22d71d35fdcd85aeb6385aed740a526c","",5,"2025-02-06 14:32:15","Review","","","",,,,,69,5.75,23,3,12,"Despite the excitement around ""data science,"" ""big data,"" and ""analytics,"" the ambiguity of these terms has led to poor communication between data scientists and organizations seeking their help. In this report, authors Harlan Harris, Sean Murphy, and Marck Vaisman examine their survey of several hundred data science practitioners in mid-2012, when they asked respondents how they viewed their skills, careers, and experiences with prospective employers. The results are striking. Based on the survey data, the authors found that data scientists today can be clustered into four subgroups, each with a different mix of skillsets. Their purpose is to identify a new, more precise vocabulary for data science roles, teams, and career paths. This report describes:Four data scientist clusters: Data Businesspeople, Data Creatives, Data Developers, and Data Researchers Cases in miscommunication between data scientists and organizations looking to hire Why ""T-shaped"" data scientists have an advantage in breadth and depth of skills How organizations can apply the survey results to identify, train, integrate, team up, and promote data scientists","",""
67,"Emc Education Services","Data Science and Big Data Analytics: Discovering, Analyzing, Visualizing and Presenting Data",2015,"","","https://www.semanticscholar.org/paper/061c3291d817076dbb3e5a41c51f99800a390e94","",6,"2025-02-06 14:32:15","","","","",,,,,67,6.70,67,1,10,"Data Science and Big Data Analytics: Discovering, Analyzing, Visualizing and Presenting Data By EMC Education Services Data Science and Big Data Analytics is about harnessing the power of data for new insights. The book covers the breadth of activities and methods and tools that Data Scientists use. The content focuses on concepts, principles and practical applications that are applicable to any industry and technology environment, and the learning is supported and explained with examples that you can replicate using open-source software. This book will help you: Become a contributor on a data science team ●","",""
62,"Samir Passi, Phoebe Sengers","Making data science systems work",2020,"Big Data & Society","","https://www.semanticscholar.org/paper/648ba966b63975c6859e1948ae3ddc30053884e4","",7,"2025-02-06 14:32:15","JournalArticle","10.1177/2053951720939605","2053-9517","",7,,,,62,12.40,31,2,5,"How are data science systems made to work? It may seem that whether a system works is a function of its technical design, but it is also accomplished through ongoing forms of discretionary work by many actors. Based on six months of ethnographic fieldwork with a corporate data science team, we describe how actors involved in a corporate project negotiated what work the system should do, how it should work, and how to assess whether it works. These negotiations laid the foundation for how, why, and to what extent the system ultimately worked. We describe three main findings. First, how already-existing technologies are essential reference points to determine how and whether systems work. Second, how the situated resolution of development challenges continually reshapes the understanding of how and whether systems work. Third, how business goals, and especially their negotiated balance with data science imperatives, affect a system’s working. We conclude with takeaways for critical data studies, orienting researchers to focus on the organizational and cultural aspects of data science, the third-party platforms underlying data science systems, and ways to engage with practitioners’ imagination of how systems can and should work.","https://journals.sagepub.com/doi/pdf/10.1177/2053951720939605",""
41,"Silu Huang, Liqi Xu, Jialin Liu, Aaron J. Elmore, Aditya G. Parameswaran","OrpheusDB: Bolt-on Versioning for Relational Databases",2017,"ArXiv","","https://www.semanticscholar.org/paper/b1c2525b4a76776585a68add2f19a45f8a0ca23d","",8,"2025-02-06 14:32:15","JournalArticle","10.14778/3115404.3115417","2150-8097","",,,,,41,5.13,8,5,8,"Data science teams often collaboratively analyze datasets, generating dataset versions at each stage of iterative exploration and analysis. There is a pressing need for a system that can support dataset versioning, enabling such teams to efficiently store, track, and query across dataset versions. We introduce OrpheusDB, a dataset version control system that ""bolts on"" versioning capabilities to a traditional relational database system, thereby gaining the analytics capabilities of the database ""for free"". We develop and evaluate multiple data models for representing versioned data, as well as a light-weight partitioning scheme, LyreSplit, to further optimize the models for reduced query latencies. With LyreSplit, OrpheusDB is on average 103× faster in finding effective (and better) partitionings than competing approaches, while also reducing the latency of version retrieval by up to 20× relative to schemes without partitioning. LyreSplit can be applied in an online fashion as new versions are added, alongside an intelligent migration scheme that reduces migration time by 10× on average.","",""
41,"J. Saltz, Ivan Shamshurin, Colin Connors","Predicting data science sociotechnical execution challenges by categorizing data science projects",2017,"Journal of the Association for Information Science and Technology","","https://www.semanticscholar.org/paper/96f5a9360ccfd1c5c4210dc62948baac234c372d","",9,"2025-02-06 14:32:15","JournalArticle","10.1002/asi.23873","","",68,,,,41,5.13,14,3,8,"The challenge in executing a data science project is more than just identifying the best algorithm and tool set to use. Additional sociotechnical challenges include items such as how to define the project goals and how to ensure the project is effectively managed. This paper reports on a set of case studies where researchers were embedded within data science teams and where the researcher observations and analysis was focused on the attributes that can help describe data science projects and the challenges faced by the teams executing these projects, as opposed to the algorithms and technologies that were used to perform the analytics. Based on our case studies, we identified 14 characteristics that can help describe a data science project. We then used these characteristics to create a model that defines two key dimensions of the project. Finally, by clustering the projects within these two dimensions, we identified four types of data science projects, and based on the type of project, we identified some of the sociotechnical challenges that project teams should expect to encounter when executing data science projects.","",""
37,"L. Lyon, Aaron L. Brenner","Bridging the Data Talent Gap: Positioning the iSchool as an Agent for Change",2015,"International Journal of Digital Curation","","https://www.semanticscholar.org/paper/6e811ad31c065863213a686173950652dd79b2b3","",10,"2025-02-06 14:32:15","Review","10.2218/IJDC.V10I1.349","","",10,,111,122,37,3.70,19,2,10,"This paper examines the role, functions and value of the “iSchool” as an agent of change in the data informatics and data curation arena. A brief background to the iSchool movement is given followed by a brief review of the data decade, which highlights key data trends from the iSchool perspective: open data and open science, big data and disciplinary data diversity. The growing emphasis on the shortage of data talent is noted and a family of data science roles identified. The paper moves on to describe three primary functions of iSchools: education, research intelligence and professional practice, which form the foundations of a new Capability Ramp Model. The model is illustrated by mini-case studies from the School of Information Sciences, University of Pittsburgh: the immersive (laboratory-based) component of two new Research Data Management and Research Data Infrastructures graduate courses, a new practice partnership with the University Library System centred on RDM, and the mapping of disciplinary data practice using the Community Capability Model Profile Tool. The paper closes with a look to the future and, based on the assertion that data is mission-critical for iSchools, some steps are proposed for the next data decade: moving data education programs into the mainstream core curriculum, adopting a translational data science perspective and strengthening engagement with the Research Data Alliance.","",""
35,"Sasa Baskarada, A. Koronios","Unicorn data scientist: the rarest of breeds",2017,"Program","","https://www.semanticscholar.org/paper/26b05f787696493c0395d735166ee3f48a4a50f9","",11,"2025-02-06 14:32:15","JournalArticle","10.1108/PROG-07-2016-0053","0033-0337","",51,,65,74,35,4.38,18,2,8,"Purpose Many organizations are seeking unicorn data scientists, that rarest of breeds that can do it all. They are said to be experts in many traditionally distinct disciplines, including mathematics, statistics, computer science, artificial intelligence, and more. The purpose of this paper is to describe authors’ pursuit of these elusive mythical creatures. Design/methodology/approach Qualitative data were collected through semi-structured interviews with managers/directors from nine Australian state and federal government agencies with relatively mature data science functions. Findings Although the authors failed to find evidence of unicorn data scientists, they are pleased to report on six key roles that are considered to be required for an effective data science team. Primary and secondary skills for each of the roles are identified and the resulting framework is then used to illustratively evaluate three data science Master-level degrees offered by Australian universities. Research limitations/implications Given that the findings presented in this paper have been based on a study with large government agencies with relatively mature data science functions, they may not be directly transferable to less mature, smaller, and less well-resourced agencies and firms. Originality/value The skills framework provides a theoretical contribution that may be applied in practice to evaluate and improve the composition of data science teams and related training programs.","",""
34,"J. Saltz, Nicholas Hotz, D. Wild, Kyle Stirling","Exploring Project Management Methodologies Used Within Data Science Teams",2018,"Americas Conference on Information Systems","","https://www.semanticscholar.org/paper/b34b9758b36c92c023c3c10f3a39aeb8f5c83927","",12,"2025-02-06 14:32:15","JournalArticle","","","",,,,,34,4.86,9,4,7,"There are many reasons data science teams should use a well-defined process to manage and coordinate their efforts, such as improved collaboration, efficiency and stakeholder communication. This paper explores the current methodology data science teams use to manage and coordinate their efforts. Unfortunately, based on our survey results, most data science teams currently use an ad hoc project management approach. In fact, 82% of the data scientists surveyed did not follow an explicit process. However, it is encouraging to note that 85% of the respondents thought that adopting an improved process methodology would improve the teams’ outcomes. Based on these results, we described six possible process methodologies teams could use. To conclude, we outlined plans to describe best practices for data science team processes and to develop a process evaluation framework.","",""
34,"N. H. Møller, Gina Neff, J. Simonsen, J. C. Villumsen, Pernille Bjørn","Can Workplace Tracking Ever Empower? Collective Sensemaking for the Responsible Use of Sensor Data at Work",2021,"Proceedings of the ACM on Human-Computer Interaction","","https://www.semanticscholar.org/paper/6cab5e1c1d87f4c1ec46b9e4ddd0897d3febc835","",13,"2025-02-06 14:32:15","JournalArticle","10.1145/3463931","","",5,,1,21,34,8.50,7,5,4,"People are increasingly subject to the tracking of data about them at their workplaces. Sensor tracking is used by organizations to generate data on the movement and interaction of their employees to monitor and manage workers, and yet this data also poses significant risks to individual employees who may face harms from such data, and from data errors, to their job security or pay as a result of such analyses. Working with a large hospital, we developed a set of intervention strategies to enable what we call ""collective sensemaking"" describing worker contestation of sensor tracking data. We did this by participating in the sensor data science team, analyzing data on badges that employees wore over a two-week period, and then bringing the results back to the employees through a series of participatory workshops. We found three key aspects of collective sensemaking important for understanding data from the perspectives of stakeholders: 1) data shadows for tempering possibilities for design with the realities of data tracking; 2) data transducers for converting our assumptions about sensor tracking, and 3) data power for eliciting worker inclusivity and participation. We argue that researchers face what Dourish (2019) called the ""legitimacy trap"" when designing with large datasets and that research about work should commit to complementing data-driven studies with in-depth insights to make them useful for all stakeholders as a corrective to the underlying power imbalance that tracked workers face.","",""
33,"B. Koçak, R. Cuocolo, D. P. dos Santos, A. Stanzione, L. Ugga","Must-have Qualities of Clinical Research on Artificial Intelligence and Machine Learning",2022,"Balkan Medical Journal","","https://www.semanticscholar.org/paper/2cb5b20e852cdde009a8570c064fb6021f51b161","",14,"2025-02-06 14:32:15","JournalArticle","10.4274/balkanmedj.galenos.2022.2022-11-51","2146-3123","",40,,3,12,33,11.00,7,5,3,"In the field of computer science, known as artificial intelligence, algorithms imitate reasoning tasks that are typically performed by humans. The techniques that allow machines to learn and get better at tasks such as recognition and prediction, which form the basis of clinical practice, are referred to as machine learning, which is a subfield of artificial intelligence. The number of artificial intelligence-and machine learnings-related publications in clinical journals has grown exponentially, driven by recent developments in computation and the accessibility of simple tools. However, clinicians are often not included in data science teams, which may limit the clinical relevance, explanability, workflow compatibility, and quality improvement of artificial intelligence solutions. Thus, this results in the language barrier between clinicians and artificial intelligence developers. Healthcare practitioners sometimes lack a basic understanding of artificial intelligence research because the approach is difficult for non-specialists to understand. Furthermore, many editors and reviewers of medical publications might not be familiar with the fundamental ideas behind these technologies, which may prevent journals from publishing high-quality artificial intelligence studies or, worse still, could allow for the publication of low-quality works. In this review, we aim to improve readers’ artificial intelligence literacy and critical thinking. As a result, we concentrated on what we consider the 10 most important qualities of artificial intelligence research: valid scientific purpose, high-quality data set, robust reference standard, robust input, no information leakage, optimal bias-variance tradeoff, proper model evaluation, proven clinical utility, transparent reporting, and open science. Before designing a study, one should have defined a sound scientific purpose. Then, it should be backed by a high-quality data set, robust input, and a solid reference standard. The artificial intelligence development pipeline should prevent information leakage. For the models, optimal bias-variance tradeoff should be achieved, and generalizability assessment must be adequately performed. The clinical value of the final models must also be established. After the study, thought should be given to transparency in publishing the process and results as well as open science for sharing data, code, and models. We hope this work may improve the artificial intelligence literacy and mindset of the readers.","",""
31,"J. Saltz, N. Grady","The ambiguity of data science team roles and the need for a data science workforce framework",2017,"2017 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/0a9b30386408595ff0b3155d4de4a56dad80a97b","",15,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData.2017.8258190","","",,,2355,2361,31,3.88,16,2,8,"This paper first reviews the benefits of well-defined roles and then discusses the current lack of standardized roles within the data science community, perhaps due to the newness of the field. Specifically, the paper reports on five case studies exploring five different attempts to define a standard set of roles. These case studies explore the usage of roles from an industry perspective as well as from national standard big data committee efforts. The paper then leverages the results of these case studies to explore the use of data science roles within online job postings. While some roles appeared frequently, such as data scientist and data engineer, no role was consistently used across all five case studies. Hence, the paper concludes by noting the need to create a data science workforce framework that could be used by students, employers, and academic institutions. This framework would enable organizations to staff their data science teams more accurately with the desired skillsets.","",""
30,"T. Davenport","Beyond Unicorns: Educating, Classifying, and Certifying Business Data Scientists",2020,"","","https://www.semanticscholar.org/paper/0d024e80547e363cfdbee6a3428d68fedcfa57c5","",16,"2025-02-06 14:32:15","","10.1162/99608f92.55546b4a","","",2,,,,30,6.00,30,1,5,"There is increasing recognition that the data scientist ‘unicorn’—one who can master all the necessary skills of data science required by businesses—exists only rarely, if at all. Successful data science teams in business organizations, then, need to assemble people with a variety of different skills. This is only possible at scale with clear classification and certification of skills. While such certifications and classifications are in their early days, some firms are beginning to create them, and they are beginning to emerge in professional associations as well. Ideally, universities and other education providers and certifiers of data science skills would also employ standard skill classifications to communicate the skills they intend to inculcate.","https://hdsr.mitpress.mit.edu/pub/t37qjoi7/download/pdf",""
28,"Xingjian Shi, Jonas W. Mueller, Nick Erickson, Mu Li, Alexander J. Smola","Benchmarking Multimodal AutoML for Tabular Data with Text Fields",2021,"ArXiv","","https://www.semanticscholar.org/paper/175a7185d2089cd8746d4ddae2ecb13755bfcf48","",17,"2025-02-06 14:32:15","JournalArticle","","","",,,,,28,7.00,6,5,4,"We consider the use of automated supervised learning systems for data tables that not only contain numeric/categorical columns, but one or more text fields as well. Here we assemble 18 multimodal data tables that each contain some text fields and stem from a real business application. Our publicly-available benchmark enables researchers to comprehensively evaluate their own methods for supervised learning with numeric, categorical, and text features. To ensure that any single modeling strategy which performs well over all 18 datasets will serve as a practical foundation for multimodal text/tabular AutoML, the diverse datasets in our benchmark vary greatly in: sample size, problem types (a mix of classification and regression tasks), number of features (with the number of text columns ranging from 1 to 28 between datasets), as well as how the predictive signal is decomposed between text vs. numeric/categorical features (and predictive interactions thereof). Over this benchmark, we evaluate various straightforward pipelines to model such data, including standard two-stage approaches where NLP is used to featurize the text such that AutoML for tabular data can then be applied. Compared with human data science teams, the fully automated methodology that performed best on our benchmark (stack ensembling a multimodal Transformer with various tree models) also manages to rank 1st place when fit to the raw text/tabular data in two MachineHack prediction competitions and 2nd place (out of 2380 teams) in Kaggle's Mercari Price Suggestion Challenge.","",""
26,"J. Saltz","CRISP-DM for Data Science: Strengths, Weaknesses and Potential Next Steps",2021,"2021 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/aaa952ea3ab8e2ac9839d52df9cea2d918f4d363","",18,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData52589.2021.9671634","","",,,2337,2344,26,6.50,26,1,4,"This paper explores the strengths and weaknesses of CRISP-DM when used for data science projects. The paper then explores what key actions data science teams using CRISP-DM should consider that addresses CRISP-DM’s weaknesses. In brief, CRISP-DM, which is the most popular framework teams use to execute data science projects, provides an easy to understand description of the data science project workflow (i.e., the data science life cycle). However, CRISP-DM’s project phases miss some key aspects of the data science project life cycle. In addition, CRISP-DM’s task-focused approach fails to address how a team should prioritize tasks, and in general, collaborate and communicate. Hence, this paper also describes how CRISP-DM could be combined with a team coordination framework, such as Scrum or Data Driven Scrum, which is a newer collaboration framework developed to address the unique data science coordination challenges.","",""
23,"J. Saltz, I. Krasteva","Current approaches for executing big data science projects—a systematic literature review",2022,"PeerJ Computer Science","","https://www.semanticscholar.org/paper/25c96052796124efc455a0c5efc4d26efe5628ca","",19,"2025-02-06 14:32:15","JournalArticle","10.7717/peerj-cs.862","2376-5992","",8,,,,23,7.67,12,2,3,"There is an increasing number of big data science projects aiming to create value for organizations by improving decision making, streamlining costs or enhancing business processes. However, many of these projects fail to deliver the expected value. It has been observed that a key reason many data science projects don’t succeed is not technical in nature, but rather, the process aspect of the project. The lack of established and mature methodologies for executing data science projects has been frequently noted as a reason for these project failures. To help move the field forward, this study presents a systematic review of research focused on the adoption of big data science process frameworks. The goal of the review was to identify (1) the key themes, with respect to current research on how teams execute data science projects, (2) the most common approaches regarding how data science projects are organized, managed and coordinated, (3) the activities involved in a data science projects life cycle, and (4) the implications for future research in this field. In short, the review identified 68 primary studies thematically classified in six categories. Two of the themes (workflow and agility) accounted for approximately 80% of the identified studies. The findings regarding workflow approaches consist mainly of adaptations to CRISP-DM (vs entirely new proposed methodologies). With respect to agile approaches, most of the studies only explored the conceptual benefits of using an agile approach in a data science project (vs actually evaluating an agile framework being used in a data science context). Hence, one finding from this research is that future research should explore how to best achieve the theorized benefits of agility. Another finding is the need to explore how to efficiently combine workflow and agile frameworks within a data science context to achieve a more comprehensive approach for project execution.","",""
21,"Kehua Miao, Jie Li, Wenxing Hong, Mingtao Chen","A Microservice-Based Big Data Analysis Platform for Online Educational Applications",2020,"Sci. Program.","","https://www.semanticscholar.org/paper/5e7d2400a18528973c4ab1cbee62b2d3080a4be4","",20,"2025-02-06 14:32:15","JournalArticle","10.1155/2020/6929750","1058-9244","",2020,,6929750,,21,4.20,5,4,5,"The booming development of data science and big data technology stacks has inspired continuous iterative updates of data science research or working methods. At present, the granularity of the labor division between data science and big data is more refined. Traditional work methods, from work infrastructure environment construction to data modelling and analysis of working methods, will greatly delay work and research efficiency. In this paper, we focus on the purpose of the current friendly collaboration of the data science team to build data science and big data analysis application platform based on microservices architecture for education or nonprofessional research field. In the environment based on microservices that facilitates updating the components of each component, the platform has a personal code experiment environment that integrates JupyterHub based on Spark and HDFS for multiuser use and a visualized modelling tools which follow the modular design of data science engineering based on Greenplum in-database analysis. The entire web service system is developed based on spring boot.","https://downloads.hindawi.com/journals/sp/2020/6929750.pdf",""
20,"Ron S. Kenett, T. Redman","The Real Work of Data Science",2019,"","","https://www.semanticscholar.org/paper/1c180b76c7b1dceda9fac2bae5fdaf161f8fd602","",21,"2025-02-06 14:32:15","","10.1002/9781119570790","","",,,,,20,3.33,10,2,6,"The Economist boldly claims that data are now ""the world's most valuable resource."" But, as Kenett and Redman so richly describe, unlocking that value requires far more than technical excellence. The Real Work of Data Science explores understanding the problems, dealing with quality issues, building trust with decision makers, putting data science teams in the right organizational spots, and helping companies become data-driven. This is the work that spells the difference between a good data scientist and a great one, between a team that makes marginal contributions and one that drives the business, between a company that gains some value from its data and one in which data truly is ""the most valuable resource.""","",""
19,"John P. Wihbey","The Challenges of Democratizing News and Information: Examining Data on Social Media, Viral Patterns and Digital Influence",2014,"CommRN: Digital Media & Social Networks (Topic)","","https://www.semanticscholar.org/paper/ee5266da1954bb27b52990c05ebe675cede96391","",22,"2025-02-06 14:32:15","Review","10.2139/SSRN.2466058","","",,,,,19,1.73,19,1,11,"The advent of social media and peer-to-peer technologies offers the possibility of driving the full democratization of news and information, undercutting the agenda-setting of large media outlets and their relative control of news and information flows. We are now about a decade into the era of the social Web. What do the data indicate about changing news flows and access/consumption patterns in the United States? Are we witnessing a paradigm shift yet, or are legacy patterns reasserting themselves? This paper brings together media industry data and perspectiveâ€”from NPR, the Boston Globe and the Wall Street Journalâ€”with a growing body of social science and computational research produced by universities and firms such as Microsoft Research and the Facebook data science team, as well as survey findings from the Pew Research Center. The bulk of the evidence so far complicates any easy narrative, and it very much remains an open question if we can expect a more radically democratized media ecosystem, despite promising early trends and anecdotes. As I review the evidence, I aim to highlight lessons and insights that can help those thinking about and operating in the social media space. This paper also aims to serve as an accessible survey of news media-related topics within social science and social network analysis scholarship.","https://dash.harvard.edu/bitstream/1/12872220/1/d85-wihbey.pdf",""
17,"L. Lyon, Eleanor Mattern","Education for Real-World Data Science Roles (Part 2): A Translational Approach to Curriculum Development",2017,"Int. J. Digit. Curation","","https://www.semanticscholar.org/paper/7595cc05331008a01fc35980f5f4caede3afe986","",23,"2025-02-06 14:32:15","JournalArticle","10.2218/ijdc.v11i2.417","1746-8256","",11,,13,26,17,2.13,9,2,8,"This study reports on the findings from Part 2 of a small-scale analysis of requirements for real-world data science positions and examines three further data science roles: data analyst, data engineer and data journalist. The study examines recent job descriptions and maps their requirements to the current curriculum within the graduate MLIS and Information Science and Technology Masters Programs in the School of Information Sciences (iSchool) at the University of Pittsburgh. From this mapping exercise, model ‘course pathways’ and module ‘stepping stones’ have been identified, as well as course topic gaps and opportunities for collaboration with other Schools. Competency in four specific tools or technologies was required by all three roles (Microsoft Excel, R, Python and SQL), as well as collaborative skills (with both teams of colleagues and with clients). The ability to connect the educational curriculum with real-world positions is viewed as further validation of the translational approach being developed as a foundational principle of the current MLIS curriculum review process","",""
16,"T. Zhang, Zheyu Zhang, Zhiyuan Fan, Haoyan Luo, Feng Liu, Li-Yu Daisy Liu, Qian Liu, Wei Cao, Jian Li","OpenFE: Automated Feature Generation with Expert-level Performance",2022,"International Conference on Machine Learning","","https://www.semanticscholar.org/paper/fd842946d549ac8d62ee85fa11d1491e46473cba","",24,"2025-02-06 14:32:15","JournalArticle","","","",,,41880,41901,16,5.33,2,9,3,"The goal of automated feature generation is to liberate machine learning experts from the laborious task of manual feature generation, which is crucial for improving the learning performance of tabular data. The major challenge in automated feature generation is to efficiently and accurately identify effective features from a vast pool of candidate features. In this paper, we present OpenFE, an automated feature generation tool that provides competitive results against machine learning experts. OpenFE achieves high efficiency and accuracy with two components: 1) a novel feature boosting method for accurately evaluating the incremental performance of candidate features and 2) a two-stage pruning algorithm that performs feature pruning in a coarse-to-fine manner. Extensive experiments on ten benchmark datasets show that OpenFE outperforms existing baseline methods by a large margin. We further evaluate OpenFE in two Kaggle competitions with thousands of data science teams participating. In the two competitions, features generated by OpenFE with a simple baseline model can beat 99.3% and 99.6% data science teams respectively. In addition to the empirical results, we provide a theoretical perspective to show that feature generation can be beneficial in a simple yet representative setting. The code is available at https://github.com/ZhangTP1996/OpenFE.","",""
14,"Kevin Crowston, J. Saltz, Amira Rezgui, Yatish Hegde, Sangseok You","Socio-technical Affordances for Stigmergic Coordination Implemented in MIDST, a Tool for Data-Science Teams",2019,"Proceedings of the ACM on Human-Computer Interaction","","https://www.semanticscholar.org/paper/c0bb7271b247b2afb363ef23614cd324565906ed","",25,"2025-02-06 14:32:15","JournalArticle","10.1145/3359219","","",3,,1,25,14,2.33,3,5,6,"We present a conceptual framework for socio-technical affordances for stigmergic coordination, that is, coordination supported by a shared work product. Based on research on free/libre open source software development, we theorize that stigmergic coordination depends on three sets of socio-technical affordances: the visibility and combinability of the work, along with defined genres of work contributions. As a demonstration of the utility of the developed framework, we use it as the basis for the design and implementation of a system, MIDST, that supports these affordances and that we thus expect to support stigmergic coordination. We describe an initial assessment of the impact of the tool on the work of project teams of three to six data-science students that suggests that the tool was useful but also in need of further development. We conclude with plans for future research and an assessment of theory-driven system design.","https://dl.acm.org/doi/pdf/10.1145/3359219",""
14,"Angel Durr","A Text Analysis of Data-Science Career Opportunities and US iSchool Curriculum",2020,"Journal of Education for Library and Information Science","","https://www.semanticscholar.org/paper/4c6ea08d11f329be1083a28a5411b44c616b678e","",26,"2025-02-06 14:32:15","JournalArticle","10.3138/JELIS.2018-0067","","",61,,270,293,14,2.80,14,1,5,"Data science employment opportunities of varied complexity and environment are in growing demand across the globe. Data science as a discipline potentially offers a wealth of jobs to prospective employees, while traditional information science-based roles continue to decrease as budgets get cut across the U.S. Since data is related closely to information historically, this research will explore the education of U.S. iSchool professionals and compare it to traditional data science roles being advertised within the job market. Through a combination of latent semantic analysis of over 1600 job postings and iSchool course documentation, it is our aim to explore the intersection of library and information science and data science. Hopefully these research findings will guide future directions for library and information science professionals into data science driven roles, while also examining and highlighting the data science techniques currently driven by the education of iSchool professionals. In addition, it is our aim to understand how data science could benefit from a mutually symbiotic relationship with the field of information science as statistically data scientists spend far too much time working on data preparation and not nearly enough time conducting scientific inquiry. The results of this examination will potentially guide future directions of iSchool students and professionals towards more cooperative data science roles and guide future research into the intersection between iSchools and data science and possibilities for partnership.","",""
12,"Gennady Smorodin, O. Kolesnichenko","Big Data as the Big Game Changer",2015,"2015 9th International Conference on Application of Information and Communication Technologies (AICT)","","https://www.semanticscholar.org/paper/f9ddeb4159ce789735ee0b84990c179812697002","",27,"2025-02-06 14:32:15","Conference","10.1109/ICAICT.2015.7338512","","",,,40,43,12,1.20,6,2,10,"Big Data is the phenomenon of the Information era. Big Data is a new dimension to explore, collecting Big Data we fix the time. Big Data has some functions, including impact on society, form spatio-temporal structures, change the world and future, and integration society with IT technologies. Most important aspect is risk in Cloud computing. To leverage risks, secure Cloud services and get additional benefits an Integrated Approach should be applied. It is important to separate the various kinds of “Security” needs when considering Cloud computing issues. Also Security Analyst should be included into Data Science Team. Data-driven economy is based on three points: open data, legislation for Big Data, and education. For students is very important practical training that engages students into the culture of Big Data Analytics. This opportunity provides the EMC Academic Alliance Russia & CIS through the establishment of ad-hoc Big Data Analytics Teams among universities. The results of the first stage of launched in 2015 the Big Data Analytics Multicenter Study are presented.","",""
12,"Ashkan Ebadi, Yvan Gauthier, Stéphane Tremblay, Patrick Paul","How can Automated Machine Learning Help Business Data Science Teams?",2019,"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","","https://www.semanticscholar.org/paper/c3b35e0f95222ecd7dd258cd6068bf79bc935b15","",28,"2025-02-06 14:32:15","JournalArticle","10.1109/ICMLA.2019.00196","","",,,1186,1191,12,2.00,3,4,6,"Artificial intelligence and machine learning have attracted the attention of many commercial and non-profit organizations aiming to leverage advanced analytics, in order to provide a better service to their customers, increase their revenues through creating new or improving their existing internal processes, and better exploit their data by discovering complex hidden patterns. Such advanced solutions require data scientists with rare (and generally expensive) skill sets. Moreover, such solutions are often perceived as complex black boxes to decision-makers. Automated machine learning tools aim to reduce the expertise gap between the technical teams and stakeholders involved in business data science projects, by reducing the amount of time and specialized skills required to generate predictive models. We systematically benchmarked five automated machine learning tools against seven supervised learning problems of a business nature. Our results suggest that such tools, in fully automated mode, must be used cautiously, only where predictive models support low-impact decisions and do not need to be explainable, and only by data scientists capable to ensure that all phases of the data mining process have been performed adequately.","",""
12,"J. Saltz, Nicholas Hotz","Identifying the most Common Frameworks Data Science Teams Use to Structure and Coordinate their Projects",2020,"2020 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/4ca927fba5ab8fedbdc12ffecfa634f6eb49bdc7","",29,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData50022.2020.9377813","","",,,2038,2042,12,2.40,6,2,5,"This paper presents the results of a study focused on exploring which framework, if any, teams use to execute data science projects. The study consisted of a survey of 109 industry professionals, as well as an evaluation of relevant framework terms searched at Google. Overall, CRISP-DM was the most commonly used framework, with Scrum and Kanban being the second and third most frequently used. We note that CRISP-DM is a life cycle framework, whereas Scrum and Kanban are team coordination frameworks. Hence, this research also notes the potential demand for a framework that integrates both life cycle and team coordination aspects of leading a data science project.","",""
12,"E. Ferrero, S. Brachat, J. Jenkins, Philippe Marc, Peter Skewes-Cox, Robert C. Altshuler, C. Keller, A. Kauffmann, Erik K Sassaman, J. Laramie, B. Schoeberl, M. Borowsky, N. Stiefl","Ten simple rules to power drug discovery with data science",2020,"PLoS Computational Biology","","https://www.semanticscholar.org/paper/15e0914a9a4e3687fa74936bf9ae02b32103f92c","",30,"2025-02-06 14:32:15","JournalArticle","10.1371/journal.pcbi.1008126","","",16,,,,12,2.40,1,13,5,"Biomedical research is increasingly a high-dimensional science. In the pharmaceutical industry, data supporting the drug discovery and development process have become cheaper to generate and are increasing in complexity, diversity, and volume at a fast pace. This is the result of the introduction and development of novel technologies that enable molecular profiling, imaging, and other types of high-throughput readouts at an unprecedented scale. Similarly, clinical data created by companies or compiled by biobanks are growing at an exponential pace, not only in terms of sample size but also in the breadth of (increasingly digital) endpoints being measured and captured. In parallel to the increase in data, methodological advances are driving renewed development in statistical modeling, machine learning, and artificial intelligence (AI). The combination of data, computing power, and advanced analytics is positioning data science as a critical core discipline in pharmaceutical research, alongside the more traditional disciplines of biology, chemistry, and medicine. Realizing the full potential of data science requires adapting both the structure and culture of an organization. Signs of this transformation can already be seen across the pharmaceutical industry, with the creation of large data science teams and executive roles responsible for the implementation of a company-wide data science strategy. At a time when discovering transformative medicines is more challenging and requires more scientific creativity than ever before, we offer strategic recommendations to those who aspire to propel a digital culture shift and data science transformation in their organizations (Fig 1).","https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1008126&type=printable",""
11,"J. Saltz, Ivan Shamshurin","Does pair programming work in a data science context? An initial case study",2017,"2017 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/a395cab69cb4cd33c11b9ea128e8adda848b0959","",31,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData.2017.8258189","","",,,2348,2354,11,1.38,6,2,8,"While pair programming has been studied extensively for software programmers, very little has been reported with respect to pair programming in a data science project. This paper reports on a case study evaluating the effectiveness of pair programming within a data science / big data context. Our findings show that pair programming can be useful for data science teams. In addition, while the driver role was similar to what has been described for software programmers, we note that the observer role had an expanded set of responsibilities, which we termed researcher activities. Further exploration is required to explore if these expanded roles are specific to data science pair programming.","",""
11,"M. Berthold","What Does It Take to be a Successful Data Scientist?",2019,"1.2","","https://www.semanticscholar.org/paper/70407af895e7eb22dfe5e016bc2fd31b5b7d3982","",32,"2025-02-06 14:32:15","JournalArticle","10.1162/99608f92.e0eaabfc","","",,,,,11,1.83,11,1,6,"Given recent claims that data science can be fully automated or made accessible to nondata scientists through easy-to-use tools, I describe different types of data science roles within an organization. I then provide a view on the required skill sets of successful data scientists and how they can be obtained, concluding that data science requires both a profound understanding of the underlying methods as well as exhaustive experience gained from real-world data science projects. Despite some easy wins in specific areas using automation or easy-to-use tools, successful data science projects still require education and training.Keywords: data science, analytics, practitioner, education, insights, discovery","https://hdsr.mitpress.mit.edu/pub/5irjez4q/download/pdf",""
11,"Arjun Panesar","Ethics of Intelligence",2019,"Machine Learning and AI for Healthcare","","https://www.semanticscholar.org/paper/5bc7240f8c27bdea86cd02c7e53274f4b8d1abc1","",33,"2025-02-06 14:32:15","JournalArticle","10.1007/978-1-4842-3799-1_6","","",,,,,11,1.83,11,1,6,"","",""
10,"M. Mansoury","Understanding and mitigating multi-sided exposure bias in recommender systems",2021,"ACM SIGWEB Newsletter","","https://www.semanticscholar.org/paper/ff42d0c815c1d724857de077354ed9c9a7a22261","",34,"2025-02-06 14:32:15","JournalArticle","10.1145/3566100.3566103","","",2022,,1,4,10,2.50,10,1,4,"Masoud Mansoury is a postdoctoral researcher at Amsterdam Machine Learning Lab at University of Amsterdam, Netherlands. He is also a member of Discovery Lab collaborating with Data Science team at Elsevier Company in the area of recommender systems. Masoud received his PhD in Computer and Information Science from Eindhoven University of Technology, Netherlands, in 2021. He has published his research works in top conferences such as FAccT, RecSys, and CIKM. His research interests include recommender systems, algorithmic bias, and contextual bandits. This research conducted by Masoud Mansoury investigated the impact of unfair recommendations on different actors in the system and proposed solutions to tackle the unfairness of recommendations. The solutions were a rating transformation technique that works as a pre-processing step before recommendation generation and a general graph-based solution that works as a post-processing approach after recommendation generation for mitigating the multi-sided exposure bias in the recommendation results. For evaluation, he introduced several metrics for measuring the exposure fairness for items and suppliers, and showed that the proposed metrics better capture the fairness properties in the recommendation results. Extensive experiments on different publicly-available datasets confirmed the superiority of the proposed solutions in improving the exposure fairness for items and suppliers.","http://arxiv.org/pdf/2111.05564",""
10,"J. Saltz, Ivan Shamshurin","Achieving Agile Big Data Science: The Evolution of a Team’s Agile Process Methodology",2019,"2019 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/b3afa94613254549ad2de1d027c43ad57dbe7b46","",35,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData47090.2019.9005493","","",,,3477,3485,10,1.67,5,2,6,"While there has been a rapid increase in the use of data science and the related field of big data, there has been minimal discussion on how teams using these techniques should best plan, coordinate and communicate their activities. To help address this gap, this paper reports on a mixed method qualitative study exploring how a big data science team within a Fortune 500 organization used two different agile process methodologies. The study helps clarify the concept of agility within a big data science project, as well as the key process challenges teams encounter when executing a big data science project. Specifically, three key issues were identified: (a) the challenge in task duration estimation, (b) how to account for team members that might be pulled onto other tasks for short bursts and (c) coordination challenges across the different groups within the big data science team. Our findings help explain how different process methodologies might mitigate or exacerbate these challenges and supports previous research showing that big data science teams would benefit from an increased focus on their process methodology and that adopting an Agile Kanban methodology, which focuses on minimizing work-in-progress, could prove beneficial for many big data science teams.","",""
10,"S. Paul, M. K. Chatterjee","Data Sharing Solutions for Biobanks for the COVID-19 Pandemic.",2020,"Biopreservation and biobanking","","https://www.semanticscholar.org/paper/19d6bb95e8ed13988e6daa892eb49a1654367142","",36,"2025-02-06 14:32:15","JournalArticle","10.1089/bio.2020.0040","1947-5543","",,,,,10,2.00,5,2,5,"The coronavirus disease 2019 (COVID-19) is a novel illness, which is not fully understood. Whether an individual has traveled outside their respective country or never left their community, COVID-19 is a highly contagious illness, which can result in high death rates. Biobanks will play a role in providing tools to examine data from those receiving treatment along with reviewing the current and long treatment outcomes associated with this novel coronavirus disease. A diverse, global network made up of laboratory scientists, clinical researchers, epidemiologists, data science teams, physicians, and so on must have a standardized, collaborative, virtual biobanking solution to share clinical expertise and evidence-based solutions. This virtual biobank must be centrally managed to ensure standardized quality assurance and quality control efforts. Virtual biobanks will eliminate the need to transport samples between two locations for a specific study, minimizing the risk of contamination. It is necessary for virtual biobanks to upload imaging data from those patients diagnosed with COVID-19. Standardized, collected information will be essential in the area of discovery and validation of disease markers as well as novel therapeutic strategies. It is essential for biobanks to collect COVID-19 specimens along with corresponding clinical and demographic data from COVID-19 diagnostic testing. Because COVID-19 is an acute respiratory illness, proper collection procedures must be in place to collect respiratory samples for biobanking purposes. A preconfigured purpose-built COVID-19 Laboratory Information Management System (LIMS) is an efficient tool to seamlessly manage a data sharing network. Data entered into LIMS will be beneficial in designing much needed clinical trials to address any unmet needs to better address clinical treatment and outcomes. The partners or entities associated with the COVID-19 data sharing network will be able to effectively communicate, view data, and images associated with their respective research interest to advance COVID-19 research and data driven, clinical care.","",""
9,"S. North, C. Scheidegger, Simon Urbanek, Gordon Woodhull","Collaborative visual analysis with RCloud",2015,"2015 IEEE Conference on Visual Analytics Science and Technology (VAST)","","https://www.semanticscholar.org/paper/d0ef47d71b025c344e3e99ebd0d0d9ea2a6c907b","",37,"2025-02-06 14:32:15","JournalArticle","10.1109/VAST.2015.7347627","","",,,25,32,9,0.90,2,4,10,"Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: discoverability, technology transfer, and coexistence. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. About 100 people used RCloud for two years. We report on interviews with some of these users, and discuss design decisions, tradeoffs and limitations in comparison to other approaches.","",""
9,"C. Dreisbach, Theresa A. Koleck","The State of Data Science in Genomic Nursing",2020,"Biological Research For Nursing","","https://www.semanticscholar.org/paper/ca1caac66e428836dff937a0cc9b0c71430072b9","",38,"2025-02-06 14:32:15","JournalArticle","10.1177/1099800420915991","1099-8004","",22,,309,318,9,1.80,5,2,5,"Nurse scientists are generating, acquiring, distributing, processing, storing, and analyzing greater volumes of complex omics data than ever before. To take full advantage of big omics data, to address core biological questions, and to enhance patient care, however, genomic nurse scientists must embrace data science. Intended for readership with limited but expanding data science knowledge and skills, this article aims to provide a brief overview of the state of data science in genomic nursing. Our goal is to introduce key data science concepts to genomic nurses who participate at any stage of the data science lifecycle, from research patient recruitment to data wrangling, preprocessing, and analysis to implementation in clinical practice to policy creation. We address three major components in this review: (1) fundamental terminology for the field of genomic nursing data science, (2) current genomic nursing data science research exemplars, and (3) the spectrum of genomic nursing data science roles as well as education pathways and training opportunities. Links to helpful resources are included throughout the article.","",""
9,"Josh Gardner, Danai Koutra, Jawad Mroueh, Victor Pang, A. Farahi, Samuel Krassenstein, Jared Webb","Driving with Data: Modeling and Forecasting Vehicle Fleet Maintenance in Detroit",2017,"ArXiv","","https://www.semanticscholar.org/paper/0a54794db731458d53423902e2043d9fca0fb99e","",39,"2025-02-06 14:32:15","JournalArticle","","2331-8422","",,,,,9,1.13,1,7,8,"The City of Detroit maintains an active fleet of over 2500 vehicles, spending an annual average of over \$5 million on new vehicle purchases and over \$7.7 million on maintaining this fleet. Understanding the existence of patterns and trends in this data could be useful to a variety of stakeholders, particularly as Detroit emerges from Chapter 9 bankruptcy, but the patterns in such data are often complex and multivariate and the city lacks dedicated resources for detailed analysis of this data. This work, a data collaboration between the Michigan Data Science Team (this http URL) and the City of Detroit's Operations and Infrastructure Group, seeks to address this unmet need by analyzing data from the City of Detroit's entire vehicle fleet from 2010-2017. We utilize tensor decomposition techniques to discover and visualize unique temporal patterns in vehicle maintenance; apply differential sequence mining to demonstrate the existence of common and statistically unique maintenance sequences by vehicle make and model; and, after showing these time-dependencies in the dataset, demonstrate an application of a predictive Long Short Term Memory (LSTM) neural network model to predict maintenance sequences. Our analysis shows both the complexities of municipal vehicle fleet data and useful techniques for mining and modeling such data.","",""
8,"A. Farahi, Jonathan C. Stroud","The Michigan Data Science Team: A Data Science Education Program with Significant Social Impact",2018,"2018 IEEE Data Science Workshop (DSW)","","https://www.semanticscholar.org/paper/bfc866c270f1d3f659140a194d7c4185472f4ecd","",40,"2025-02-06 14:32:15","JournalArticle","10.1109/DSW.2018.8439915","","",,,120,124,8,1.14,4,2,7,"One role of universities is to provide students with the practical knowledge necessary to address broad societal needs. The growing field of data science has the potential to address many of these needs, primarily due to recent efforts to collect large amounts of data related to social, environmental, and political issues. A challenge is that there exists a disconnect between these real-world issues and the course materials taught to university students. This gap is due in part to a lack of engagement between universities and their local communities, leaving students with few opportunities to work with datasets relevant to real-world problems. To address this disconnect, the authors have implemented a novel data science education and outreach program in which students acquire new knowledge and skills while creating positive social impact through community service. In this work, we outline this outreach program, the Michigan Data Science Team, and provide empirical evidence of positive educational and social impact.","",""
8,"Nathan Sanders","A Balanced Perspective on Prediction and Inference for Data Science in Industry",2019,"Issue 1","","https://www.semanticscholar.org/paper/a88d6a605844473081430913ed85077db8933d9b","",41,"2025-02-06 14:32:15","JournalArticle","10.1162/99608F92.644EF4A4","","",,,,,8,1.33,8,1,6,"The strategic role of data science teams in industry is fundamentally to help businesses to make smarter decisions. This includes decisions on minuscule scales, such as what fraction of a cent to bid on an ad placement displayed in a web browser, whose importance is only manifest when scaled by orders of magnitude through machine automation. But it also extends to singular, monumental decisions made by businesses, such as how to position a new entrant within a competitive market. In both regimes, the potential impact of data science is only realized when both humans and machine actors are learning from data and when data scientists communicate effectively to decision makers throughout the business. I examine this dynamic through the instructive lens of the duality between inference and prediction. I define these concepts, which have varied use across many fields, in practical terms for the industrial data scientist. Through a series of descriptions, illustrations, contrasting concepts, and examples from the entertainment industry (box office prediction and advertising attribution), I offer perspectives on how the concepts of inference and prediction manifest in the business setting. From a balanced perspective, prediction and inference are integral components of the process by which models are compared to data. However, through a textual analysis of research abstracts from the literature, I demonstrate that an imbalanced, prediction-oriented perspective prevails in industry and has likewise become increasingly dominant among quantitative academic disciplines. I argue that, despite these trends, data scientists in industry must not overlook the valuable, generalizable insights that can be extracted through statistical inference. I conclude by exploring the implications of this strategic choice for how data science teams are integrated in businesses.KeywordsIndustry, Entertainment, Communication, Inference, Bibliometrics","",""
8,"M. Pasupuleti","Data Scientist Careers: Applied Orientation for the Beginners",2016,"Global Disclosure of Economics and Business","","https://www.semanticscholar.org/paper/a47e1d8af59aedc1da40cda168ff3637eba65a6b","",42,"2025-02-06 14:32:15","JournalArticle","10.18034/gdeb.v5i2.617","2305-9168","",,,,,8,0.89,8,1,9,"A data scientist's job is making sense of complex, unstructured data that comes from a variety of sources, including smart devices, social media feeds, and emails, and that doesn't cleanly fit into a database structure. According to the findings of this study, Data Scientists require programming, mathematics, and database abilities, all of which may be learned by self-study or through formal education. Companies looking to hire a Data Science team must be aware of the wide range of tasks that Data Scientists may fill, as well as the need for soft skills such as storytelling and connection building in addition to technical abilities and knowledge. The interpretation emphasizes that high school students interested in pursuing a career in Data Science should learn programming, mathematics, databases, and, most importantly, exercise their newfound knowledge. The study's findings centered on data scientists as analytical specialists who employ their expertise in both technology and social science to discover patterns and manage data. The solutions to business difficulties are discovered via the use of industry expertise, contextual awareness, and skepticism of current assumptions.","https://i-proclaim.my/journals/index.php/gdeb/article/download/617/571",""
8,"Ruoxuan Xiong, Alex Chin, Sean Taylor","Bias-Variance Tradeoffs for Designing Simultaneous Temporal Experiments",2023,"","","https://www.semanticscholar.org/paper/70159faf35d277a7f05da3ae6bd1465c7a29238e","",43,"2025-02-06 14:32:15","JournalArticle","","","",,,115,131,8,4.00,3,3,2,"We study the analysis and design of simultaneous temporal experiments, where a set of interventions are applied concurrently in continuous time, and outcomes are measured on a sequence of events observed in time. As a motivating setting, suppose multiple data science teams are conducting experiments simultaneously and independently on a ride-hailing platform to test changes to marketplace algorithms such as pricing and matching, and estimating effects from observed event outcomes such as the rate at which ride requests are completed. The design problem involves partitioning a continuous space of time into intervals and assigning treatments at the interval level. Design and analysis must account for three factors: carryover effects from interventions at earlier times, correlation in event outcomes, and effects of interventions tested simultaneously. We provide simulations to build intuition and guidance for practitioners.","",""
8,"T. Zhang, Zheyu Zhang, Zhiyuan Fan, Haoyan Luo, Feng Liu, Wei Cao, Jian Li","OpenFE: Automated Feature Generation beyond Expert-level Performance",2022,"ArXiv","","https://www.semanticscholar.org/paper/20ebf32e3fa4691e243106bd44eef2d81dbbe787","",44,"2025-02-06 14:32:15","JournalArticle","10.48550/arXiv.2211.12507","2331-8422","",,,,,8,2.67,1,7,3,"The goal of automated feature generation is to liberate machine learning experts from the laborious task of manual feature generation, which is crucial for improving the learning performance of tabular data. The major challenge in automated feature generation is to efﬁciently and accurately identify useful features from a vast pool of candidate features. In this paper, we present OpenFE, an automated feature generation tool that provides competitive results against machine learning experts. OpenFE achieves efﬁciency and accuracy with two components: 1) a novel feature boosting method for accurately estimating the incremental performance of candidate features. 2) a feature-scoring framework for retrieving effective features from a large number of candidates through successive feature-wise halving and feature importance attribution. Extensive experiments on seven benchmark datasets show that OpenFE outperforms existing baseline methods. We further evaluate OpenFE in two famous Kaggle competitions with thousands of data science teams participating. In one of the competitions, features generated by OpenFE with a simple baseline model can beat 99.3% data science teams. In addition to the empirical results, we provide a theoretical perspective to show that feature generation is beneﬁcial in a simple yet representative setting. The code is available at https:","http://arxiv.org/pdf/2211.12507",""
7,"Sofia Meacham, Vaclav Pech, D. Nauck","Classification Algorithms Framework (CAF) to Enable Intelligent Systems Using JetBrains MPS Domain-Specific Languages Environment",2020,"IEEE Access","","https://www.semanticscholar.org/paper/d0bdf91a2bce3fe3a512879505838aa31401e01c","",45,"2025-02-06 14:32:15","JournalArticle","10.1109/ACCESS.2020.2966630","2169-3536","",8,,14832,14840,7,1.40,2,3,5,"This paper describes the design and development of a Classification Algorithms Framework (CAF) using the JetBrains MPS domain-specific languages (DSLs) development environment. It is increasingly recognized that the systems of the future will contain some form of adaptivity therefore making them intelligent systems as opposed to the static systems of the past. These intelligent systems can be extremely complex and difficult to maintain. Descriptions at higher-level of abstraction (system-level) have long been identified by industry and academia to reduce complexity. This research presents a Framework of Classification Algorithms at system-level that enables quick experimentation with several different algorithms from Naive Bayes to Logistic Regression. It has been developed as a tool to address the requirements of British Telecom’s (BT’s) data-science team. The tool has been presented at BT and JetBrains MPS and feedback has been collected and evaluated. Beyond the reduction in complexity through the system-level description, the most prominent advantage of this research is its potential applicability to many application contexts. It has been designed to be applicable for intelligent applications in several domains from business analytics, eLearning to eHealth, etc. Its wide applicability will contribute to enabling the larger vision of Artificial Intelligence (AI) adoption in context.","",""
7,"Rohith Sothilingam, E. Yu","Modeling Agents, Roles, and Positions in Machine Learning Project Organizations",2020,"International i* Workshop","","https://www.semanticscholar.org/paper/670d2b4fc5c6953e6643f699915a9c69d1150abf","",46,"2025-02-06 14:32:15","JournalArticle","","","",,,61,66,7,1.40,4,2,5,". As Machine Learning (ML) continues its emergence across numerous industries, software teams and organizations face new challenges beyond those found in conventional software projects. The design of data science teams in ML software projects can vary substantially based on the organization's maturity, personnel availability, and their relationship with customers. In an empirical case study of three ML software project organizations, we examined variations in project team designs using i* models. We consider the usefulness of the concepts of Agents, Roles, and Positions defined in the original i* framework to support the analysis of complex organizational relationships. We illustrate how the Position concept helps distinguish the different ways in which each ML software project organizes its team to meet specific needs.","",""
7,"Christopher McComb, J. Defranco, Torsten Maier","An analysis of design process and performance in distributed data science teams",2019,"Team Performance Management: An International Journal","","https://www.semanticscholar.org/paper/6086f3bddd41c0760c6a1072b1b0e5bdff16ad08","",47,"2025-02-06 14:32:15","JournalArticle","10.31224/osf.io/fwrqj","1352-7592","",,,,,7,1.17,2,3,6,"PurposeOften, it is assumed that teams are better at solving problems than individuals working independently. However, recent work in engineering, design and psychology contradicts this assumption. This study aims to examine the behavior of teams engaged in data science competitions. Crowdsourced competitions have seen increased use for software development and data science, and platforms often encourage teamwork between participants.Design/methodology/approachWe specifically examine the teams participating in data science competitions hosted by Kaggle. We analyze the data provided by Kaggle to compare the effect of team size and interaction frequency on team performance. We also contextualize these results through a semantic analysis.FindingsThis work demonstrates that groups of individuals working independently may outperform interacting teams on average, but that small, interacting teams are more likely to win competitions. The semantic analysis revealed differences in forum participation, verb usage and pronoun usage when comparing top- and bottom-performing teams.Research limitations/implicationsThese results reveal a perplexing tension that must be explored further: true teams may experience better performance with higher cohesion, but nominal teams may perform even better on average with essentially no cohesion. Limitations of this research include not factoring in team member experience level and reliance on extant data.Originality/valueThese results are potentially of use to designers of crowdsourced data science competitions as well as managers and contributors to distributed software development projects.","https://engrxiv.org/preprint/download/541/1214",""
7,"D. Patil","Building Data Science Teams The Skills Tools and Perspectives Behind Great Data Science Groups",2011,"","","https://www.semanticscholar.org/paper/603ca9f831bef1dbb55f26c068bb3722da3a9326","",48,"2025-02-06 14:32:15","","","","",18,,,,7,0.50,7,1,14,"","",""
7,"J. Saltz, A. Sutherland","SKI: An Agile Framework for Data Science",2019,"2019 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/39df17fff25077da585abf4b378e07dbcb110ccc","",49,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData47090.2019.9005591","","",,,3468,3476,7,1.17,4,2,6,"This paper explores data science project management by first noting the need for a new process management framework and then defines a process framework that effectively supports the needs of a data science team. The paper also reports on a pilot study of teams using the framework. The framework adheres to the lean Kanban philosophy but augments Kanban by providing a structured iteration process for teams to incrementally explore and learn via lean hypothesis testing. Specifically, the Structured Kanban Iteration (SKI) framework focuses on having teams define capability-based iterations (as opposed to Kanban-like no iterations or Scrumlike time-based sprints). Furthermore, unlike Kanban, the framework leverages Scrum best practices to define roles, meetings and artifacts. Thus, SKI implements the Kanban process, but with a more repeatable and structured approach.","",""
7,"Atin Sood, Benjamin Elder, Benjamin Herta, Chao Xue, C. Bekas, A. Malossi, Debashis Saha, F. Scheidegger, Ganesh Venkataraman, Gegi Thomas, G. Mariani, Hendrik Strobelt, Horst Samulowitz, Martin Wistuba, Matteo Manica, M. Choudhury, Rong Yan, R. Istrate, Ruchi Puri, Tejaswini Pedapati","NeuNetS: An Automated Synthesis Engine for Neural Network Design",2019,"ArXiv","","https://www.semanticscholar.org/paper/00e60afd39fb5df9e0d7ed0a3895467bdd86eaca","",50,"2025-02-06 14:32:15","JournalArticle","","2331-8422","",,,,,7,1.17,1,20,6,"Application of neural networks to a vast variety of practical applications is transforming the way AI is applied in practice. Pre-trained neural network models available through APIs or capability to custom train pre-built neural network architectures with customer data has made the consumption of AI by developers much simpler and resulted in broad adoption of these complex AI models. While prebuilt network models exist for certain scenarios, to try and meet the constraints that are unique to each application, AI teams need to think about developing custom neural network architectures that can meet the tradeoff between accuracy and memory footprint to achieve the tight constraints of their unique use-cases. However, only a small proportion of data science teams have the skills and experience needed to create a neural network from scratch, and the demand far exceeds the supply. In this paper, we present NeuNetS : An automated Neural Network Synthesis engine for custom neural network design that is available as part of IBM's AI OpenScale's product. NeuNetS is available for both Text and Image domains and can build neural networks for specific tasks in a fraction of the time it takes today with human effort, and with accuracy similar to that of human-designed AI models.","",""
6,"Sindhu Ghanta, Sriram Ganapathi Subramanian, L. Khermosh, Harshil Shah, Y. Goldberg, S. Sundararaman, D. Roselli, Nisha Talagala","MPP: Model Performance Predictor",2019,"ArXiv","","https://www.semanticscholar.org/paper/d5f80c1bda049cec79e5996e6252056da7c4c972","",51,"2025-02-06 14:32:15","JournalArticle","","","",,,,,6,1.00,1,8,6,"Operations is a key challenge in the domain of machine learning pipeline deployments involving monitoring and management of real-time prediction quality. Typically, metrics like accuracy, RMSE etc., are used to track the performance of models in deployment. However, these metrics cannot be calculated in production due to the absence of labels. We propose using an ML algorithm, Model Performance Predictor (MPP), to track the performance of the models in deployment. We argue that an ensemble of such metrics can be used to create a score representing the prediction quality in production. This in turn facilitates formulation and customization of ML alerts, that can be escalated by an operations team to the data science team. Such a score automates monitoring and enables ML deployments at scale.","",""
6,"Tee Zhen Quan, Mafas Raheem","Human Resource Analytics on Data Science Employment Based on Specialized Skill Sets with Salary Prediction",2023,"International Journal of Data Science","","https://www.semanticscholar.org/paper/c309b91e50ddde16a33dc35bd1b4ad0fd90a2b27","",52,"2025-02-06 14:32:15","JournalArticle","10.18517/ijods.4.1.40-59.2023","2053-0811","",,,,,6,3.00,3,2,2,"The research aims to perform meaningful human resource analysis on data science employment using the strong influences of specialized skills set with assisting salary prediction. With explosive big data development, a data science job shortage has occurred with high accurate recruitment demand to hire suitable professionals for specific data science roles. To achieve such outcomes, the current data science employment trends were analyzed based on a secondary dataset. Useful analytics insights for job securement and better career development were provided through the main dashboard. Besides, the significant in-demand data science skill variables were also identified for further effective model building. Particularly, certain data pre-processing techniques were performed extensively to prepare and optimize the dataset for the mentioned human resource analytics purposes. The ensemble model was selected as the most suitable salary prediction model with the lowest Average Squared Error (ASE) on validation. Despite the low prediction accuracy caused by numerous filtered skill variables, the salary prediction model’s main objective was to interpret the relationships between input variables and the target salary levels variable. Overall, the results from both the human resource analytic dashboard and salary prediction model were tally where a detailed analytic report was provided to encourage different data science roles with specific and effective career development guidance, using salary as the motivation key.","http://www.ijods.org/index.php/ds/article/download/64/45",""
6,"Marva V. Foster, Zarin Tasnim","Data Science and Graduate Nursing Education",2020,"Clinical Nurse Specialist","","https://www.semanticscholar.org/paper/a951dd4cf5a80fcf0b28e5df868ad8d23d9329b3","",53,"2025-02-06 14:32:15","JournalArticle","10.1097/NUR.0000000000000516","","",34,,124,131,6,1.20,3,2,5,"Background The emergence of big data and data science offers unprecedented opportunities for accelerating scientific advances in nursing, yet current nursing curricula are not adequate to prepare students to leverage those opportunities. Purpose The purpose of this review was to describe current strategies that can be used to educate graduate nurses about data science methods as well as facilitators and challenges to adopting those strategies. Method We conducted a critical literature review of papers addressing data science and graduate nursing education. Results Ten articles were included in this review. The most common strategy was the integration of data science methods into existing courses throughout the graduate nursing curricula. A major facilitator was interdisciplinary collaboration between nursing faculty and colleagues in other disciplines. Conclusion The findings provide strategies that can be used to prepare graduate nurses to work in data science teams to shape big data research and optimize patient outcomes.","",""
6,"Shuangzhe Liu","Directional Statistics for Innovative Applications: A Bicentennial Tribute to Florence Nightingale",2023,"Technometrics","","https://www.semanticscholar.org/paper/6b4edfac23dde5ddb941b75f739dd32c02b74294","",54,"2025-02-06 14:32:15","JournalArticle","10.1080/00401706.2022.2163808","0040-1706","",65,,133,134,6,3.00,6,1,2,"some of this information may become dated relatively soon, but it takes a basic mathematical statistics book down a useful path. The direction is set early in chapter 1 with this advice, “...careful thought is needed to decide which statistical methods are appropriate for any particular situation, as they all make certain assumptions, and some methods work poorly when the assumptions are violated.” Statistical packages can always run the numbers, but understanding the assumptions discussed in this book is necessary for proper use. Chapters 4–6 take the reader into the heart of more traditional statistical inference used by a frequentist along with the corresponding Bayesian approach. The classical approach has been the building blocks for the majority of statistical analysis but now there are so many more tools at the disposal of talented and resourceful data scientists. I like that in chapter 4 the authors introduce the use of bootstrapping. Not only does bootstrapping help when the underlying sampling distribution is unknown but it has multiple applications for the data scientist. The introduction of the Bayesian approach is great, realizing that it may require additional resources for practical implementation. Chapter 5 covers the obligatory treatment of statistical tests. I like that the authors include Bayesian statistical tests with the frequentist versions in this chapter and that they address the importance of practical significance versus statistical significance and how statistical tests can be misleading. Chapter 6 includes the basic setup for linear models and least squares. This is expanded to include multiple regression, summarizing variability in regression models, with statistical inference using the classical approach and Bayesian methods and concludes the chapter with some matrix notation. Some of the practical advice presented in this chapter is “Reality is more complex and never perfectly described by a model, but a model is a tool for making our perception of reality clearer.” Or as George Box is often quoted as saying “All models are wrong, but some are useful” (Box 1979). I also like that the authors whet the appetite of the reader by pointing to chapter 7 and describe when it is more appropriate to use regularization rather than the more common usage of multiple regression techniques. The final chapters, 7–9, briefly expose the reader to generalized linear models, clustering, classification, and a historical overview of statistics. In chapter 7, the practical techniques of linear regression are expanded to include useful tools like logistic and Poisson regression. This greatly enhances a data scientist’s toolbox for working with the wide variety of situations that occur when trying to model real world relationships. Chapter 8 introduces the reader to classification and clustering. Valuable practical information is provided in their discussion of when to use logistic regression versus linear discriminant analysis and classification trees. The rest of the chapter gives a brief discussion of k nearest neighbors and neural networks for classification and cluster analysis. The topics introduced here serve only as a starting point for the reader to do more learning in these areas in order to apply these types of analysis in practical applications. Chapter 9 discusses some of the history of data science. What I find the most interesting for a data scientist from this chapter are their final words addressing what they call the pillars of wisdom for practicing data science. These are as follows: plan the study well, data quality is paramount, be aware of potential sources of bias, expect variability and deal with it properly, check assumptions and use appropriate statistical methods, aim for parsimony in methods, presentation, and interpretation, and make analyses reproducible and encourage replication. These are all true and valuable, but situations arise where not all assumptions can be verified. When this happens and the process needs to move forward it is necessary to give our best estimate, qualified with all concerns (transparency). Sometimes we have to act as a lawyer because of all the fine print needed to qualify what can be concluded from the available data and what we may need to reevaluate as more and/or better data is collected. The appendices for using R and Python are definitely one of the strengths of this book both for training future data scientists and a reference for those transitioning into the data science role. The examples in the appendices provide more complicated, realistic examples with outliers for bootstrap confidence intervals, simulation, nonparametric, survival, regularization, and clustering. It also shows the reader how to do the same analysis in R and Python which can aid the reader in their understanding of how to use these two different programming languages. Every data scientist benefits from having a solid statistical foundation. If this knowledge can be gained as an undergraduate student that is ideal, but some without statistical training transition into a data science role after they leave college. It is important for these data scientists to also have access to the same knowledge. Internet searches for statistical techniques are a valuable tool, but when researching how to use a data science tool it is easy to overlook the assumptions needed to properly interpret the results. The statistical foundation that this book provides about the proper use of statistical methods is key for the application of data science tools in practice. That makes this book a valuable asset to those working on a degree in data science and to those who are getting their education on the job.","https://www.tandfonline.com/doi/pdf/10.1080/00401706.2022.2163808?needAccess=true&role=button",""
6,"Yannis Katsis, Christine T. Wolf","ModelLens: An Interactive System to Support the Model Improvement Practices of Data Science Teams",2019,"Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing","","https://www.semanticscholar.org/paper/45f207674045bceb1046e0059a99bd040236925a","",55,"2025-02-06 14:32:15","Book","10.1145/3311957.3359512","","",,,,,6,1.00,3,2,6,"This demo presents ModelLens, an interactive system designed to support data science teams in their model improvement practices. A central component of improving models is analyzing model errors, often incorporating feedback on the model's precision and recall performance (e.g., differences between the model's predicted label and its actual label). Today, error analysis is typically an ad hoc, team-specific process, largely accomplished through spreadsheets. ModelLens offers a unified view of feedback from multiple sources, the ability for data scientists to explore the context of an individual feedback instance, as well as a customizable ontology to enable collaborative and systematic annotations of model errors.","",""
5,"Bin Yu, Chandan Singh","Seven Principles for Rapid-Response Data Science: Lessons Learned from Covid-19 Forecasting",2021,"Statistical Science","","https://www.semanticscholar.org/paper/d2db5631a1ba6e006addf418894875ac5f53faf7","",56,"2025-02-06 14:32:15","JournalArticle","10.1214/22-sts855","0883-4237","",,,,,5,1.25,3,2,4,"In this article, we take a step back to distill seven principles out of our experience in the spring of 2020, when our 12-person rapid-response team used skills of data science and beyond to help distribute Covid PPE. This process included tapping into domain knowledge of epidemiology and medical logistics chains, curating a relevant data repository, developing models for short-term county-level death forecasting in the US, and building a website for sharing visualization (an automated AI machine). The principles are described in the context of working with Response4Life, a then-new nonprofit organization, to illustrate their necessity. Many of these principles overlap with those in standard data-science teams, but an emphasis is put on dealing with problems that require rapid response, often resembling agile software development.","https://projecteuclid.org/journals/statistical-science/volume-37/issue-2/Seven-Principles-for-Rapid-Response-Data-Science--Lessons-Learned/10.1214/22-STS855.pdf",""
5,"Ivar Hukkelberg, M. Berntzen","Exploring the Challenges of Integrating Data Science Roles in Agile Autonomous Teams",2019,"","","https://www.semanticscholar.org/paper/bf0491447a3b2238864061d3227a2c3f61fd0dc2","",57,"2025-02-06 14:32:15","JournalArticle","10.1007/978-3-030-30126-2_5","","",,,37,45,5,0.83,3,2,6,"","https://link.springer.com/content/pdf/10.1007%2F978-3-030-30126-2_5.pdf",""
5,"Arjun Panesar","Machine Learning and AI Ethics",2020,"Machine Learning and AI for Healthcare","","https://www.semanticscholar.org/paper/b3a72f596b57a18bf3120f6157789b055a4b03e5","",58,"2025-02-06 14:32:15","JournalArticle","10.1007/978-1-4842-6537-6_8","","",,,207,247,5,1.00,5,1,5,"","",""
5,"Mohan Mahanty, K. Swathi, K. Teja, P. H. Kumar, A. Sravani","Forecasting the Spread of COVID-19 Pandemic with Prophet",2021,"Rev. d'Intelligence Artif.","","https://www.semanticscholar.org/paper/a681f18f5c308560c92392c7022d04340153d987","",59,"2025-02-06 14:32:15","JournalArticle","10.18280/ria.350202","","",35,,115,122,5,1.25,1,5,4,"COVID-19 pandemic shook the whole world with its brutality, and the spread has been still rising on a daily basis, causing many nations to suffer seriously. This paper presents a medical stance on research studies of COVID-19, wherein we estimated a time-series data-based statistical model using prophet to comprehend the trend of the current pandemic in the coming future after July 29, 2020 by using data at a global level. Prophet is an open-source framework discovered by the Data Science team at Facebook for carrying out forecasting based operations. It aids to automate the procedure of developing accurate forecasts and can be customized according to the use case we are solving. The Prophet model is easy to work because the official repository of prophet is live on GitHub and is open for contributions and can be fitted effortlessly. The statistical data presented on the paper refers to the number of daily confirmed cases officially for the period January 22, 2020, to July 29, 2020. The estimated data produced by the forecast models can then be used by Governments and medical care departments of various countries to manage the existing situation, thus trying to flatten the curve in various nations as we believe that there is minimal time to do this. The inferences made using the model can be clearly comprehended without much effort. Furthermore, it tries to give an understanding of the past, present, and future trends by showing graphical forecasts and statistics. Compared to other models, prophet specifically holds its own importance and innovativeness as the model is fully automated and generates quick and precise forecasts that can be tunable additionally. © 2021 Lavoisier. All rights reserved.","https://www.iieta.org/download/file/fid/54975",""
5,"Nur Yildirim, Susanna Zlotnikov, Deniz Sayar, Jeremy M. Kahn, L. Bukowski, Sher Shah Amin, K. Riman, B. Davis, J. S. Minturn, Andrew J. King, Dan Ricketts, Lu Tang, Venkatesh Sivaraman, Adam Perer, Sarah Preum, James McCann, John Zimmerman","Sketching AI Concepts with Capabilities and Examples: AI Innovation in the Intensive Care Unit",2024,"Proceedings of the CHI Conference on Human Factors in Computing Systems","","https://www.semanticscholar.org/paper/98e07970cf2609454d74a33c29a2c0629f520fe9","",60,"2025-02-06 14:32:15","JournalArticle","10.1145/3613904.3641896","","",,,,,5,5.00,1,17,1,"Advances in artificial intelligence (AI) have enabled unprecedented capabilities, yet innovation teams struggle when envisioning AI concepts. Data science teams think of innovations users do not want, while domain experts think of innovations that cannot be built. A lack of effective ideation seems to be a breakdown point. How might multidisciplinary teams identify buildable and desirable use cases? This paper presents a first hand account of ideating AI concepts to improve critical care medicine. As a team of data scientists, clinicians, and HCI researchers, we conducted a series of design workshops to explore more effective approaches to AI concept ideation and problem formulation. We detail our process, the challenges we encountered, and practices and artifacts that proved effective. We discuss the research implications for improved collaboration and stakeholder engagement, and discuss the role HCI might play in reducing the high failure rate experienced in AI innovation.","https://dl.acm.org/doi/pdf/10.1145/3613904.3641896",""
5,"J. Saltz, F. Armour, R. Sharda","Data Science Roles and the Types of Data Science Programs",2018,"Commun. Assoc. Inf. Syst.","","https://www.semanticscholar.org/paper/854540b7fa62b38ee17dcc5353dbcc7a120d18ec","",61,"2025-02-06 14:32:15","JournalArticle","10.17705/1CAIS.04333","1529-3181","",43,,33,,5,0.71,2,3,7,"","",""
5,"J. Saltz","Identifying the Key Drivers for Teams to Use a Data Science Process Methodology",2018,"European Conference on Information Systems","","https://www.semanticscholar.org/paper/09207f6026c71cf1d01f811bd0cb8dcae4719865","",62,"2025-02-06 14:32:15","JournalArticle","","","",,,58,,5,0.71,5,1,7,"While data science teams do not yet typically use a standard team process methodology, researchers are starting to explore process methodologies that improve team performance. However, little has been done to understand what might be the key acceptance factors for teams to implement a data science process methodology. To address this gap, the Diffusion of Innovation Theory is used as a theoretical lens to identify factors that might drive an organization to adopt a data science process methodology. The results of this qualitative research effort found ten factors that can influence a team to use, or not use, a data science process methodology. In short, eight positive factors were found with respect to relative advantage and compatibility and two negative factors were identified with respect to complexity. While more work is required to validate and refine these factors, the derived acceptance model can help teams as they consider adopting an improved data science process methodology.","",""
5,"M. Goul, T. S. Raghu, Robert D. St. Louis","APC Forum: Governing the Wild West of Predictive Analytics and Business Intelligence",2018,"MIS Q. Executive","","https://www.semanticscholar.org/paper/01e8c88c58b8488ae1c50444732777231f9842bc","",63,"2025-02-06 14:32:15","JournalArticle","","","",17,,8,,5,0.71,2,3,7,"Most organizations look to data science teams to parlay data assets into business intelligence and prescriptive analytics solutions. Such solutions will inevitably be embedded in core applications and business processes essential to running the enterprise because faster speed-to-decision can create a competitive advantage. Effective organizational governance of such infused analytics solutions is necessary to mitigate the risks associated with analytics that may go awry, resulting in unintended consequences. Governance also avoids losing critical information on assumptions underlying analytics solutions when data scientists leave the organization or when environmental changes render these assumptions, and thus the solution, obsolete or invalid. Consider the Target fiasco with coupons aimed at a teenage girl algorithmically deemed to be pregnant. Her family did not take kindly to being informed by mailings signaling the situation. Also, think about the mortgage derivatives that were rapidly devalued leading to the Great Recession. It was clear that investment ratings agencies’ predictive models were decayed and no longer relevant as the financial mess cascaded into chaos. Also, consider the flash crash of 2010, when the stock market took a 1,000-point swing in one day. In 2015, a person APC Forum: Governing the Wild West of Predictive Analytics and Business Intelligence","",""
4,"Rock Yuren Pang, Ruotong Wang, Joely Nelson, L. Battle","How Do Data Science Workers Communicate Intermediate Results?",2022,"2022 IEEE Visualization in Data Science (VDS)","","https://www.semanticscholar.org/paper/be6d6bd04a99c74d4e1ab3ab271f25bc366085cf","",64,"2025-02-06 14:32:15","JournalArticle","10.1109/VDS57266.2022.00010","","",,,46,54,4,1.33,1,4,3,"Data science workers increasingly collaborate on large-scale projects before communicating insights to a broader audience in the form of visualization. While prior work has modeled how data science teams, oftentimes with distinct roles and work processes, communicate knowledge to outside stakeholders, we have little knowledge of how data science workers communicate intermediately before delivering the final products. In this work, we contribute a nuanced description of the intermediate communication process within data science teams. By analyzing interview data with 8 self-identified data science workers, we characterized the data science intermediate communication process with four factors, including the types of audience, communication goals, shared artifacts, and mode of communication. We also identified three overarching challenges in the current communication process. We also discussed design implications that might inform better tools that facilitate intermediate communication within data science teams.","https://arxiv.org/pdf/2210.03305",""
4,"T. Vairam, S. Sarathambekai, S. Bhavadharani, A. Kavi Dharshini, N. Nithya Sri, Tarika Sen","Evaluation of Naïve Bayes and Voting Classifier Algorithm for Credit Card Fraud Detection",2022,"2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS)","","https://www.semanticscholar.org/paper/be5a7ed4faed34e5bcf7321b6bae9cf8ed468425","",65,"2025-02-06 14:32:15","Conference","10.1109/ICACCS54159.2022.9784968","","",1,,602,608,4,1.33,1,6,3,"In this new generation, each and everything is done online and most of the time the payment is performed via the internet using net banking or a credit card. Debit card and credit card plays a major part in day-to- day life. The total amount of money transfers through online has a great amount of growth. Fraudulent transactions have escalated as E-commerce continues to expand at a rapid pace. Therefore banks, financial institutions and many other companies offer credit card fraud detection applications with more demand, and it adds more value to the applications. To reduce the transactions that are fraud, Credit Card Fraud Detection that employ Machine Learning Techniques comes to the rescue, which is a data investigation procedure carried out by a Data Science team, with the model generated providing the greatest outcomes in stopping fraudulent transactions.","",""
4,"J. Saltz, Nicholas Hotz","Factors that Influence the Selection of a Data Science Process Management Methodology: An Exploratory Study",2021,"Hawaii International Conference on System Sciences","","https://www.semanticscholar.org/paper/7df8af6af097d2c3834a8c6fe88235da3116e2fd","",66,"2025-02-06 14:32:15","JournalArticle","10.24251/HICSS.2021.116","","",,,1,11,4,1.00,2,2,4,"This paper explores the factors that impact the adoption of a process methodology for managing and coordinating data science projects. Specifically, by conducting semi-structured interviews from data scientists and managers across 14 organizations, eight factors were identified that influence the adoption of a data science project management methodology. Two were technical factors (Exploratory Data Analysis, Data Collection and Cleaning). Three were organizational factors (Receptiveness to Methodology, Team Size, Knowledge and Experience), and three were environmental factors (Business Requirements Clarity, Documentation Requirements, Release Cadence Expectations). The research presented in this paper extends recognized factors for IT process adoption by bringing together influential factors that apply to data science. Teams can use the developed process adoption model to make a more informed decision when selecting their data science project management process methodology.","http://scholarspace.manoa.hawaii.edu/bitstream/10125/70728/1/0094.pdf",""
4,"Antonio Maiorino, Zoe Padgett, Chun Wang, Misha Yakubovskiy, Peng Jiang","Application and Evaluation of Large Language Models for the Generation of Survey Questions",2023,"Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","","https://www.semanticscholar.org/paper/59f4b8e052700b806abebbd8fa37eee541b2d7f5","",67,"2025-02-06 14:32:15","Book","10.1145/3583780.3615506","","",,,,,4,2.00,1,5,2,"Generative Language Models have shown promising results in various domains, and some of the most successful applications are related to ""concept expansion"", which is the task of generating extensive text based on concise instructions provided through a ""seed"" prompt. In this presentation we will discuss the recent work conducted by the Data Science team at SurveyMonkey, where we have recently introduced a new feature that harnesses Generative AI models to streamline the survey design process. With this feature users can effortlessly initiate this process by specifying their desired objectives through a prompt, allowing them to automate the creation of surveys that include the critical aspects they wish to investigate. We will share our findings regarding some of the challenges encountered during the development of this feature. These include techniques for conditioning the model outputs, integrating generated text with industry-standard questions, fine-tuning Language Models using semi-synthetic Data Generation techniques, and more. Moreover, we will showcase the Evaluation Methodology that we have developed to measure the quality of the generated surveys across several dimensions. This evaluation process is crucial in ensuring that the generated surveys align well with user expectations and serve their intended purpose effectively. Our goal is to demonstrate the promising potential of Generative Language Models in the context of Survey Research, and we believe that sharing our learnings on these challenges and how we addressed them will be useful for practitioners working with Language Models on similar problems.","",""
4,"Doug Rose","Understanding Critical Thinking",2016,"","","https://www.semanticscholar.org/paper/4747f60440f04973386f3b6476be7ec9692e430b","",68,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_15","","",,,145,154,4,0.44,4,1,9,"","",""
3,"Dan Sholler, S. Stoudt, Chris J. Kennedy, Fernando Hoces de la Guardia, F. Lanusse, Karthik Ram, Kellie Ottoboni, Marla Stuart, M. Vareth, Nelle Varoquaux, Rebecca L. Barter, R. Geiger, Scott Peterson, Stéfan J. van der Walt","Resistance to Adoption of Best Practices",2019,"","","https://www.semanticscholar.org/paper/fb7c4cc408c30859a7cf649d9ef0f5326a70d08f","",69,"2025-02-06 14:32:15","","10.31235/osf.io/qr8cz","","",,,,,3,0.50,0,14,6,"There are many recommendations of ""best practices"" for those doing data science, data-intensive research, and research in general. These documents usually present a particular vision of how people should work with data and computing, recommending specific tools, activities, mechanisms, and sensibilities. However, implementation of best (or better) practices in any setting is often met with resistance from individuals and groups, who perceive some drawbacks to the proposed changes to everyday practice. We offer some definitions of resistance, identify the sources of researchers' hesitancy to adopt new ways of working, and describe some of the ways resistance is manifested in data science teams. We then offer strategies for overcoming resistance based on our group members' experiences working alongside resistors or resisting change themselves. Our discussion concluded with many remaining questions left to tackle, some of which are listed at the end of this piece.","",""
3,"Sara Bonesso, F. Gerli, Elena Bruni","The emotional and social side of analytics professionals: an exploratory study of the behavioral profile of data scientists and data analysts",2022,"International Journal of Manpower","","https://www.semanticscholar.org/paper/f473a3a27f5658a7264c7afd1283d9cd282313d6","",70,"2025-02-06 14:32:15","JournalArticle","10.1108/ijm-07-2020-0342","0143-7720","",,,,,3,1.00,1,3,3,"PurposeAnalytics technologies are profoundly changing the way in which organizations generate economic and social value from data. Consequently, the professional roles of data scientists and data analysts are in high demand in the labor market. Although the technical competencies expected for these roles are well known, their behavioral competencies have not been thoroughly investigated. Drawing on the competency-based theoretical framework, this study aims to address this gap, providing evidence of the emotional, social and cognitive competencies that data scientists and data analysts most frequently demonstrate when they effectively perform their jobs, and identifying those competencies that distinguish them.Design/methodology/approachThis study is exploratory in nature and adopts the competency-based methodology through the analysis of in-depth behavioral event interviews collected from a sample of 24 Italian data scientists and data analysts.FindingsThe findings empirically enrich the extant literature on the intangible dimensions of human capital that are relevant in analytics roles. Specifically, the results show that, in comparison to data analysts, data scientists more frequently use certain competencies related to self-awareness, teamwork, networking, flexibility, system thinking and lateral thinking.Research limitations/implicationsThe study was conducted in a small sample and in a specific geographical area, and this may reduce the analytic generalizability of the findings.Practical implicationsThe skills shortages that characterize these roles need to be addressed in a way that also considers the intangible dimensions of human capital. Educational institutions can design better curricula for entry-level data scientists and analysts who encompass the development of behavioral competencies. Organizations can effectively orient the recruitment and the training processes toward the most relevant competencies for those analytics roles.Originality/valueThis exploratory study advances our understanding of the competencies required by professionals who mostly contribute to the performance of data science teams. This article proposes a competency framework that can be adopted to assess a broader portfolio of the behaviors of big data professionals.","https://www.emerald.com/insight/content/doi/10.1108/IJM-07-2020-0342/full/pdf?title=the-emotional-and-social-side-of-analytics-professionals-an-exploratory-study-of-the-behavioral-profile-of-data-scientists-and-data-analysts",""
3,"Tiffany Tuor, J. Lockhart, D. Magazzeni","Asynchronous collaborative learning across data silos",2021,"Proceedings of the Second ACM International Conference on AI in Finance","","https://www.semanticscholar.org/paper/eb89ac8e55ee0ccc462542c5d1f9fb3036a96cae","",71,"2025-02-06 14:32:15","JournalArticle","10.1145/3490354.3494394","","",,,,,3,0.75,1,3,4,"Machine learning algorithms can perform well when trained on large datasets. While large organisations often have considerable data assets, it can be difficult for these assets to be unified in a manner that makes training possible. Data is very often 'siloed' in different parts of the organisation, with little to no access between silos. This fragmentation of data assets is especially prevalent in heavily regulated industries like financial services or healthcare. In this paper we propose a framework to enable asynchronous collaborative training of machine learning models across data silos. This allows data science teams to collaboratively train a machine learning model, without sharing data with one another. Our proposed approach enhances conventional federated learning techniques to make them suitable for this asynchronous training in this intra-organisation, cross-silo setting. We validate our proposed approach via extensive experiments.","https://dl.acm.org/doi/pdf/10.1145/3490354.3494394",""
3,"Jay Gendron, Steve Mortimer, Tammy Crane, C. Eshelman-Haynes","Transforming Governmental Data Science Teams in the Future",2018,"","","https://www.semanticscholar.org/paper/d7bb55da1acd6724f4a8a7d8f1a26778fe4c03ef","",72,"2025-02-06 14:32:15","","10.1016/B978-0-12-812443-7.00013-2","","",,,211,221,3,0.43,1,4,7,"","",""
3,"Julita Vassileva, James Blustein, Lora Aroyo, S. D’Mello","Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization",2016,"Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization","","https://www.semanticscholar.org/paper/a9e0b5cc8c3dfb373b42ef22f982dd38366d5ca1","",73,"2025-02-06 14:32:15","Book","10.1145/3209219","","",,,,,3,0.33,1,4,9,"Welcome to the 24th ACM International Conference on User Modeling, Adaptation, and Personalization (UMAP 2016) in Halifax, Canada, July 13-16, 2016. UMAP is the premier international conference for researchers and practitioners working on systems that adapt to individual users or to groups of users. UMAP is the successor of the biennial User Modeling (UM) and Adaptive Hypermedia and Adaptive Web-based Systems (AH) conferences that were merged in 2009. It has traditionally been organized under the auspices of User Modeling Inc. This year (2016) UMAP became an ACM conference, sponsored by ACM SIG CHI and SIG WEB. The conference spans a wide scope of topics related to user modeling, adaptation, and personalization. UMAP 2016 is focused on bringing together cutting-edge research from user interaction and modeling, adaptive technologies, and delivery platforms. It includes high-quality peer-reviewed papers featuring substantive new research in one of five research areas, each chaired by leaders in the field: User Modeling for Recommender Systems (chairs: Alexander Felfernig & Pasquale Lops) Adaptive & Personalized Educational Systems (chairs: Antonija Mitrovic & Kalina Yacef) Personalization in the Social Web & Crowdsourcing Era (chairs: Alessandro Bozzon & Harith Alani) Adaptive, Intelligent, & Multimodal User Interfaces (chairs: Julien Epps & Hatice Gunes) Architectures, Techniques, & Methodologies for UMAP (chairs: Stephan Weibelzahl & Mihaela Cocea) This year we received 123 submissions. In keeping with UMAPs rigorous standards, each paper was carefully reviewed by members of the Program Committee (PC) while the Area Chairs (ACs) coordinated the reviews and provided recommendations to the Program Chairs. The international Program Committee (PC) consisted of 132 members who were assisted by 49 subreviewers. These were leading researchers as well as highly promising young researchers. Papers were assigned to at least 4 members of the PC and to 1 AC member based on their expertise, interests, and other factors. Each paper received at least 3 reviews, and 95% received 4 reviews. After the initial reviews were submitted, the designated AC facilitated discussion amongst reviewers in order to resolve differences and correct misunderstandings. The AC then provided a summative meta-review and a recommendation to the Program Chairs. The final decisions were based on these recommendations, the meta-reviews, and reviewer scores. We accepted 21 long papers (23.9% acceptance rate) and 13 short papers (27.6% acceptance rate) for oral presentation and an additional 17 extended abstracts for poster presentation and inclusion in the proceedings. The program also features posters, demos, and late breaking results, which collectively showcase the wide spectrum of novel ideas and latest results in user modeling, adaptation and personalization. We also invited three distinguished keynote speakers, each illustrating significant issues and prospective directions for the field. Hossein Derakhshan (shared keynote speaker with Hypertext 2016) is an Iranian-Canadian blogger who was imprisoned in Tehran from November 2008 to November 2014. He has been called the ""father of Persian blogging"" and has helped promote podcasting in Iran. His talk, ""Killing the Hyperlink, Killing the Web: the Shift from Library-Internet to Television-Internet,"" reflects his views on the Internet today. Lada Adamic leads the Product Science group within Facebook's Data Science Team. She is also an adjunct associate professor at the University of Michigan's School of Information and Center for the Study of Complex Systems. Her talk ""The Life and Times of Information in Networks"" focuses on cascades of information-sharing and resharing within social media. Sandra Carberry was one of the founders of the User Modeling research area at the first workshop in Maria Laach in 1986. As appropriate for the 30th anniversary, her talk ""User Modeling: The Past, The Present and The Future"" discusses how the field evolved, insights into where the field is headed, and the hottest topics for exploration. The conference includes a doctoral consortium that provides an opportunity for doctoral students to explore and develop their research interests under the guidance of distinguished scholars. This track received 18 submissions of which nine were accepted as full papers and eight as posters. A set of seven workshops and two tutorials round out the program. (Workshop) IFUP: Workshop on Multi-dimension Information Fusion for Modeling and Personalisation (half-day) organized by Robin Burke (DePaul University, USA), Feida Zhu (Singapore Management University, Singapore), Neil Yorke-Smith (American University of Beirut, Lebanon), and Guibing Guo (Northeastern University, China) (Workshop) INRA: News Recommendation and Analytics (half-day) organized by Jon Atle Gulla (Norwegian University of Science and Technology Trondheim, Norway), Luc Martens (Minds-UGent-WiCa Ghent, Belgium), Ozlem Ozgobek (Norwegian University of Science and Technology Trondheim, Norway), and Nafiseh Shabib (TNS Gallup, Oslo, Norway) (Workshop) SOAP: Workshop on Surprise, Opposition, and Obstruction in Adaptive and Personalized Systems (half-day) organized by Peter Knees (Johannes Kepler University Linz, Austria), Kristina Andersen (Studio for Electro Instrumental Music, Amsterdam, the Netherlands), Alan Said (Recorded Future, Gothenburg, Sweden), and Marko Tkalcic (Free University of Bozen-Bolzano, Italy) (Workshop) HAAPIE: Human Aspects in Adaptive and Personalised Interactive Environments (half-day) organized by Panagiotis Germanakos (SAP SE, Germany), Marios Belk (Department of Computer Science, University of Cyprus), George Samaras (Department of Computer Science, University of Cyprus), and Vania Dimitrova (University of Leeds, UK) (Workshop) EvalUMAP: Towards comparative evaluation in the user modelling, adaptation and personalization space (full-day) organized by Owen Conlan (Trinity College Dublin, Ireland), Liadh Kelly (Trinity College Dublin, Ireland), Kevin Koidl (Trinity College Dublin, Ireland), Seamus Lawless (Trinity College Dublin, Ireland), Killian Levacher (Trinity College Dublin, Ireland), and Athanasios Staikopoulos (Trinity College Dublin, Ireland) (Workshop) FuturePD: The future of personal data: envisioning new personalized services enabled by Quantified Self technologies (half-day) organized by Amon Rapp (University of Torino, Italy), Federica Cena (University of Torino, Italy), Judy Kay (University of Sidney, Australia), Bob Kummerfeld (University of Sydney, Australia), Frank Hopfgartner (University Gardens Glasgow, UK), Jakob Eg Larsen (Technical University of Denmark, Denmark), and Elise van den Hoven (University of Technology Sydney, Australia). (Workshop) PALE: Personalization Approaches in Learning Environments (full-day) organized by Milos Kravcik (RWTH Aachen University, Germany), Olga C. Santos (UNED, Spain), Jesus G. Boticario (UNED, Spain), and Maria Bielikova (FIIT STUBA, Slovakia) (Tutorial) Semantics-Aware Techniques for Social Media Analysis, User Modeling, and Recommender Systems (half-day) by Pasquale Lops and Cataldo Musto (University of Bari Aldo Moro, Italy) (Tutorial) Games, Gamification and Personalization (half-day) by Amon Rapp (University of Torino, Italy).","",""
3,"Jie Tao, Xing Fang, Lina Zhou","Unsupervised Deep Learning for Fake Content Detection in Social Media",2021,"Hawaii International Conference on System Sciences","","https://www.semanticscholar.org/paper/a9ba12e9ec37ee3e5ca90bb8888f9ac67cb0bcd9","",74,"2025-02-06 14:32:15","JournalArticle","10.24251/HICSS.2021.032","","",,,1,10,3,0.75,1,3,4,"Fake content is ever increasing in the online environment, driven by various motivations such as gaining commercial and political advantages. The interactive and collaborative nature of social media further fuels the growth of fake content by exerting fast and widespread influence. Despite growing and interdisciplinary efforts in detecting fake content in social media, some common research challenges remain to be addressed such as humans’ cognitive bias and scarcity of labeled data for training supervised machine learning models. This study aims to tackle both challenges by developing unsupervised deep learning models for the detection of fake content in social media. In view that traditional linguistic features fail to capture context information, our proposed method learns feature representations from the context in social media content. The empirical evaluation results with fake comments from YouTube demonstrate that our proposed methods not only outperform baseline models with traditional unsupervised machine learning techniques, but also achieve comparable performance to the state-of-the-art supervised models. The proposed analytical pipeline provides an end-toend solution to detecting fake social media contents, which largely reduce the human labor required in collaborative data science teams (i.e., particularly the data labeling). The findings of this study can be used to facilitate collaboration in data science by reducing humans’ cognitive bias and improve the collaboration efficiency.","http://scholarspace.manoa.hawaii.edu/bitstream/10125/70643/1/0028.pdf",""
3,"Enda Ridge","Guerrilla Analytics: A Practical Approach to Working with Data",2014,"","","https://www.semanticscholar.org/paper/908855d5e50fa1f0550479b9e51f5e0e9c0e7f35","",75,"2025-02-06 14:32:15","","","","",,,,,3,0.27,3,1,11,"Doing data science is difficult. Projects are typically very dynamic with requirements that change as data understanding grows. The data itself arrives piecemeal, is added to, replaced, contains undiscovered flaws and comes from a variety of sources. Teams also have mixed skill sets and tooling is often limited. Despite these disruptions, a data science team must get off the ground fast and begin demonstrating value with traceable, tested work products. This is when you need Guerrilla Analytics. In this book, you will learn about: The Guerrilla Analytics Principles: simple rules of thumb for maintaining data provenance across the entire analytics life cycle from data extraction, through analysis to reporting. Reproducible, traceable analytics: how to design and implement work products that are reproducible, testable and stand up to external scrutiny. Practice tips and war stories: 90 practice tips and 16 war stories based on real-world project challenges encountered in consulting, pre-sales and research. Preparing for battle: how to set up your team's analytics environment in terms of tooling, skill sets, workflows and conventions. Data gymnastics: over a dozenanalytics patterns that your team will encounter again and again in projects.","",""
3,"","Facilitating team-based data science: Lessons learned from the DSC-WAV project",2021,"Foundations of Data Science","","https://www.semanticscholar.org/paper/88412fd49aeba20bb6efbbc09e26abd6f67efc0f","",76,"2025-02-06 14:32:15","Review","10.3934/fods.2022003","2639-8001","",,,,,3,0.75,0,0,4,"While coursework provides undergraduate data science students with some relevant analytic skills, many are not given the rich experiences with data and computing they need to be successful in the workplace. Additionally, students often have limited exposure to team-based data science and the principles and tools of collaboration that are encountered outside of school.In this paper, we describe the DSC-WAV program, an NSF-funded data science workforce development project in which teams of undergraduate sophomores and juniors work with a local non-profit organization on a data-focused problem. To help students develop a sense of agency and improve confidence in their technical and non-technical data science skills, the project promoted a team-based approach to data science, adopting several processes and tools intended to facilitate this collaboration.Evidence from the project evaluation, including participant survey and interview data, is presented to document the degree to which the project was successful in engaging students in team-based data science, and how the project changed the students' perceptions of their technical and non-technical skills. We also examine opportunities for improvement and offer insight to other data science educators who may want to implement a similar team-based approach to data science projects at their own institutions.","https://www.aimsciences.org/data/article/export-pdf?id=620c4aaf2d80b75aa4a24b8f",""
3,"Xin Fu, Hernán Asorey","Data-Driven Product Innovation",2015,"Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","https://www.semanticscholar.org/paper/755fa7afe27c5e87b8480efeab125559e5975629","",77,"2025-02-06 14:32:15","Book","10.1145/2783258.2789994","","",,,,,3,0.30,2,2,10,"Data Science is an increasingly popular area of Knowledge Discovery and Data Mining. Leading consumer Web companies such as Amazon, Facebook, eBay, Google and LinkedIn, as well as B2B companies like Salesforce, possess Petabytes of data. Through effective mining of this data, they create products and services that benefit millions of users and generate tremendous amount of business value. It is widely acknowledged that Data Scientists play key roles in the creation of these products, from pattern identification, idea generation and product prototyping to experiment design and launch decisions. Nonetheless, they also face common challenges, such as the gap between creating a prototype and turning it into a scalable product, or the frustration of generating innovative product ideas that do not get adopted. Organizers of this tutorial have many years of experience leading Data Science teams in some of the most successful consumer Web companies. In this tutorial, we introduce the framework that we created to nurture data-driven product innovations. The core of this framework is the focus on scale and impact - we take the audience through a discussion on how to balance between velocity and scale, between product innovation and product operation, and between theoretical research and practical impact. We also share some guidelines for successful data-driven product innovation with real examples from our experiences. We end the tutorial by discussing the organizational perspective of data-driven product innovation: how to structure Data Science teams so Data Scientists collaborate effectively with other functions, and how to hire and grow talents into Data Scientist roles.","",""
3,"Linmiao Zhang, William Susanto, Katsumasa Takahashi, Albert Chen, Tim Tang, Y. Zou, Chenxi Lin, Simon P. Hastings, Samee ur Rehman, M. Rijpstra, A. Sun","Process context based wafer level grouping control: an advanced overlay process correction designed for DRAM 1z nm node in high volume manufacturing",2020,"","","https://www.semanticscholar.org/paper/68019ebabc29721e6299c3e376e8661816de2c14","",78,"2025-02-06 14:32:15","","10.1117/12.2552823","","",11325,,113251,,3,0.60,0,11,5,"On Product Overlay (OPO) is a critical budget for advanced lithography. LithoInSight (LIS), an ASML application product, has proven to improve the ability of advanced process control (APC) for overlay with accurate fingerprint estimation and optimized scanner correction. It is now often used as Process of Record (PoR) for performing chuck/lot based run-to-run (R2R) control in a High Volume Manufacturing (HVM) environment. In order to further improve the on-product performance given the ever-tightening overlay spec. in advanced nodes, the question of how to reduce wafer-to-wafer process-induced variation has been asked frequently. Studies have shown that the wafer-to-wafer overlay variation is driven by certain critical process contexts. Aiming to bring a solution to the HVM phase, the ASML and Micron Data Science teams developed a Wafer Level Grouping Control (WLGC) methodology to perform overlay control given the process context information. This methodology has been implemented in one of the Micron production fabs, and demonstrated both reduced wafer-to-wafer (W2W) overlay variation and improved device yield on a yield-critical layer for a product from Micron 1z DRAM node.","",""
3,"Trent Jacobs","Shell Picks a Digital Platform To Build Its AI Future Upon",2018,"Journal of Petroleum Technology","","https://www.semanticscholar.org/paper/669bc1d8193c91fe3454ce929b64ad43bda77828","",79,"2025-02-06 14:32:15","JournalArticle","10.2118/1218-0043-jpt","0149-2136","",,,,,3,0.43,3,1,7,"Alisa Choong, the chief information officer at Shell, recently told several hundred oil and gas professionals that “digitization is about making the right choices.” Speaking on a panel at SPE’s Annual Technology Conference and Exhibition in Dallas in September, Choong shared that Shell has made one of those choices by signing a 3-year deal to use the enterprisewide analytics platform developed by Silicon Valley-based C3 IOT on Microsoft’s Azure cloud service. The development comes on the heels of BP’s September announcement that is expanding the use of a competing analytics platform. Taken together, these cases reveal how large operating companies plan to manage and put into action their growing arsenals of machine-learning and artificial-intelligence (AI) programs. For the past few years, the industry’s first movers have been assembling data science teams. As these teams and their capabilities mature, it has become clearer that they need a new kind of digital infrastructure that runs independent of the IT department. “That’s fundamentally why Shell decided to standardize on the C3 IOT platform,” said Ed Abbo, chief technology officer and cofounder of C3 IOT. Seeing his firm’s platform as a “catalyst,” he added that Shell now has “a jumpstart on the market to operationalize these AI algorithms.” After raising $100 million in equity funding earlier this year, C3 IOT has become one of the fastest-growing industrial analytics players. Its leadership also includes the billionaire entrepreneur Tom Siebel, who serves as chief executive officer and is most known for selling his previous software company, Siebel Systems, to Oracle for $5.8 billion in 2005. Abbo was involved in software development at both Siebel Systems and Oracle prior to starting C3 IOT with Siebel. Scaling Up Shell’s AI Shell began its trials with the C3 IOT platform by using it to automatically predict maintenance needs on dozens of gas compressors, which was successful in identifying failure risks up to 48 hours in advance. The plan is now to expand this use case to hundreds of thousands of machines across the world—both on the company’s offshore facilities and onshore refineries. Additionally, Shell’s ambitions include using C3 IOT’s platform to support its supply chain and other digital initiatives involving computer vision and natural-language processing. The ability to scale up this diverse set of applications is seen as the chief driver behind the adoption of enterprise-wide platforms. Founded in 2009, C3 IOT is among the earliest entrants into the platform space and is joined by a growing cast of competitors that include Arundo and GE Predix. These companies are vying for their slice of the upstream market because most oil and gas companies of size store their data in hundreds or thousands of locations. The developers say that without an analytics platform, the job of ingesting, correlating, and keeping all these data sources updated in real time will keep industrial firms from launching algorithms across large bases of equipment and production systems.","",""
3,"Ido Guy, Kira Radinsky","Structuring the Unstructured: From Startup to Making Sense of eBay's Huge eCommerce Inventory",2017,"Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval","","https://www.semanticscholar.org/paper/62aa06d9372692bd0c8a4fa98dc7abbfbae77c2f","",80,"2025-02-06 14:32:15","JournalArticle","10.1145/3077136.3096469","","",,,,,3,0.38,2,2,8,"Electronic commerce continues to gain popularity in recent years. On eBay, one of the largest on-line marketplaces in the world, millions of new listings (items) are submitted by a variety of sellers every day. This renders a rich diverse inventory characterized by a particularly long tail. In addition, many items in the inventory lack basic structured information, such as product identifiers, brand, category, and other properties, due to sellers' tendency to input unstructured information only, namely title and description. Such inventory therefore requires a handful of large-scale solutions to assist in organizing the data and gaining business insights. In 2016, eBay acquired SalesPredict to help structure its unstructured data. In this proposed presentation, we will share the story of a research startup from its inception until its acquisition and integration as eBay's data science team. We will review the numerous challenges from research and engineering perspectives of a startup and the principal challenges the eBay data science organization deals with today. These include the identification of duplicate, similar, and related products; the extraction of name-value attributes from item titles and descriptions; the matching of items entered by sellers to catalog products; the ranking of item titles based on their likelihood to serve as ""good"" product titles; and the creation of ""browse node"" pages to address complex search queries from potential buyers. We will describe how the eBay data science team approaches these challenges and some of the solutions already launched to production. These solutions involve the use of large-scale machine learning, information retrieval, and natural language processing techniques, and should therefore be of interest to the SIGIR audience at large.","",""
3,"Sarah E. Ryan, Lingzi Hong, Mohotarema Rashid","From corpus creation to formative discovery: the power of big-data-rhetoric teams and methods",2023,"Review of Communication","","https://www.semanticscholar.org/paper/37c23216df6fa2d097d714ca9478a61b9649c18f","",81,"2025-02-06 14:32:15","JournalArticle","10.1080/15358593.2022.2119094","1535-8593","",23,,38,61,3,1.50,1,3,2,"ABSTRACT Rhetoric has been slow to adopt big-data techniques, but that is changing. In this article, we describe the formative work of our rhetoric-data science team on an ideographic analysis of state veteran laws. Our interdisciplinary approach enabled us to build a corpus of more than 7,000 files, segment that corpus into likely public and private laws, and develop dictionaries for discerning individual entitlements, such as waived fees for gun permits. Early results show state-level trends in the number of veteran laws, proportion of veteran laws concerning disabled veterans, and proportion of veteran/disability laws affording individual entitlements. While this article presents early findings, its broader purpose is to contribute to discussions of corpus building, data cleaning, formative analysis, and the value of big-data-rhetoric collaborations. Our experience provides five insights: (1) big-data collection methods can save a public rhetoric project when customary retrieval methods fail; (2) big-data-rhetoric work starts conceptually and becomes concretized; (3) formative big-data rhetoric work can problematize fundamental research assumptions, such as what should be included in a corpus; (4) big-data methods can produce interesting results early, yielding a roadmap for future work; and (5) big-data-rhetoric teams need more guidance from the field.","",""
3,"Winston Maxwell, Bruno Dumas","Meaningful XAI Based on User-Centric Design Methodology",2023,"ArXiv","","https://www.semanticscholar.org/paper/2193765c1405cccfc78c688983a18f89248a305e","",82,"2025-02-06 14:32:15","JournalArticle","10.48550/arXiv.2308.13228","2331-8422","",,,,,3,1.50,2,2,2,"This report first takes stock of XAI-related requirements appearing in various EU directives, regulations, guidelines, and CJEU case law. This analysis of existing requirements will permit us to have a clearer vision of the purposes, the ``why'', of XAI, which we separate into five categories: contestability, empowerment/redressing information asymmetries, control over system performance, evaluation of algorithmic decisions, and public administration transparency. The analysis of legal requirements also permits us to create four categories of recipients for explainability: data science teams; human operators of the system; persons affected by algorithmic decisions, and regulators/judges/auditors. Lastly, we identify four main operational contexts for explainability: XAI for the upstream design and testing phase; XAI for human-on-the-loop control; XAI for human-in-the-loop control; and XAI for ex-post challenges and investigations.Second, we will present user-centered design methodology, which takes the purposes, the recipients and the operational context into account in order to develop optimal XAI solutions.Third, we will suggest a methodology to permit suppliers and users of high-risk AI applications to propose local XAI solutions that are effective in the sense of being ``meaningful'', for example, useful in light of the operational, safety and fundamental rights contexts. The process used to develop these ``meaningful'' XAI solutions will be based on user-centric design principles examined in the second part.Fourth, we will suggest that the European Commission issue guidelines to provide a harmonised approach to defining ``meaningful'' explanations based on the purposes, audiences and operational contexts of AI systems. These guidelines would apply to the AI Act, but also to the other EU texts requiring explanations for algorithmic systems and results.","https://arxiv.org/pdf/2308.13228",""
3,"Sucheta Lahiri, J. Saltz","Evaluating Data Science Project Agility by Exploring Process Frameworks Used by Data Science Teams",2023,"Hawaii International Conference on System Sciences","","https://www.semanticscholar.org/paper/1fe0e0d7a69a7fa44f5b9d2ea7c3dc72984615d2","",83,"2025-02-06 14:32:15","JournalArticle","10.24251/hicss.2023.790","","",,,6538,6547,3,1.50,2,2,2,"","https://scholarspace.manoa.hawaii.edu/bitstreams/7fe7d024-3885-43fe-84e8-e7302ed6445f/download",""
3,"Kevin Crowston, J. Saltz, Amira Rezgui, Yatish Hegde, Sangseok You","MIDST: A System to Support Stigmergic Coordination in Data-Science Teams",2019,"Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing","","https://www.semanticscholar.org/paper/1d28c4881b919f6fefdd29559e6937d3690adf06","",84,"2025-02-06 14:32:15","Book","10.1145/3311957.3359509","","",,,,,3,0.50,1,5,6,"We demonstrate MIDST, a system we developed to support stigmergic coordination in data-science teams, that is, coordination supported by a shared work product. To improve coordination, the system supports modularization of an analysis as a workflow, distributed code development and sharing and tracking of task status through a web application.","https://dl.acm.org/doi/pdf/10.1145/3311957.3359509",""
3,"Kevin Crowston, J. Saltz, Niraj Sitaula","Evaluating MIDST, A System to Support Stigmergic Team Coordination",2021,"Proceedings of the ACM on Human-Computer Interaction","","https://www.semanticscholar.org/paper/0d9016aa4368cbc03c7bc7a543bbaa88c906e9db","",85,"2025-02-06 14:32:15","JournalArticle","10.1145/3449110","","",5,,1,24,3,0.75,1,3,4,"Data science teams working on a shared analysis face coordination problems such as dividing up the work to be done, monitoring performance and integrating the pieces. Research on distributed software development teams has raised the potential of stigmergic coordination, that is, coordination through a shared work product in place of explicit communication. The MIDST system was developed to support stigmergic coordination by making individual contributions to a shared work product visible, legible and combinable. In this paper, we present initial studies of a total of 40 student teams (24 using MIDST) that shows that teams that used MIDST did experience the intended system affordances to support their work, did seem to coordinate at least in part stigmergically and performed better on an assigned project.","",""
3,"H. MacGillivray","Data science, statistical investigations, team sport, and assessment",2019,"Teaching Statistics","","https://www.semanticscholar.org/paper/08c0d1f727936288a5bbe54af86d9a141b1a885b","",86,"2025-02-06 14:32:15","JournalArticle","10.1111/test.12189","0141-982X","",41,,1,2,3,0.50,3,1,6,"In recent years, the term data science has been used somuch it is a wonder it has not made it onto any shortlists of Oxford Dictionaries’ Word of the Year. Universities and, more recently, school authorities have been anxiously scrambling to set up programs and courses in data science. Business forums have seen discussions on the difference between data science and data analytics, while the stampede to define data science has seen a wordsmithing smorgasbord. Although it is a truism that the jobs of the future may not be able to be imagined today, the current furore over data science is important for many reasons across education levels, across disciplines, and across workplaces. It is important for statistics education, and the lessons from statistics education are important for data science. It is also an opportunity for statistics and statistics education to grasp and hold. Wearing a number of hats, both nationally and internationally, I have listened tomuch about data science over recent years. In October, wearingmy ISI (International Statistical Institute) presidential hat, I attended the second United Nations World Data Forum (UNWDF) in Dubai. Because the UNWDF is particularly focused on the UN SDG’s (Sustainable Development Goals), much is concerned with official statistics and data for development and citizen benefit, so that statistical literacy, sometimes called or confused with data literacy, also features. However, a session that included comments of particular relevance to education, both school and university, was “Data Scientists: What are they?” with speakers leading data science teams in large organizations across industry, business, and government, including communications, securities, information technologies, and official statistics. The UNWDF sessions tend to be discussion panels, often conducted in interview format, so I cannot refer you to papers or reports, but if you have a spare 75 minutes, the recorded session is at https://undataforum. org/WorldDataForum/sessions/ta6-08-data-scientist-what-are-they/. Here, I paraphrase a few comments highly relevant to education from my rapidly scribbled notes, with apologies to the speakers for extracting just a little from an extensive session: • Data science is everywhere and not new ○ A label for work being done for years ○ What is changed is recognition of what can be done and bringing this out of the back room. ○ Need to know what can and cannot be done with data.","",""
2,"Nils Kraut, Fabian Transchel","On the Application of SCRUM in Data Science Projects",2022,"2022 7th International Conference on Big Data Analytics (ICBDA)","","https://www.semanticscholar.org/paper/f9be2f17cbae76478901ef5d7fa199773c475a5b","",87,"2025-02-06 14:32:15","Conference","10.1109/ICBDA55095.2022.9760341","","",,,1,9,2,0.67,1,2,3,"The emerging discipline of Data Science poses several challenges for teams conducting projects in the field as notably, the majority of Data Science teams fail to deliver the expected outcomes. To improve the results, researchers tried to adapt agile project methodologies like Scrum for Data Science projects. Scrum in particular is often implemented due its success in software engineering. However, the basic Scrum framework has proven itself to be too strict for Data Science, due to frequent unpredictabilities of Data Science tasks. Consequently, adaptions were made to traditional Scrum to make it more suitable for the new challenges. This article discusses further adaptations and suggests that Scrum in itself is usable in Data Science, however, additional adaptations of the core concepts need to be envisioned.","",""
2,"Ilya Makarov, Olga Gerasimova, Pavel Sulimov, Ksenia Korovina, L. Zhukov","Analysis of Images, Social Networks and Texts",2018,"Lecture Notes in Computer Science","","https://www.semanticscholar.org/paper/dfc6395772dfe43bce84d8c60faab29f3804ad0c","",88,"2025-02-06 14:32:15","","10.1007/978-3-030-11027-7","0302-9743","",11179,,,,2,0.29,0,5,7,"","",""
2,"Kayla Robinson, C. Billman, Muktesh Masih, Kevin Rose, Xi Wang, K. Hundman","A Full-Stack Machine Learning Environment for Rapidly Evolving Industry Applications",2021,"2021 IEEE 8th International Conference on Data Science and Advanced Analytics (DSAA)","","https://www.semanticscholar.org/paper/b1d831ae4dd4ccd6415c28052fdb24b86a7c4800","",89,"2025-02-06 14:32:15","JournalArticle","10.1109/DSAA53316.2021.9564174","","",,,1,3,2,0.50,0,6,4,"Developing, deploying, and maintaining machine learning models is a key function of many data science teams. We describe a framework built by American Family Insurance to model the risk profiles of properties. Through empirical experiments, we demonstrate that our automated, end-to-end framework provides a rapid platform for experimentation and productionalization in a business environment.","",""
2,"Göktug Diker, Herwig Frühbauer, Edna Michelle Bisso Bi Mba","Development of a Digital ESP Performance Monitoring System Based on Artificial Intelligence",2021,"Day 3 Wed, November 17, 2021","","https://www.semanticscholar.org/paper/9f159d554bbc168ca0bbd86ef6defd0ac7ac094a","",90,"2025-02-06 14:32:15","JournalArticle","10.2118/207929-ms","","",,,,,2,0.50,1,3,4,"Wintershall Dea is developing together with partners a digital system to monitor and optimize electrical submersible pump (ESP) performance based on the data from Mittelplate oil field. This tool is using machine learning (ML) models which are fed by historic data and will notify engineers and operators when operating conditions are trending beyond the operating envelope, which enables an operator to mitigate upcoming performance problems. In addition to traditional engineering methods, such a system will capture knowledge by continuous improvement based on ML. With this approach the engineer has a system at hand to support the day-to-day work. Manual monitoring and on demand investigations are now backed up by an intelligent system which permanently monitors the equipment. In order to create such a system, a proof of concept (PoC) study has been initiated with industry partners and data scientists to evaluate historic events, which are used to train the ML-systems. This phase aims to better understand the capabilities of machine learning and data science in the subsurface domain as well as to build up trust for the engineers with such systems. The concept evaluation has shown that the intensive collaboration between engineers and data scientist is essential. A continuous and structured exchange between engineering and data science resulted in a mutual developed product, which fits the engineer's needs based on the technical capabilities and limits set by ML-models. To organize such a development, new project management elements like agile working methods, sprints and scrum methods were utilized. During the development Wintershall Dea has partnered with two organizations. One has a pure data science background and the other one was the data science team of the ESP manufacturer. After the PoC period the following conclusions can be derived: (1) data quality and format is key to success; (2) detailed knowledge of the equipment speeds up the development and the quality of the results; (3) high model accuracy requires a high number of events in the training dataset. The overall conclusion of this PoC is that the collaboration between engineers and data scientists, fostered by the agile project management toolkit and suitable datasets, leads to a successful development. Even when the limits of the ML-algorithms are hit, the model forecast, in combination with traditional engineering methods, adds significant value to the ESP performance. The novelty of such a system is that the production engineer will be supported by trusted ML-models and digital systems. This system in combination with the traditional engineering tools improves monitoring of the equipment and taking decisions leading to increased equipment performance.","",""
2,"Kerk F. Kee, A. Olshansky, Shan Xu","A Socio-Technical Framework for Measuring Organizational Capacity During Cyberinfrastructure Diffusion",2021,"2021 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/9bbf758a970d49202c4fadd6a9017a0d85806141","",91,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData52589.2021.9672004","","",,,2301,2305,2,0.50,1,3,4,"This paper presents a socio-technical framework for measuring organizational capacity for cyberinfrastructure (CI) implementation, adoption, and diffusion at the team’s level. CI implementation is an example of big data science project in data-intensive projects funded by the US National Science Foundation (NSF), providing a unique case for understanding big data science teams from an important field that is academic and scientific in nature. We argue that organizational capacity can be defined by the three dimensions of foundational technical expertise, daily social interactions, and enduring organizational qualities. We provide scale items for measuring these three dimensions, using a questionnaire in a self-reported and self-reflexive fashion. The overall average score and the individual composite scores of the three dimensions (and their sub-dimensions) can be used as feedback and capacity building activities as intervention strategies. Future research will statistically validate the framework using exploratory and confirmatory factor analyses.","",""
2,"A. McDavid, A. Corbett, J. Dutra, Andrew G. Straw, D. Topham, G. Pryhuber, M. Caserta, S. Gill, Kristin M. Scheible, J. Holden-Wiltse","Eight practices for data management to enable team data science",2020,"Journal of Clinical and Translational Science","","https://www.semanticscholar.org/paper/87f6158042fea0466a010e8015d725bc9c305f1d","",92,"2025-02-06 14:32:15","JournalArticle","10.1017/cts.2020.501","2059-8661","",5,,,,2,0.40,0,10,5,"Abstract Introduction: In clinical and translational research, data science is often and fortuitously integrated with data collection. This contrasts to the typical position of data scientists in other settings, where they are isolated from data collectors. Because of this, effective use of data science techniques to resolve translational questions requires innovation in the organization and management of these data. Methods: We propose an operational framework that respects this important difference in how research teams are organized. To maximize the accuracy and speed of the clinical and translational data science enterprise under this framework, we define a set of eight best practices for data management. Results: In our own work at the University of Rochester, we have strived to utilize these practices in a customized version of the open source LabKey platform for integrated data management and collaboration. We have applied this platform to cohorts that longitudinally track multidomain data from over 3000 subjects. Conclusions: We argue that this has made analytical datasets more readily available and lowered the bar to interdisciplinary collaboration, enabling a team-based data science that is unique to the clinical and translational setting.","https://www.cambridge.org/core/services/aop-cambridge-core/content/view/E50F7A75DEDC701C3FEC1819D0DB314D/S2059866120005014a.pdf/div-class-title-eight-practices-for-data-management-to-enable-team-data-science-div.pdf",""
2,"Aayushi Roy, Deepthi Raghunandan, Niklas Elmqvist, Leilani Battle","How I Met Your Data Science Team: A Tale of Effective Communication",2023,"2023 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)","","https://www.semanticscholar.org/paper/86fd9db66875268d9d39bbb0096c22a9aef1a5c4","",93,"2025-02-06 14:32:15","JournalArticle","10.1109/VL-HCC57772.2023.00032","","",,,199,208,2,1.00,1,4,2,"Deriving actionable insights from data requires expertise in both data science as well as the specific application domain. This need for domain-specific knowledge often necessitates engaging an interdisciplinary team rather than an individual for most realistic data science problems in domains such as finance, biology, or drug discovery. This, in turn, requires effective collaboration between team members. This paper seeks to understand common themes in how such multi-disciplinary teams communicate to accomplish their analytical goals. We conduct an interview study with 15 professional data scientists working in small to large organizations in fields ranging from bioinformatics to accounting. Communication between individuals in these teams depends on their team structure and expertise. Data scientists specifically adapt their tools to communicate with team members with different types of domain knowledge. We discuss the strengths and weaknesses of these approaches for supporting communication in multi-disciplinary environments.","",""
2,"J. Saltz, Kevin Crowston, Robert Heckman, Yatish Hegde","MIDST: an enhanced development environment that improves the maintainability of a data science analysis",2021,"International Journal of Information Systems and Project Management","","https://www.semanticscholar.org/paper/532470ea83bd7c46d56e83b53eeff73b5904729c","",94,"2025-02-06 14:32:15","Review","10.12821/ijispm080301","2182-7796","",,,,,2,0.50,1,4,4,"With the increasing ability to generate actionable insight from data, the field of data science has seen significant growth. As more teams develop data science solutions, the analytical code they develop will need to be enhanced in the future, by an existing or a new team member. Thus, the importance of being able to easily maintain and enhance the code required for an analysis will increase. However, to date, there has been minimal research on the maintainability of an analysis done by a data science team. To help address this gap, data science maintainability was explored by (1) creating a data science maintainability model, (2) creating a new tool, called MIDST (Modular Interactive Data Science Tool), that aims to improve data science maintainability, and then (3) conducting a mixed method experiment to evaluate MIDST. The new tool aims to improve the ability of a team member to update and rerun an existing data science analysis by providing a visual data flow view of the analysis within an integrated code and computational environment. Via an analysis of the quantitative and qualitative survey results, the experiment found that MIDST does help improve the maintainability of an analysis. Thus, this research demonstrates the importance of enhanced tools tohelp improve the maintainability of data science projects.","https://revistas.uminho.pt/index.php/ijispm/article/download/3557/3590",""
2,"Kerk F. Kee, A. Olshansky, Shan Xu","An Organizational Framework of Institutional Stakeholder Engagement for Capacity to Support Big Data Science Teams Towards Cyberinfrastructure Diffusion",2022,"2022 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/3c99d4749c050d42cae7a7b7eee0aabf53213696","",95,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData55660.2022.10020213","","",,,2655,2659,2,0.67,1,3,3,"This paper presents an organizational framework for measuring institutional stakeholder engagement for big data science teams toward cyberinfrastructure (CI) diffusion. CI projects are an academic example of big data science projects in data-intensive research efforts. CI projects provide a unique case for understanding big data science teams from an important context, which is scientific and academic in nature. We argue that the capacity of a big data science team needs to take into consideration several institutional stakeholder engagement factors, such as having a pro-CI administration, institutional CI investments, campus CI tech support, and a non-traditional research culture. We proposed composite scale items designed to quantitatively measure these four dimensions, using a self-reported questionnaire. The overall mean score and the four individual composite scores of the main dimensions can be used as reflexive feedback and assessment for teams about the macro institutional environment in which they are embedded. Future research should statistically validate the framework via (exploratory and confirmatory) factor analyses.","",""
2,"Silu Huang, Liqi Xu, Jialin Liu, Aaron J. Elmore, Aditya G. Parameswaran","ORPHEUS\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\varvec{\textsc {Orpheus}}$$\end{document}DB: bolt-on versionin",2019,"The VLDB Journal","","https://www.semanticscholar.org/paper/391f56a39fce14b6ba03d65cf51a85dda489ff67","",96,"2025-02-06 14:32:15","JournalArticle","10.1007/s00778-019-00594-5","1066-8888","",29,,509,538,2,0.33,0,5,6,"","",""
2,"David S. Batista, Matti Lyra","COMTRAVO-DS team at GermEval 2019 Task 1 on Hierarchical Classification of Blurbs",2019,"Conference on Natural Language Processing","","https://www.semanticscholar.org/paper/2a7c2317a09b9d364d4bb1c0f36921e1d658e204","",97,"2025-02-06 14:32:15","JournalArticle","","","",,,,,2,0.33,1,2,6,"We present two systems developed by the Comtravo Data Science team for the Ger-mEval’19 Task 1 on hierarchical classiﬁcation of blurbs. The challenge is a document clas-siﬁcation task where the hierarchical structure of each document needs to be captured. Our systems achieved the 13th place out of 19 sub-missions for Sub-Task A and the 11th place out of 19 submissions for Sub-Task B. We describe in detail these two systems pointing out the advantages and disadvantages of each as well as laying out future research directions.","",""
2,"Desalegn Temesgen Delelegn","Non-Destructive Evaluation for Composite Material",2018,"","","https://www.semanticscholar.org/paper/29d2cfa4e15e095603a2a76f8375a6a07eed27c3","",98,"2025-02-06 14:32:15","","10.25777/VC78-T122","","",,,,,2,0.29,2,1,7,"NON-DESTRUCTIVE EVALUATION FOR COMPOSITE MATERIAL Desalegn Temesgen Delelegn Old Dominion University, 2018 Director: Dr. Jiang Li The Nondestructive Evaluation Sciences Branch (NESB) at the National Aeronautics and Space Administration (NASA) Langley Research Center (LaRC) has conducted impact damage experiments over the past few years with the goal of understanding structural defects in composite materials. The Data Science Team within the NASA LaRC Office of the Chief Information Officer (OCIO) has been working with the Non-Destructive Evaluation (NDE) subject matter experts (SMEs), Dr. Cheryl Rose, from the Structural Mechanics & Concepts Branch and Dr. William Winfree, from the Research Directorate, to develop computer vision solutions using digital image processing and machine learning techniques that can help identify the structural defects in composite materials. The research focused on developing an autonomous Non-Destructive Evaluation system which detects, identifies, and characterizes crack and delamination in composite materials from computed tomography (CT scans) images. The identification and visualization of cracking and delamination will allow researchers to use volumetric models to better understand the propagation of damage in materials, leading to design optimizations that will prevent catastrophic failure.","",""
2,"M. Lyndon, Atipong Pathanasethpong, M. Henning, Yan Chen, L. Celi","Measuring the learning outcomes of datathons",2022,"BMJ Innovations","","https://www.semanticscholar.org/paper/28330b0025baf7cfe80a6daa3496308f7578cd70","",99,"2025-02-06 14:32:15","Review","10.1136/bmjinnov-2021-000747","2055-642X","",8,,72,77,2,0.67,0,5,3,"Purpose Healthcare datathons are events in which cross-disciplinary teams leverage data science methodologies to address clinical questions using large datasets. The aim of this research was to evaluate participant satisfaction and learning outcomes of datathons. Methods A multicentre cross-sectional study was performed using survey data from datathons conducted in Sydney, Australia (April 2018) n=98, Singapore (July 2018) n=169 and Beijing, China (December 2018) n=200. Participants (n=467) completed an online confidential survey at the end of the datathons which contained the Affective Learning Scale, and measures of event satisfaction, perceived knowledge gain, as well as free text responses, and participants’ demographic background. Data analysis used descriptive statistics and multivariate analysis of variance (MANOVA). Thematic analysis was performed on the text responses. Results The overall response rate was 64% (301/467). Participants were mostly male (70%); 50.2% were health professionals and 49.8% were data scientists. Based on the Affective Learning Scale (7-point Likert type scale), participants reported a positive learning experience (M = 5.93, SD = 1.21), satisfaction for content and subject matter of the datathon (M = 5.81, SD = 1.17), applying behaviours (M = 4.71, SD =2.02), instruction from mentors (M = 6.01, SD = 1.18), and intention to participate in future datathons (M = 6.03, SD = 1.23). The MANOVA showed significant differences between health professionals and data scientists in perceived knowledge gain from the datathons. Themes from text responses emerged: (1) cross-disciplinary collaboration; (2) improving healthcare using data science and (3) preparations for big data analytics. Conclusions Datathons provide a satisfying learning experience for participants and promote affective learning, cross-disciplinary collaboration and knowledge gain in health data science.","",""
2,"Alison Callahan, Duncan McElfresh, Juan M. Banda, Gabrielle Bunney, Danton Char, Jonathan Chen, Conor K. Corbin, Debadutta Dash, Norman L. Downing, Sneha S. Jain, N. Kotecha, Jonathan Masterson, Michelle M. Mello, Keith Morse, Srikar Nallan, Abby Pandya, Anurang Revri, Aditya Sharma, Christopher Sharp, Rahul Thapa, Michael Wornow, Alaa Youssef, Michael A. Pfeffer, Nigam H. Shah","Standing on FURM ground - A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems",2024,"ArXiv","","https://www.semanticscholar.org/paper/04c973e91e47bf39444868493aeae9a2d9160261","",100,"2025-02-06 14:32:15","JournalArticle","10.48550/arXiv.2403.07911","2331-8422","",,,,,2,2.00,0,24,1,"The impact of using artificial intelligence (AI) to guide patient care or operational processes is an interplay of the AI model's output, the decision-making protocol based on that output, and the capacity of the stakeholders involved to take the necessary subsequent action. Estimating the effects of this interplay before deployment, and studying it in real time afterwards, are essential to bridge the chasm between AI model development and achievable benefit. To accomplish this, the Data Science team at Stanford Health Care has developed a Testing and Evaluation (T&E) mechanism to identify fair, useful and reliable AI models (FURM) by conducting an ethical review to identify potential value mismatches, simulations to estimate usefulness, financial projections to assess sustainability, as well as analyses to determine IT feasibility, design a deployment strategy, and recommend a prospective monitoring and evaluation plan. We report on FURM assessments done to evaluate six AI guided solutions for potential adoption, spanning clinical and operational settings, each with the potential to impact from several dozen to tens of thousands of patients each year. We describe the assessment process, summarize the six assessments, and share our framework to enable others to conduct similar assessments. Of the six solutions we assessed, two have moved into a planning and implementation phase. Our novel contributions - usefulness estimates by simulation, financial projections to quantify sustainability, and a process to do ethical assessments - as well as their underlying methods and open source tools, are available for other healthcare systems to conduct actionable evaluations of candidate AI solutions.","",""
1,"J. J. M. Guervós","Agile (data) science: a (draft) manifesto",2021,"ArXiv","","https://www.semanticscholar.org/paper/fc0a77ba4c0d6fd1ecca78bcb30f05a9257ff6ab","",101,"2025-02-06 14:32:15","JournalArticle","","2331-8422","",,,,,1,0.25,1,1,4,"Science has a data management problem, as well as a project management problem. While industrial-grade data science teams have embraced the agile mindset, and adopted or created all kind of tools to create reproducible workflows, academia-based science is still (mostly) mired in a mindset that is focused on a single final product (a paper), without focusing on incremental improvement, on any specific problem or customer, or, paying any attention reproducibility. In this report we argue towards the adoption of the agile mindset and agile data science tools in academia, to make a more responsible, and over all, reproducible science.","",""
1,"Dan Wu, Siyu Lv, Hao Xu","An analysis on competency of human‐centered data science employment",2020,"Proceedings of the Association for Information Science and Technology","","https://www.semanticscholar.org/paper/eae49816038ba5cb0ae867290def44733fdf4c11","",102,"2025-02-06 14:32:15","JournalArticle","10.1002/pra2.219","","",57,,,,1,0.20,0,3,5,"The rapid rise of data science has brought about the problem of talent gaps and concerns about employment competency development. This paper performed a study on the analysis of data science employment market in the information science context with open data from online recruitment website. In addition to basic qualitative analysis and descriptive statistical summarization of advertisement characteristics, it mainly established a competency framework of data science workforce with the method of content analysis. The objective is through market needs to provide guidance for institutions planning for or revising a major in data science, help bridge the gap between the high demand and low supply of data scientists and enable existing data science teams to operate more efficiently. Our working results indicate that the market is looking for ways in which humans can integrate their roles into data science, and these methods depend on the spread of how to use human‐centered data science and its benefits, the operating mechanism of which is explained by our proposed model.","",""
1,"G. Kumar, G. Prakash, P. Karthik","Data Science based Secure Healthcare Framework for COVID-19",2020,"International journal of engineering research and technology","","https://www.semanticscholar.org/paper/d9c06fcd7e4c6e98737e5f7d41dec301fad2be8e","",103,"2025-02-06 14:32:15","JournalArticle","","","",8,,,,1,0.20,0,3,5," Abstract — this paper presents a brief introduction to data science role in healthcare applications especially for COVID-19. The corona virus or Covid-19 is a communicable disease a large family of viruses that causes illnesses ranging from the common cold to acute respiratory syndromes, but the current virus is a novel strain not seen before. Common symptoms of the novel corona virus strain include respiratory symptoms such as fever, cough, and shortness of breath, according to the WHO. The WHO has declared the corona virus epidemic as a global health emergency. When clinical and community sectors work synergistically, they can improve care and support patients better than either of these sectors could do alone. It is observed that the use of data science techniques is continuously assisting in managing world is Fighting Corona Virus. The proposed research is more effective disease diagnosis using big data analysis, artificial intelligent, machine learning and virtual reality.","",""
1,"A. Wilhelm, Susan Vanderplas","Visual Narratives of the Covid-19 pandemic",2022,"J. Data Sci. Stat. Vis.","","https://www.semanticscholar.org/paper/d2dd3c230aa60f2ac7fd227c1074a6281bc1d1cf","",104,"2025-02-06 14:32:15","JournalArticle","10.52933/jdssv.v2i7.64","2773-0689","",2,,84,113,1,0.33,1,2,3,"Covid-19 has sparked a worldwide interest in understanding the dynamic evo- lution of a pandemic and tracking the effectiveness of preventive measures and rules. For this reason, numerous media and research groups have produced com- prehensive data visualisations to illustrate the relevant trends and figures. In this paper, we will look at a selection of Covid 19 data visualisations to evaluate and discuss the currently established visualisation tools in terms of their ability to provide a communication channel both within the data science team and between data analysts, domain experts and a general interested audience. Although there is no set catalogue of evaluation criteria for data visualisations, we will try to give an overview of the different core aspects of visualisation evaluation and their competing principles.","",""
1,"W. Monteiro, Marcio Leandro do Prado, G. Reynoso-Meza","Leveraging Data Scientists and Business Expectations During the COVID-19 Pandemic",2021,"2021 IEEE/ACM 8th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)","","https://www.semanticscholar.org/paper/cba0e4739340892fa3e68c6b769745adde187221","",105,"2025-02-06 14:32:15","JournalArticle","10.1109/SER-IP52554.2021.00008","","",,,2,9,1,0.25,0,3,4,"The COVID-19 pandemic presented itself as a challenge for separate societal sectors. On the information technology (IT) standpoint, it does include the maintenance of the infrastructure required to hold collaborative activities that went to happen online; the implementation of projects in a scenario of uncertainty; and keep the software engineering and information security best practices in place. This article presents the context of a data science team organized as a skunk works group composed of professionals with experience in both the industry and academia, located in an IT department working with a team of seasoned data engineers. At the time the pandemic started, the relatively new data science team was positioning itself as a Center of Excellence in Advanced Analytics. With the pandemic, it had to keep up with the expectations from the stakeholders; manage current and upcoming data science projects within the methodology practiced in IT; and maintain a high level in the quality of service delivered. This article discusses how did the COVID-19 pandemic affected the team productivity and its practices as well as the lessons learned with it.","https://arxiv.org/pdf/2103.05425",""
1,"Tejashri A. Patil, A. Bhavsar","Data Science Team Roles and Need of Data Science: A Review of Different Cases",2020,"Lecture Notes on Data Engineering and Communications Technologies","","https://www.semanticscholar.org/paper/bae7832479e0b5d3c6c66e6aa390ca9027bd8c3a","",106,"2025-02-06 14:32:15","Review","10.1007/978-981-15-4474-3_2","","",,,,,1,0.20,1,2,5,"","",""
1,"Yael Grushka-Cockayne, Kenneth C. Lichtendahl, Bert De reyck, I. Fragkos","A/B Testing at Vungle",2018,"Darden Case: Business Communications (Topic)","","https://www.semanticscholar.org/paper/b747bdeea0036e3e9664f4b3791c1801f7288716","",107,"2025-02-06 14:32:15","JournalArticle","10.2139/ssrn.3213752","1556-5068","",,,,,1,0.14,0,4,7,"Two recently graduated MBA students are tasked with developing an ad-serving learning algorithm for a mobile ad-serving company. The case illustrates the way in which hypotheses can be tested in an A/B format or ""horse race"" in order to establish customer preferences and superior profitability. The case was written for a course elective covering hypothesis testing. Excerpt UVA-QA-0821 Rev. Mar. 7, 2017 A/B Testing at Vungle Andrew Kritzer and Hammond Guerin stared at the screen and then at each other. It was June 30, 2014—six weeks since they had graduated from the Darden School of Business. The ad-serving algorithm Kritzer and Guerin had spent six months developing for Vungle, a mobile advertising company, seemed to be outperforming the company's current algorithm. But they did not want to start celebrating too soon. Could their algorithm really deliver the type of improvement they had promised Vungle's CEO? Would install rates of advertised apps really increase? Would Vungle see an increase in ad-serving efficiency as a result? Neither Kritzer nor Guerin could afford for the algorithm to disappoint. Now that he had graduated, Kritzer was headed to LinkedIn, having left a legend among MBA students for his appreciation of data science, tech, and media and raising expectations for what Darden students knew and could learn about data science, analytics, and the ever-growing world of big data. His work on the Vungle project during his second year had received a lot of attention, and he was looking forward to having the results support the effort. Guerin's data science capabilities were also legendary among his MBA peers. He won every school forecasting competition, and his data mining algorithms even beat those of the professional consultants who did classroom visits. Late in his second year, Guerin decided to turn down a generous offer from a well-known consulting firm in favor of an offer from Vungle for an annual salary of $ 100,000 and stock options to serve as the head of Vungle's brand new data science team out in the company's San Francisco headquarters. The job was a dream for the computer scientist turned MBA. He and his wife were already house hunting in the Bay Area, looking for the right place to raise their baby daughter. . . .","",""
1,"Raechel Walker, Sophia Brady, Olivia Dias, Adriana Castillo, K. Asfaw, Elijah Johnson, Matt Taylor, Cynthia Breazeal","Unveiling Voices: Boston Students' Data Activism Journey with Community Catalysts",2024,"2024 Black Issues in Computing Education (BICE)","","https://www.semanticscholar.org/paper/ae958b6b85c4593d99003a9b067dbd2537502c5b","",108,"2025-02-06 14:32:15","Review","10.1109/BICE60192.2024.00009","","",,,1,7,1,1.00,0,8,1,"A noticeable gap exists in the availability of computing curricula tailored to empower African American students to apply their computing skills for the betterment of their communities. This research applies “liberatory computing” as a way to empower African American students in addressing embedded racism through computing. An exemplar of this liberatory computing approach is our curriculum on data activism, which uses data science to confront and mitigate systemic oppression. The study engaged 24 high school students of African American descent, who partnered with community organizations in the Greater Boston area for a range of data activism initiatives. These projects encompassed data analysis, geospatial analysis, qualitative analysis, surveys, interviews, artistic expression, and the incorporation of community perspectives. The organizers intend to use the students' projects for advocacy purposes, such as advocating for policies addressing flooding in African American and low-income Boston communities using data visualizations. The student surveys revealed heightened awareness of data science's role in combating racism and enhanced proficiency in promoting racial justice. Interviews with the students revealed that mitigating systemic oppression through their data activism projects with community organizers was a pivotal aspect that motivated them to persist in integrating data activism into their future pursuits. The implications of this research demonstrate how African American students can be empowered to utilize data science in order to catalyze societal transformation. This is achieved by fostering opportunities for them to apply their data science skills to tangible real-life issues through collaboration with community organizations addressing systemic challenges.","",""
1,"Doug Rose","Avoiding Pitfalls in Asking Great Questions",2016,"","","https://www.semanticscholar.org/paper/833242c359594a3b67fe1e3584f198d4dfaa9071","",109,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_18","","",,,185,188,1,0.11,1,1,9,"","",""
1,"J. Saltz","Nine Questions to Evaluate a Data Science Team’s Process: Exploring a Big Data Science Team Process Evaluation Framework Via a Delphi Study",2022,"2022 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/738bd995ec806f1bc1303144950ceb3053e1327f","",110,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData55660.2022.10020499","","",,,2667,2672,1,0.33,1,1,3,"While the lack of an effective team process is often noted as one of the key drivers for data science project inefficiencies and failures, there has been minimal research on how to evaluate a data science team’s process. Without an evaluation framework, it is difficult for data science teams to understand their team process strengths and weaknesses. To help address this challenge, this exploratory research, via a Delpha study, identified nine key questions a data science team could answer to help evaluate their process. In short, the study identified questions evaluating the team’s communication (within the team and with stakeholders). The study also identified team process questions (e.g., the use of iterations, life cycles and a prioritization process for potential tasks). Future research could explore how data science teams can best improve their process by leveraging and refining these questions as well as defining an overall data science project management evaluation framework.","",""
1,"M. E. Saban","Data science for the oil and gas industry in the Arab region",2021,"Communications of the ACM","","https://www.semanticscholar.org/paper/71f80bc7d36e9d19401705ddc455ec5b103393a0","",111,"2025-02-06 14:32:15","JournalArticle","10.1145/3447721","0001-0782","",64,,54,56,1,0.25,1,1,4,"54 COMMUNICATIONS OF THE ACM | APRIL 2021 | VOL. 64 | NO. 4 P H O T O B Y D U L A A Z /S H U T T E R S T O C K .C O M demics and practitioners to tackle challenges within O&G using data science technologies. The Arab region is well suited for building data science teams serving a global market specially for the O&G industry: ˲ There is recent interest from governments in the region to offer data science-related programs and degrees. ˲ The region can supply a talented, well-trained workforce at a relatively lower cost. ˲ The O&G industry is key in the region; hence data is readily available in lenge is twofold: create opportunities for juniors to grow technically by working on challenging problems of global nature, and complement juniors by experienced returning expats to the region. We next detail some of the technical challenges that Raisa Energy faces and the novel approaches it uses in solving them that resulted in several academic publications and U.S. patents. Well production forecasting is a time series forecasting problem of an O&G well production. Well features include geological large quantity. Such massive data is the key behind any modern artificial intelligence system. For example, Raisa Energy, a U.S.-based O&G inves tment company, has its entire software and data science teams in Egypt building capacity in the important energy domain offering a unique edge for the region. Though junior talent is generally available, there remains a challenge in easily finding senior talent as professionals typically move early into managerial roles for career growth. Our answer to this chalO IL AND GAS (O&G) sources will still supply around 50% of the global energy demand by 2040. In this article, we make the case for why the Arab region is well positioned for building world-class data science teams to fill the supply shortage of data professionals, especially in the O&G field critical to region’s economy. This article presents challenges facing O&G industry players, such as governments, regulatory bodies, operators, and investors, and shows how Raisa Energy (with its Egyptbased data science team) is efficiently and effectively solving these challenges. Such challenges aim at assessing the economic viability of an O&G asset that depends on several factors (as shown in the accompanying figure) such as estimating well production, O&G prices, and risks associated with inputs uncertainty. It is worth emphasizing that the challenges presented here are global in nature and yet are tackled with a team fully formed from the region working at a worldclass research and development level. We hope this article will motivate aca-","",""
1,"Daniel James Kershaw, R. Koeling, Stephan Bourgeois, Antonio Trenta, Harriet J. Muncey","Fairness in Reviewer Recommendations at Elsevier",2021,"Proceedings of the 15th ACM Conference on Recommender Systems","","https://www.semanticscholar.org/paper/64bbb4c6ac31b0a136ce392521b9ced29e413121","",112,"2025-02-06 14:32:15","Book","10.1145/3460231.3474613","","",,,,,1,0.25,0,5,4,"At Elsevier we aim to help scientists further their research. On the one hand, by offering a platform for publishing ground-breaking research, and on the other by helping researchers discover relevant content to assist their work. In our team, Editorial Data Science, we support the former goal by providing tools to help editors in the decisions that they make, from finding reviewers to recommending transfers for manuscripts to more appropriate journals. To improve the workflows for publishing research and help editors in finding relevant reviewers we developed a reviewer recommender. The reviewer recommender will, based on a submitted manuscript, recommend reviewers that optimise the fit between the manuscript, the journal, and the reviewer themselves. To achieve this, the reviewer recommender is built on top of the three principles of quality data, expert knowledge, and experimentation. We leverage data from across Elsevier, ranging from Scopus profiles which includes publication histories and academic impact data, to data from our","",""
1,"Paul Duncan, N. Smith, M. Romanchikova","Metrology for data in life sciences, healthcare and pharmaceutical manufacturing: Case studies from the National Physical Laboratory",2023,"Acta IMEKO","","https://www.semanticscholar.org/paper/4ba8b2086b77e1982b8bb7f5a434c7604d2730a6","",113,"2025-02-06 14:32:15","JournalArticle","10.21014/actaimeko.v12i1.1406","0237-028X","",,,,,1,0.50,0,3,2,"Data metrology, i.e., the evaluation of data quality and its fitness-for-purpose, is an inherent part of many disciplines including physics and engineering. In other domains such as life sciences, medicine, and pharmaceutical manufacturing these tools are often added as an afterthought, if considered at all. The use of data-driven decision making and the advent of machine learning in these industries has created an urgent demand for harmonised, high-quality, content rich, and instantly available datasets across domains. The Findable, Accessible, Interoperable, Reproducible principles are designed to improve overall quality of research data. However, these principles alone do not guarantee that data is fit-for-purpose. Issues such as missing data and metadata, insufficient knowledge of measurement conditions or data provenance are well known and can be aided by applying metrological concepts to data preparation to increase confidence. This work conducted by National Physical Laboratory Data Science team showcases life sciences and healthcare projects where data metrology has been used to improve data quality.","https://acta.imeko.org/index.php/acta-imeko/article/download/1406/2785",""
1,"Jacob D. Abernethy, Cyrus Anderson, Alex Chojnacki, Chengyu Dai, J. Dryden, Eric M. Schwartz, W. Shen, Jonathan C. Stroud, Laura Burdick, Sheng Yang, Daniel T. Zhang","Data Science in Service of Performing Arts: Applying Machine Learning to Predicting Audience Preferences",2016,"ArXiv","","https://www.semanticscholar.org/paper/4a04bc59738f54c8494a5a5a2f9cf2c8558b8790","",114,"2025-02-06 14:32:15","JournalArticle","","2331-8422","",,,,,1,0.11,0,11,9,"Performing arts organizations aim to enrich their communities through the arts. To do this, they strive to match their performance offerings to the taste of those communities. Success relies on understanding audience preference and predicting their behavior. Similar to most e-commerce or digital entertainment firms, arts presenters need to recommend the right performance to the right customer at the right time. As part of the Michigan Data Science Team (MDST), we partnered with the University Musical Society (UMS), a non-profit performing arts presenter housed in the University of Michigan, Ann Arbor. We are providing UMS with analysis and business intelligence, utilizing historical individual-level sales data. We built a recommendation system based on collaborative filtering, gaining insights into the artistic preferences of customers, along with the similarities between performances. To better understand audience behavior, we used statistical methods from customer-base analysis. We characterized customer heterogeneity via segmentation, and we modeled customer cohorts to understand and predict ticket purchasing patterns. Finally, we combined statistical modeling with natural language processing (NLP) to explore the impact of wording in program descriptions. These ongoing efforts provide a platform to launch targeted marketing campaigns, helping UMS carry out its mission by allocating its resources more efficiently. Celebrating its 138th season, UMS is a 2014 recipient of the National Medal of Arts, and it continues to enrich communities by connecting world-renowned artists with diverse audiences, especially students in their formative years. We aim to contribute to that mission through data science and customer analytics.","",""
1,"Jakub Zavrel, A. Grotov, Jonathan Mitnik","Building a Platform for Ensemble-based Personalized Research Literature Recommendations for AI and Data Science at Zeta Alpha",2021,"Proceedings of the 15th ACM Conference on Recommender Systems","","https://www.semanticscholar.org/paper/4909fedf1811b0dcb16d37aa93cf448a699be0dc","",115,"2025-02-06 14:32:15","Book","10.1145/3460231.3474619","","",,,,,1,0.25,0,3,4,"1 EXTENDED ABSTRACT When as busy AI researchers we try to stay up-to-date in our own field of study, where hundreds of new papers are being published every day, we increasingly rely on automated recommendation systems to help us allocate our scarce reading time to the most relevant new work. At the same time we are also interested in discovering interesting and impactful new work outside of our direct area of expertise. Zeta Alpha is a new Scientific Literature Recommendation platform specialized for AI and Data Science teams, that aims to make it easy to discover, organize, and share knowledge, and to stay upto-date. At the time of submission, the platform is operational and already has a small and growing active user base. Based on our user research, we have come to a number of design principles which differ from existing systems in this area.","",""
1,"Jesse Anderson","The Data Science Team",2020,"","","https://www.semanticscholar.org/paper/3bc8f5e8c0348853778346c3e328b3636012082b","",116,"2025-02-06 14:32:15","","10.1007/978-1-4842-6228-3_3","","",,,29,41,1,0.20,1,1,5,"","",""
1,"Panayu Keelawat","NBGuru: Generating Explorable Data Science Flowcharts to Facilitate Asynchronous Communication in Interdisciplinary Data Science Teams",2023,"Computer Supported Cooperative Work and Social Computing","","https://www.semanticscholar.org/paper/339255edbf9c0641fa1df573dfb7ca330aa14da2","",117,"2025-02-06 14:32:15","JournalArticle","10.1145/3584931.3607020","","",,,,,1,0.50,1,1,2,"Data scientists typically work with domain experts in a Data Science (DS) project, resulting in knowledge gaps between roles. Communication holds an immense and difficult workload due to the complicated content, limited meeting time, vast audience backgrounds, etc. Thus, it is almost impossible to build a common ground within the team. Taking a step back, flowcharts and program descriptions have shown to help programmers learn algorithms. However, drawing a flowchart or writing a description takes time and effort. The novel AI-powered search engines can generate elaborate grounded responses with citations. It is then possible to generate flowcharts with text descriptions from code. Therefore, we studied 92 DS flowcharts and 173 code descriptions from top-voted Kaggle notebooks. We propose NBGuru, a flowchart-based communication tool. Users can explore computation steps asynchronously with generated texts and citations. Furthermore, we also discuss the possibility of AI in other collaborative roles.","https://dl.acm.org/doi/pdf/10.1145/3584931.3607020",""
1,"Doug Rose","Starting the Work",2016,"","","https://www.semanticscholar.org/paper/3379d6f91f7502e2751f52a4697a7b8a814c5340","",118,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_8","","",,,67,75,1,0.11,1,1,9,"","",""
1,"Antonio Duarte Santos","An Essay on How Data Science Can Strengthen Business",2023,"Studies of Applied Economics","","https://www.semanticscholar.org/paper/2e206eedb3a775012499e4d3c1cd791bef733837","",119,"2025-02-06 14:32:15","JournalArticle","10.25115/sae.v41i1.9158","","",,,,,1,0.50,1,1,2,"Data science combines several extensions, including, e.g., statistics, scientific methods, artificial intelligence (AI) and data analysis to extract value from raw data. Analytical applications and data scientists can then verify and defer the results to discover patterns and trends. In this way, they allow business leaders to gain enlightened knowledge about the market. Companies have kept a wealth of data with them. As modern technology allowed for the creation and storage of ever-increasing amounts of information, data volumes popped. The wealth of data collected and stored by these technologies can bring regenerative benefits to organizations and societies around the world, but only if they can interpret it. That's where data science comes in. So, the applied economics refers to the application of economic theory and analysis. In this article we intend to present several software that are available for the application of economic analysis. Analysis can be performed on any type of data and is a way of looking at raw data and find useful information. There are several technologies available for economic analysis, with more or less characteristics, some of which are not only intended for this single purpose, and cover a wider spectrum of functionalities. Some of the technologies we will use are, e.g., Rstudio, SPSS, Statis and SAS/Stata. These are very common technologies when talking about economic or business analysis. The intention is to demonstrate how each of these software analyse the data and subsequently the interpretations that we can draw from that scrutiny. Organizations are using data science teams to turn data into a competitive advantage by refining products and services and cost-effective solutions. We will use some different algorithms to verify how they are processed by the different technologies, namely we will use metrics such as maximum, minimum, covariance, standard deviation, average and multicollinearity and variance, even the use of types of regression models.","https://repositorio.ual.pt/bitstream/11144/6334/1/MONOGRAFIA_9158-Article%20Text-32358-1-10-20230228.pdf",""
1,"B. D. Reyck, I. Fragkos, Casey Lichtendahl, Andrew Kritzer","Improves Monetization Using Big Data Analytics",2017,"","","https://www.semanticscholar.org/paper/27ac4020d50bde007cfb654e9ef59cc3a513b55f","",120,"2025-02-06 14:32:15","","","","",,,,,1,0.13,0,4,8,"Vungle Inc. Improves Monetization Using Big Data Analytics Bert De Reyck UCL School of Management, University College London, London, United Kingdom, bdereyck@ucl.ac.uk Ioannis Fragkos Department of Technology and Operations Management, Rotterdam School of Management, Rotterdam, The Netherlands, fragkos@rsm.nl Yael Grushka-Cockayne, Casey Lichtendahl Darden School of Business, University of Virginia, Charlottesville, Virginia 22903, {grushkay@darden.virginia.edu, lichtendahlc@darden.virginia.edu} Hammond Guerin Data Science Team, Vungle Inc., San Francisco, California 94107, hammond.guerin@vungle.com Andrew Kritzer BookMD, Los Angeles, California 90081, akritzer@gmail.com","",""
1,"Leila Etaati","Data Science Virtual Machine and AI Frameworks",2019,"Machine Learning with Microsoft Technologies","","https://www.semanticscholar.org/paper/23de77b96e40c72f9c0ec5d7a4f88b96fa4fde1f","",121,"2025-02-06 14:32:15","Review","10.1007/978-1-4842-3658-1_16","","",,,,,1,0.17,1,1,6,"","",""
1,"Doug Rose","Applying Statistical Analysis",2016,"","","https://www.semanticscholar.org/paper/0ec21aec8402630f23c95e2c8d2c7709480a0ece","",122,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_4","","",,,27,38,1,0.11,1,1,9,"","",""
1,"W. Branch-Elliman, David B Banach, L. J. Batshon, G. Dumyati, Sarah Haessler, Vincent P Hsu, Robin L P Jump, Anurag N. Malani, Trini A Mathew, Rekha K Murthy, S. Pergam, Erica S. Shenoy, David J. Weber","SHEA position statement on pandemic preparedness for policymakers: pandemic data collection, maintenance, and release.",2024,"Infection control and hospital epidemiology","","https://www.semanticscholar.org/paper/06866be52f8dd6d90b524001083d38fa2b983198","",123,"2025-02-06 14:32:15","JournalArticle","10.1017/ice.2024.65","0899-823X","",,,1,5,1,1.00,0,13,1,"The Society for Healthcare Epidemiology in America (SHEA) strongly supports modernization of data collection processes and the creation of publicly available data repositories that include a wide variety of data elements and mechanisms for securely storing both cleaned and uncleaned data sets that can be curated as clinical and research needs arise. These elements can be used for clinical research and quality monitoring and to evaluate the impacts of different policies on different outcomes. Achieving these goals will require dedicated, sustained and long-term funding to support data science teams and the creation of central data repositories that include data sets that can be ""linked"" via a variety of different mechanisms and also data sets that include institutional and state and local policies and procedures. A team-based approach to data science is strongly encouraged and supported to achieve the goal of a sustainable, adaptable national shared data resource.","",""
1,"A. Busson, Rennan Gaio, Rafael H. Rocha, Francisco Evangelista, Bruno Rizzi, Luan Carvalho, Rafael Miceli, Marcos Rabaioli, David Favaro","Saturn Platform: Foundation Model Operations and Generative AI for Financial Services",2023,"ArXiv","","https://www.semanticscholar.org/paper/00a296be7fb0ed7b2c3dad04cb5958010c948b3c","",124,"2025-02-06 14:32:15","JournalArticle","10.5753/webmedia_estendido.2023.234354","","",,,,,1,0.50,0,9,2,"Saturn is an innovative platform that assists Foundation Model (FM) building and its integration with IT operations (Ops). It is custom-made to meet the requirements of data scientists, enabling them to effectively create and implement FMs while enhancing collaboration within their technical domain. By offering a wide range of tools and features, Saturn streamlines and automates different stages of FM development, making it an invaluable asset for data science teams. In this white paper, we discuss the expected impacts of Saturn on the financial sector.","https://sol.sbc.org.br/index.php/webmedia_estendido/article/download/25680/25496",""
0,"Vishwanadham Mandala","An Overview of Data Science Algorithms",2020,"Mathematics and Computer Science Journal","","https://www.semanticscholar.org/paper/ff85d17b13d6178f57d735699a0b89e242019dd7","",125,"2025-02-06 14:32:15","JournalArticle","10.18535/mcsj/v2020.05","","",,,,,0,0.00,0,1,5,"Data science algorithms are on the way to becoming an integral part of every company, and we can already see the effects in many corporations that have invented their own data science teams and also implemented the latest data science algorithms. To be able to work with all the different challenges that are emerging, new powerful data science tools have been developed (e.g. Python, R, H2O, Weka, Tensorflow, Spark, Flink, BigML or KNIME). One balance that companies that want to use these new tools have to face is the cost of implementation vs. the enhanced development that they give in return. Nowadays, most of the advanced algorithms are open source and available on multiple platforms and programming languages, which helps to minimize the development cost challenges that each company has to overcome. Still, one of the main dangers lurking inside these development teams is that they do not know what the state of the art of advanced algorithms is and which problem they can address. To help mitigate this problem, a review of algorithms has been implemented in this paper. This review gives us a perspective on which algorithms are being developed and which problem areas they can address. With the development of more powerful data science algorithms, we are also enabling the possibility of tackling more complex and interesting problems. However, one characteristic of the review is that there are missing algorithms from the many that are currently being produced and frequently selected by the community as the best performers in many benchmark datasets.  ","",""
0,"Jasmina Tacheva, Sucheta Lahiri, J. Saltz","Analyzing a Data Science Online Practitioner Community: Trends and Implications for Data Science Project Management",2022,"2022 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/fdcdfa40a3ad4d6d1b1bfac2150fce7eda25ddfa","",126,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData55660.2022.10020600","","",,,2673,2681,0,0.00,0,3,3,"The overarching goal of this research was to gain an understanding of what the data science Reddit online community discussed before, during, and after COVID-19. We used a publicly available Reddit API to harvest the r/datascience subreddit first level post data. We then performed manual annotation to explore the taxonomy of trends and themes discussed by the practitioners who belonged to reddit data science community. Then, we augmented the manually annotated data using a BERT model with topic modeling. In short, the key discussion themes, in order of frequency, were: Education, Jobs, Methods (of data science), Hardware and data collection, Data visualization, and Quality. The Quality theme includes discussions on bias, transparency, and fairness. Hence, a key finding was that there were very few discussions on data science project quality, especially trying to minimize the risk of machine learning bias. As discussions on bias are not yet common, data science teams should proactively identify and address potential questions and concerns that might arise in data science projects, especially the need to increase the team’s focus on potential bias and fairness.","",""
0,"Lori Fischbach, Lisa V. Smith, J. King, M. Inkelas, T. Kuo","Using Grand Rounds to Train and Prepare a Local Public Health Workforce To Manage COVID-19 Outbreaks During the 2020–2021 Pandemic Winter Upsurge",2023,"Health Promotion Practice","","https://www.semanticscholar.org/paper/faeca8e7ee21c188d2100ca1efb9b0ee7b6287a9","",127,"2025-02-06 14:32:15","JournalArticle","10.1177/15248399231171952","1524-8399","",,,,,0,0.00,0,5,2,"In response to the coronavirus disease 2019 (COVID-19) pandemic, the Los Angeles County Department of Public Health (DPH) expanded its workforce by >250 staff during Fall 2020 to manage the expected volume of outbreaks, which ultimately peaked. The workforce included reorganized groups of physicians, nurses, outbreak investigators from several DPH programs, and a 100+ member data science team tasked with designing and operating a data system and information flow process that became the backbone infrastructure of support for field investigation and outbreak management in real-time. The accelerated workforce expansion was completed in 3 months. To prepare new and reassigned permanent staff for fieldwork, DPH and several faculty from the Emory University Rollins School of Public Health adopted a flexible, skills-based series of medical Grand Rounds. These 16 sessions were grounded in practice- and problem-based learning principles using case studies, interactive scenarios, and didactic presentations based on scientific and public health practice information to teach knowledge and skills that were needed to manage COVID-19 outbreaks in different sectors. The evaluation suggests positive experience with the training series as well as impact on job performance.","https://escholarship.org/content/qt0gb4h8xc/qt0gb4h8xc.pdf?t=rxz4ml",""
0,"Chelsey Legacy, A. Zieffler, B. Baumer, Valerie Barr, N. Horton","Facilitating team-based data science: Lessons learned from the DSC-WAV project",2021,"Foundations of Data Science","","https://www.semanticscholar.org/paper/f9236cb90f8a1ebdbc047c6d15418798eb411cdc","",128,"2025-02-06 14:32:15","Review","10.3934/fods.2022003","2639-8001","",,,,,0,0.00,0,5,4,"While coursework provides undergraduate data science students with some relevant analytic skills, many are not given the rich experiences with data and computing they need to be successful in the workplace. Additionally, students often have limited exposure to team-based data science and the principles and tools of collaboration that are encountered outside of school.In this paper, we describe the DSC-WAV program, an NSF-funded data science workforce development project in which teams of undergraduate sophomores and juniors work with a local non-profit organization on a data-focused problem. To help students develop a sense of agency and improve confidence in their technical and non-technical data science skills, the project promoted a team-based approach to data science, adopting several processes and tools intended to facilitate this collaboration.Evidence from the project evaluation, including participant survey and interview data, is presented to document the degree to which the project was successful in engaging students in team-based data science, and how the project changed the students' perceptions of their technical and non-technical skills. We also examine opportunities for improvement and offer insight to other data science educators who may want to implement a similar team-based approach to data science projects at their own institutions.","https://www.aimsciences.org/data/article/export-pdf?id=620c4aaf2d80b75aa4a24b8f",""
0,"Doug Rose","Avoiding Pitfalls in Delivering in Data Science Sprints",2016,"","","https://www.semanticscholar.org/paper/ef69dd69943b3589cf51414538cd8161da670f06","",129,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_14","","",,,127,141,0,0.00,0,1,9,"","",""
0,"Doug Rose","Avoiding Pitfalls in Building Your Data Science Team",2016,"","","https://www.semanticscholar.org/paper/ec15d1d4576db75b05f839d8c39ed8968e375101","",130,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_10","","",,,85,90,0,0.00,0,1,9,"","",""
0,"S. North, Infovisible Carlos Scheidegger, Simon Urbanek, Gordon Woodhull","BACK END STORAGE Get Put Post FRONT END Redis Find / Browse fork Python / Perl / Java Bindings Edit View Run Share Web Browser Main RCloud process text indices SOLR",2015,"","","https://www.semanticscholar.org/paper/eabf587e5d76792bbd0f5bb47080ff294d472c1d","",131,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,4,10,"Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: discoverability, technology transfer, and coexistence. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. About 100 people used RCloud for two years. We report on interviews with some of these users, and discuss design decisions, tradeoffs and limitations in comparison to other approaches.","",""
0,"A. Acharya, Ruth Black, Alisdair Smithies, A. Darzi","Evaluating the Impact of the National Health Service Digital Academy on Participants’ Perceptions of Their Identity as Leaders of Digital Health Change: Mixed Methods Study",2023,"JMIR Medical Education","","https://www.semanticscholar.org/paper/ea57b8b156d6ce2a816181c953019964068e8fa5","",132,"2025-02-06 14:32:15","JournalArticle","10.2196/46740","2369-3762","",10,,,,0,0.00,0,4,2,"Background The key to the digital leveling-up strategy of the National Health Service is the development of a digitally proficient leadership. The National Health Service Digital Academy (NHSDA) Digital Health Leadership program was designed to support emerging digital leaders to acquire the necessary skills to facilitate transformation. This study examined the influence of the program on professional identity formation as a means of creating a more proficient digital health leadership. Objective This study aims to examine the impact of the NHSDA program on participants’ perceptions of themselves as digital health leaders. Methods We recruited 41 participants from 2 cohorts of the 2-year NHSDA program in this mixed methods study, all of whom had completed it >6 months before the study. The participants were initially invited to complete a web-based scoping questionnaire. This involved both quantitative and qualitative responses to prompts. Frequencies of responses were aggregated, while free-text comments from the questionnaire were analyzed inductively. The content of the 30 highest-scoring dissertations was also reviewed by 2 independent authors. A total of 14 semistructured interviews were then conducted with a subset of the cohort. These focused on individuals’ perceptions of digital leadership and the influence of the course on the attainment of skills. In total, 3 in-depth focus groups were then conducted with participants to examine shared perceptions of professional identity as digital health leaders. The transcripts from the interviews and focus groups were aligned with a previously published examination of leadership as a framework. Results Of the 41 participants, 42% (17/41) were in clinical roles, 34% (14/41) were in program delivery or management roles, 20% (8/41) were in data science roles, and 5% (2/41) were in “other” roles. Interviews and focus groups highlighted that the course influenced 8 domains of professional identity: commitment to the profession, critical thinking, goal orientation, mentoring, perception of the profession, socialization, reflection, and self-efficacy. The dissertation of the practice model, in which candidates undertake digital projects within their organizations supported by faculty, largely impacted metacognitive skill acquisition and goal orientation. However, the program also affected participants’ values and direction within the wider digital health community. According to the questionnaire, after graduation, 59% (24/41) of the participants changed roles in search of more prominence within digital leadership, with 46% (11/24) reporting that the course was a strong determinant of this change. Conclusions A digital leadership course aimed at providing attendees with the necessary attributes to guide transformation can have a significant impact on professional identity formation. This can create a sense of belonging to a wider health leadership structure and facilitate the attainment of organizational and national digital targets. This effect is diminished by a lack of locoregional support for professional development.","",""
0,"Akit Kumar, M. S. L. Devi, J. Saltz","GenAI Tools to Improve Data Science Project Outcomes",2024,"2024 IEEE International Conference on Big Data (BigData)","","https://www.semanticscholar.org/paper/e91abe154a83638d0058a41e0dd7d9d461832d3d","",133,"2025-02-06 14:32:15","Conference","10.1109/BigData62323.2024.10825326","","",,,3143,3152,0,0.00,0,3,1,"The introduction of Generative AI (GenAI) has significantly impacted data science, offering powerful tools that enhance project outcomes through automated analysis, decision support, and personalized guidance. This study investigates the features of GenAI-powered tools designed to support both individuals and teams in data science projects. Using a qualitative approach, this study identifies essential features for supporting individuals and project teams. Key findings suggest that GenAI tools should include tailored learning aids, automated data processing capabilities, and collaborative project management features that facilitate workflow efficiency. For tool features, teams prioritize resource sharing and collaborative progress, while individuals focus on personalized support and timeline management. The study also emphasizes the advantages of domain-specific GenAI tools, offering project-specific guidance and management that surpass the capabilities of generalized solutions.","",""
0,"Biao Yin, Nicholas Josselyn, Ziming Zhang, Elke A. Rundensteiner, Thomas A. Considine, John V. Kelley, B. Rinderspacher, Robert E. Jensen, James F. Snyder","MOSS: AI Platform for Discovery of Corrosion-Resistant Materials",2023,"Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","","https://www.semanticscholar.org/paper/e62493dc9baec2038986c46918bb091191c3b4b5","",134,"2025-02-06 14:32:15","Book","10.1145/3583780.3614748","","",,,,,0,0.00,0,9,2,"Amid corrosion degradation of metallic structures causing expenses nearing 3 trillion or 4% of the GDP annually along with major safety risks, the adoption of AI technologies for accelerating the materials science life-cycle for developing materials with better corrosive properties is paramount. While initial machine learning models for corrosion assessment are being proposed in the literature, their incorporation into end-to-end tools for field experimentation by corrosion scientists remains largely unexplored. To fill this void, our university data science team in collaboration with the materials science unit at the Army Research Lab have jointly developed MOSS, an innovative AI-based digital platform to support material science corrosion research. MOSS features user-friendly iPadOS app for in-field corrosion progression data collection, deep-learning corrosion assessor, robust data repository system for long-term experimental data modeling, and visual analytics web portal for material science research. In this demonstration, we showcase the key innovations of the MOSS platform via use cases supporting the corrosion exploration processes, with the promise of accelerating the discovery of new materials. We open a MOSS video demo at: https://www.youtube.com/watch?v=CzcxMMRsxkE","",""
0,"Marta Stelmaszak","Inside a Data Science Team: Data Crafting in Generating Strategic Value from Analytics",2022,"European Conference on Information Systems","","https://www.semanticscholar.org/paper/e4f99a0e439b7e2a724f69ab8712d02f4560ca13","",135,"2025-02-06 14:32:15","JournalArticle","","","",,,,,0,0.00,0,1,3,"","",""
0,"Stephen Rassenfoss","Time To Enlist in the Analytics Army",2018,"Journal of Petroleum Technology","","https://www.semanticscholar.org/paper/de6685fa4cbd125d9cc9ecc528901dcb66b826b6","",136,"2025-02-06 14:32:15","JournalArticle","10.2118/0618-0033-jpt","0149-2136","",,,,,0,0.00,0,1,7,"Data analytics is the future of getting ahead for engineers and geoscientists in the exploration and production (E&P) business. Three executives of large companies recently played up the growing importance of data-driven employee development, from data science boot camps at BP to the Citizen Data Scientist program at ConocoPhillips. “We have got a data science community that is growing by leaps and bounds,” said Michael Rowley, director of technology and innovation at BP, during a presentation at the recent Data Science Convention 2018 put on by the Data Analytics Study Group of the SPE Gulf Coast Section. “The most powerful way for us to pro-mote data analytics is to give our technical people training so they are fully armed with data analytics tools,” said Greg Leveille, chief technology officer of ConocoPhillips. Those willing to learn and apply these new tools “will have a disproportional impact on each of your companies,” Leveille said, adding “our industry will be populated by people who know and who can do data analytics well.” In a tough job market, data skills could offer a critical edge. If two people are interviewing for a job in unconventional exploration, and one has analytics skills and experience and the other does not, “guess who gets the job,” said Andy Flowers, director of advanced analytics for Marathon Oil. One sign of the times was the number of data scientists asking questions at the gathering. Another was the 400-person crowd at the first-ever gathering. They are building and maintaining the industry’s new data gathering and analysis infrastructure, putting large databases and analytical tools in the hands of engineers, geoscientists, and financial managers. They are a small part of the E&P workforce, are hard to find, and costly to hire. “We feel like we won the lottery when we get a new person in” for the data science team, Flowers said. But engineers and geoscientists will remain central to E&P companies because “you cannot outsource knowledge of the oil industry,” Flowers said. They will be asked to use their experience to focus the work on the most important problems, and apply methods drawing on both traditional and statistical approaches. “People with a good grounding and understanding of physics, combined with analytics, can solve problems that are very hard to solve” with first principles physics, Leveille said. Increasingly, the data-driven tools will also integrate the economic aspects of decision making. Engineering decisions need to be aligned with current corporate goals. An application integrating technical and economic information could help an engineer tailor a gas project development plan based on predicted demand. “Not everything is about geology and physics,” Rowley said. Another priority is to figure out “how to connect up data in the financial space,” he said.","",""
0,"R. D. Graaf","Data Science Team Strategy",2019,"","","https://www.semanticscholar.org/paper/dd571f573a82b3e044241fcf4bdeb74506ac19c0","",137,"2025-02-06 14:32:15","","10.1007/978-1-4842-4907-9_1","","",,,1,23,0,0.00,0,1,6,"","",""
0,"Lidia Contreras-Ochando, Fernando Martínez-Plumed, C. Ferri, J. Hernández-Orallo","Logging Data Scientists : Collecting Evidence for Data Science Automation",2016,"","","https://www.semanticscholar.org/paper/dcbae3d2d95ccf16687d93b3bc6aeed94dc6cf5b","",138,"2025-02-06 14:32:15","Review","","","",,,,,0,0.00,0,4,9,"If we really want to automate data science we need to know how data scientists behave. In other words, we have to apply data science to data scientists. However, it seems very difficult to track all the activities a data scientist (or a data science team) is doing. Indeed, apart from a few surveys (about the tools and times they devote to every stage of the whole process), there is a lack of evidence about what data scientists really do and the decisions and actions they take, especially at a high granularity level. The introduction of data mining tools in the past two decades, such as SPSS Clementine (then IBM Modeler), Weka KnowledgeFlow, SAS Enterprise Miner, RapidMiner and many others that followed, made it possible, for the first time, to incorporate most of a data mining process into the same tool. However, logging the actions of the users had to be done locally, with the difficulty of obtaining a relative good number of expert experiences. Collaborative or competitive platforms such as Kaggle or Github can also be a source of data, but it is difficult to extract information about sequential workflow or the particular actions that have to be taken for all the stages of a data science project. This is aggravated by the recent “back to programming” trend, where the products of data scientists in these platforms are programs (usually in R or python), and not a sequence of actions over a structured set of possibilities. In fact, some tools that try to automate the process are based on the “knowledge, experience and best practices” of data scientists, such as DataRobot, but not based on the evidence of real logs at a high granularity level.","",""
0,"Motashim Rasool, Vipin Kumar Chaudhary","Applications of Data Science in Respective Engineering Domains",2022,"International Journal of Scientific Research in Science and Technology","","https://www.semanticscholar.org/paper/d79a5b2d859193bef3ae9f40468b5c9c9760bfdb","",139,"2025-02-06 14:32:15","JournalArticle","10.32628/ijsrst22958","2395-6011","",,,,,0,0.00,0,2,3,"Data Science is answerable to the every field of technology domain even it is Electronics and Communication Engineering, Electrical Engineering, Mechanical Engineering or Civil Engineering. For example in Civil Engineering following applications like Advance Predictions in construction works, Project risk Analysis, availability of water resources, Traffic forecasting and many more similarly we have many applications from Engineering Domain. Data Science approaches has adopted many technical techniques within the Engineering domain ranging from data analysis to neural network to deep learning and it has very vast variety of particular engineering domain solutions. Data scientists today draw largely from extensions of the “analyst” of years past trained in traditional disciplines. As data science becomes an integral part of many industries and enriches research and development, there will be an increased demand for more holistic and more nuanced data science roles.","",""
0,"C. Sverdloff, Letícia Marquez Anselmo, Juliana de Lurdes Magri, Vinicius Marcondes Rezende","Overview of regulatory clinical research in Brazil: current situation of an inefficient system",2024,"Brazilian Journal of Health Review","","https://www.semanticscholar.org/paper/d5407bfcc65525fc9f2fcdbfcbad308f36e98377","",140,"2025-02-06 14:32:15","JournalArticle","10.34119/bjhrv7n5-227","2595-6825","",,,,,0,0.00,0,4,1,"Background: In Brazil, the regulatory process for clinical research is notably intricate, encompassing a series of pivotal phases. These include ethical evaluation and approval by Research Ethics Committees and health evaluation conducted by the Brazilian Health Surveillance Agency (Anvisa). Moreover, the Drug Market Regulation Chamber (CMED) imposes price limitations, which can prevent the return on investment for both national and foreign companies in most cases. Objectives: to present an analysis of the current state of clinical research in Brazil, based on publicly available information, in order to identify the weaknesses and challenges that Research faces in the country. Methods: The data science team obtained statistical data and information on the pharmaceutical market, as well as epidemiological data, from public databases, which allowed the team to organize the evidence according to the objectives of this study. Results and challenges: Despite the widely spread opinions investment in innovation, as compared to those of other countries, at present, there is a shortage of new products and innovative treatments. This outlook is further complicated for the most research, which is affected by the regulatory system and currently conducted by the local pharmaceutical industry with fewer resources.","",""
0,"Hanluen Kuo, Vinay Murakonda, Hunter Hines, D. Mudaranthakam, Paula Monaghan-Nichols, Eric Rush, Jeffrey Statland","89 Two Newly Developed Frontiers CTSI Applications to Support Recruitment and Trial Management: The Frontiers Trial Finder Mobile App and a Predictive Accrual Web-based App",2024,"Journal of Clinical and Translational Science","","https://www.semanticscholar.org/paper/d48ad509c986e4acb5461fd2fe3752c9a4d56859","",141,"2025-02-06 14:32:15","JournalArticle","10.1017/cts.2024.87","2059-8661","",8,,23,24,0,0.00,0,7,1,"OBJECTIVES/GOALS: Frontiers CTSI developed applications to ensure its science teams have technological tools to advance their community engagement and trial management. The Trial Finder app is a mobile application that allows users to navigate available trials. The Accrual app will help study teams monitor their recruitment performances in real time. METHODS/STUDY POPULATION: The Data Science team at the University of Kansas Medical Center (KUMC) had previously developed similar applications for The University of Kansas Cancer Center. Both retrieve information from KUMC’s clinical trial management system and ClinicalTrials.gov. This was replicated to include KUMC Pulmonary Critical Care (PCC) and KUMC Neuromuscular (NM) trials. Frontiers CTSI is working with both groups for piloting and feedback. Recruiting and marketing strategies for investigators to add their trials to both apps will be done through existing communication channels and be highlighted on Frontiers trial resource website. Recruiting and marketing strategies of the Frontiers Trial Finder app to the external community will have a focus on, but not limited to, paid social media advertising. RESULTS/ANTICIPATED RESULTS: The Trial Finder app can help providers search for trials their patient may be eligible for during clinic visits and to engage with the community by allowing anyone to download and browse on their Android/iOS device. Built in REDCap forms are used to capture contact information. The Accrual app is a web-based application that helps study teams monitor their recruitment performances in real time and provide an opportunity to adjust strategies. It uses an in-house algorithm to predict if trials will meet timeline goals. This data is conveniently laid out on a single web page so that science teams can overview all their trials’ recruitment performances simultaneously. The next phase of developing these applications is to market their use within Frontiers CTSI and its community catchment area. DISCUSSION/SIGNIFICANCE: Through collaboration, Frontiers CTSI is developing resources to support community engagement and trial management. New innovative applications like these ensure all the main stakeholders involved with clinical trial execution are always engaged and have access to iterative contemporary technologies that support their research.","https://www.cambridge.org/core/services/aop-cambridge-core/content/view/3C751A23428F523790E343025FEFE23C/S2059866124000876a.pdf/div-class-title-89-two-newly-developed-frontiers-ctsi-applications-to-support-recruitment-and-trial-management-the-frontiers-trial-finder-mobile-app-and-a-predictive-accrual-web-based-app-div.pdf",""
0,"Holly A. H. Handley, C. Eshelman-Haynes","Formation of Data Science Teams based on Scenario Characteristics",2021,"Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","https://www.semanticscholar.org/paper/d1fd766a4677288d4ff64d665c096b52d20de9ba","",142,"2025-02-06 14:32:15","JournalArticle","10.1177/1071181321651048","1071-1813","",65,,535,540,0,0.00,0,2,4,"The objective of this research was to identify a set of attributes to characterize data science scenarios to assists in the formation of an accompanying data science team. The six scenario characteristics were developed in consultation with a Subject Matter Expert (SME) to identify the important aspects of a data science endeavor. Concurrently, a generalizable role by task matrix was developed that captures the high-level data science functions and potential team member roles. This matrix was based on the NATO data science process function definitions, linked to the U.S. Department of Labor social science work activities, and data science role definitions. The mapping of the characteristics to the role by task matrix results in guidelines for forming a data science team; an example scenario with its characteristics and proposed team design is described. This work suggests methods to customize team information for specific data science needs based on scenario attributes.","",""
0,"M. Goul, W. P. Carey, J. Saltz, A. Sidorova","Introduction to the Artificial Intelligence and Big Data Analytics Management, Governance, and Compliance Minitrack",2019,"","","https://www.semanticscholar.org/paper/d198e46463e2c883a3f04a0aec699fc17296b55e","",143,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,4,6,"Artificial Intelligence (AI) and Big Data applications are becoming increasingly important strategic assets as they enable organizations to differentiate from their competitors by offering new data-driven products and services, by achieving increased agility in operations and decision making, by enhancing the discovery of new business insights, and by augmenting decision making and acting on decisions in a faster, more streamlined manner. As organizations become more reliant on AI and data-driven models for insight, decision making and action, they need new theories, frameworks and methodologies that can help them in the following areas: • Deploying effective strategies and policies for managing AI and Big Data • Streamlining processes to develop and deploy analytical models and Machine Learning (ML) algorithms • Designing new KPIs and deploying actionable dashboards • Managing and staffing AI, ML and data science teams • Structuring analytics functions/capabilities within organizations • Designing, staffing and providing direction to AI, data and analytics governance committees • Managing AI and Big Data Analytics project and deployment risk and • Advancing AI and Big Data capability maturity","",""
0,"Lucas B. Miguel, D. Takabayashi, Jose R. Pizani, Tiago Andrade, Brody West","Marvin - Open source artificial intelligence platform",2018,"International Conference on Predictive APIs and Apps","","https://www.semanticscholar.org/paper/d0be89cb0ed1c038097ef1395a9f1b0f2c78d9ad","",144,"2025-02-06 14:32:15","JournalArticle","","","",,,33,44,0,0.00,0,5,7,"Marvin is an open source project that focuses on empowering data science teams to deliver industrial-grade applications supported by a high-scale, low-latency, language agnostic and standardized architecture platform, while simplifying the process of exploration and modeling. Building model-dependent applications in a robust way is not trivial, one is required to have knowledge in advanced areas of sciences like computing, statistics and math. Marvin aims at abstracting the complexities in the creation process of scalable, highly available, interoperable and maintainable predictive software.","",""
0,"Simon Urbanek","RCloud – Collaborative Visualization and Analysis Platform",2024,"Journal of Data Science","","https://www.semanticscholar.org/paper/cee0f0495200bbb41e01897c89d89b96267b806c","",145,"2025-02-06 14:32:15","JournalArticle","10.6339/24-jds1153","1680-743X","",,,,,0,0.00,0,1,1,"The last decade has seen a vast increase of the abundance of data, fuelling the need for data analytic tools that can keep up with the data size and complexity. This has changed the way we analyze data: moving from away from single data analysts working on their individual computers, to large clusters and distributed systems leveraged by dozens of data scientists. Technological advances have been addressing the scalability aspects, however, the resulting complexity necessitates that more people are involved in a data analysis than before. Collaboration and leveraging of other’s work becomes crucial in the modern, interconnected world of data science. In this article we propose and describe an open-source, web-based, collaborative visualization and data analysis platform RCloud. It de-couples the user from the location of the data analysis while preserving security, interactivity and visualization capabilities. Its collaborative features enable data scientists to explore, work together and share analyses in a seamless fashion. We describe the concepts and design decisions that enabled it to support large data science teams in the industry and academia.","",""
0,"Doug Rose","Using a Data Science Life Cycle",2016,"","","https://www.semanticscholar.org/paper/ce8bef71bfb011acf5efd8584b12091cd39a5c4b","",146,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_12","","",,,105,114,0,0.00,0,1,9,"","",""
0,"Sabarish Vadarevu, Ajith Kumar Battaje, Alexander Berkovich","DataExplorer - Computer Vision data management, exploration, curation, and modeling at scale",2023,"Proceedings of the Third International Conference on AI-ML Systems","","https://www.semanticscholar.org/paper/c9783ea4011966117f6b6c88e02981d58a262469","",147,"2025-02-06 14:32:15","Book","10.1145/3639856.3639910","","",,,,,0,0.00,0,3,2,"Akridata’s Data-Explorer is the leading data-centric MLOps platform that helps data science teams manage, explore, and curate visual data at a large scale. Users can connect data sources from cloud or on-prem data stores and catalogs. Datasets can be explored as a whole, or as filtered slices, to surface latent structures and underlying statistics. Interactive exploration allows identifying data patterns and quality issues, and subsequent creation of efficient training subsets through distribution-aware sampling. Targeted refinement for rare concepts is supported through semantic search driven by images, image-regions, or text-prompts. Trained models can be analyzed for failure modes by correlating mispredictions with the corresponding data points.This is further aided by explaining models using saliency maps.","",""
0,"B. Wyatt","The design and use of the Australian Petroleum Exploration Data Index",1985,"Exploration Geophysics","","https://www.semanticscholar.org/paper/c8e71cc0e345bb239df0e713f8ca1b4371fb74f6","",148,"2025-02-06 14:32:15","Review","10.1071/EG985331","","",16,,331,333,0,0.00,0,1,40,"The concept of the Petroleum Exploration Data Index (PEDIN) database was initiated by the Bureau of Mineral Resource's (BMR) Petroleum Branch. Funding by National Energy Research, Development and Demonstration Council (NERDDC) during 1984 and 1985 has seen the design and implementation of the database by Data Science Pty Limited and B. R. Senior and Associates. Data Science's role was to design and implement the database, to set up a system to manage data in BMR's Core and Cuttings Laboratory, to extract and enter data regarding Petroleum Search Subsidy Act (PSSA) geophysical surveys, and to enter some well data. B. R. Senior and Associates extracted and entered Petroleum Search Subsidy Act (PSSA) well data.","http://www.publish.csiro.au/eg/pdf/eg985331",""
0,"Doug Rose","Recognizing Different Data Types",2016,"","","https://www.semanticscholar.org/paper/c7322aafbd9699f529d5c7b819b15819c3c7e64f","",149,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_3","","",,,19,26,0,0.00,0,1,9,"","",""
0,"Patrick Holl, Kevin Gossling","Midas: Towards an Interactive Data Catalog",2019,"","","https://www.semanticscholar.org/paper/c591d153f0c2bf0906b4636ea58f79817dbb2ab4","",150,"2025-02-06 14:32:15","JournalArticle","10.1007/978-3-030-33752-0_9","","",,,128,138,0,0.00,0,2,6,"","",""
0,"Xingjian Shi, Jonas Mueller, Nick Erickson, Mu Li, Alexander J. Smola","Multimodal AutoML on Tables with Text Fields",2021,"","","https://www.semanticscholar.org/paper/bb5960d2af0fe79fd5b2ae7880a33854c072fb10","",151,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,5,4,"We consider the design of automated supervised learning systems for data tables 1 that not only contain numeric/categorical columns, but text ﬁelds as well. Here we 2 assemble 15 multimodal data tables that each contain some text ﬁelds and stem 3 from a real business application. Over this benchmark, we evaluate numerous 4 multimodal AutoML strategies, including standard two-stage approaches where 5 NLP is used to featurize the text such that AutoML for tabular data can then be 6 applied. We identify practically superior strategies based on multimodal adaptations 7 of Transformer networks and stack ensembling of these networks with classical 8 tabular models. Compared with human data science teams, the best fully automated 9 methodology 2 discovered through our benchmark manages to rank 1st place when 10 ﬁt to the raw text/tabular data in two MachineHack prediction competitions and 11 2nd place (out of 2380 teams) in Kaggle’s Mercari Price Suggestion Challenge. 12","",""
0,"Rylan Chong, Laura Tipton","The Pacific Innovations, Knowledge, and Opportunities (PIKO) Program: A Data Lifecycle Research Experience.",2023,"Hawai'i journal of health & social welfare","","https://www.semanticscholar.org/paper/ba3b22e7c7905ea28012138b4bbd614e5951ff8e","",152,"2025-02-06 14:32:15","JournalArticle","","2641-5216","",82,10,117,120,0,0.00,0,2,2,"Pacific evidence-based clinical and translational research is greatly needed. However, there are research challenges that stem from the creation, accessibility, availability, usability, and compliance of data in the Pacific. As a result, there is a growing demand for a complementary approach to the traditional Western research process in clinical and translational research. The data lifecycle is one such approach with a history of use in various other disciplines. It was designed as a data management tool with a set of activities that guide researchers and organizations on the creation, management, usage, and distribution of data. This manuscript describes the data lifecycle and its use by the Biostatistics, Epidemiology, and Research Design core data science team in support of the Center for Pacific Innovations, Knowledge, and Opportunities program.","",""
0,"Doug Rose","Places to Look for Questions",2016,"","","https://www.semanticscholar.org/paper/b8665396693f1ee45d39b2a0a031656002ef4cb6","",153,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_17","","",,,165,184,0,0.00,0,1,9,"","",""
0,"Michael Niederée, H. Jäger, C. Schwarz, S. Grotehans","Recht",2018,"Digitale Welt","","https://www.semanticscholar.org/paper/b1a4cbcd7129dec12897cc7a8b91d0d24455f8e2","",154,"2025-02-06 14:32:15","JournalArticle","10.1007/s42354-019-0150-6","2510-3008","",3,,52,57,0,0.00,0,4,7,"","",""
0,"","DataHub – A Collaborative Dataset Management Platform",2015,"","","https://www.semanticscholar.org/paper/adbe9c67ddfba99a31d4d0b64c1fa01112c62dc3","",155,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,0,10,"The rise of the Internet, smart phones, and wireless sensors has produced a huge diversity of datasets about all aspects of our lives, from our social interactions to our personal preferences to our vital signs and medical records. Increasingly, researchers and “data science” teams want to collect and collaborate on these datasets. Consider a few examples: • a geneticist who wants to share and collaborate on genome data with other research groups; • an athlete who wants to quickly study and visualize his performance data; • a member of a web advertising team who wants to distill insights from unstructured ad-click data; • a university scheduling office that wants to share room reservations data with campus; • a journalist who wants to examine public data related to terrorist strikes in Afghanistan; • a city that wants to publish transit ridership data; • a small-shop owner who wants to study their sales data in the context of public economic data Each of these is an example of a data “enthusiast” or a data sub-community with a need to share, exchange, collaborate on, distill, and/or visualize datasets. Our thesis is that these (and many more similar) communities are under-served by the current data management and collaboration technologies available. Although there is a wealth of “data science” research addressing stand-alone data analysis issues or building integrated tools for analysis, the dataset management, collaboration, and sharing aspects of these tools are poor, requiring data scientists to use ad-hoc mechanisms to record and reason about datasets. Furthermore, although there is a vast array of “big data” research, the emphasis is on performance, and not on simplifying and automating many of the fundamental bookkeeping and management procedures necessary to facilitate seamless data science. To this end, we propose DataHub, a hosted, collaborative platform for preparing, storing, and analyzing datasets. DataHub’s goal is to provide a common substrate for members of data science teams to collaborate, analyze, and reason about datasets. Our goal is not, in fact, to replace existing data science tools: rather, we effectively support existing data science tools through much-needed basic infrastructure and management capabilities. DataHub stands apart from previous systems in two main ways:","",""
0,"Syahrul Nizam Junaini, Sopian Bujang, Nadri Aetis Heromi Basmawi, Jusmawati Fauzaman","Shaping the Digital Future of Civil Service: An Assessment of Digital Transformation and Data Science Competencies",2023,"2023 IEEE 8th International Conference On Software Engineering and Computer Systems (ICSECS)","","https://www.semanticscholar.org/paper/aa71480bb82ab654d50a70525fac6d3ec09297b9","",156,"2025-02-06 14:32:15","JournalArticle","10.1109/ICSECS58457.2023.10256327","","",,,229,234,0,0.00,0,4,2,"In the era of digital transformation and data proliferation, the need for effective digital competency assessment is increasingly critical. However, existing frameworks often lack comprehensive integration of key digital transformation and data science competencies necessary for roles within the civil service sector. This study introduces a robust instrument to profile competency domains critical to digital transformation and data science roles in the civil service. Leveraging a four-phase mixed-method methodology, including brainstorming, external validation, and a pilot study, the instrument was developed, validated, and tested among 30 state government servants. The reliability of the domains-Data Analytics, Data Science Management, Data & Digital Architecture, and Digital Transformation-was confirmed by excellent Cronbach's Alpha values ( 0.9). Content validity was evaluated using Lawshe's Content Validity Ratio (CVR) and Index (CVI), indicating strong validity for Digital Transformation and Data & Digital Architecture domains, while suggesting refinement for Data Analytics and Data Science Management. The proposed instrument, validated through self-evaluation scores, illustrates potential for career and organizational development within the civil service, emphasizing its practical value and feasibility.","http://ir.unimas.my/id/eprint/42707/3/Shaping.pdf",""
0,"Sohini Sengupta, S. Mugde, R. Deshpande, Kimaya Potdar","Workforce Analytics: A Data-Driven Machine Learning Approach to Predict Job Change of Data Scientists",2021,"Transnational Marketing Journal","","https://www.semanticscholar.org/paper/aa1d89f8869511f85b689e1239980353a1423c64","",157,"2025-02-06 14:32:15","JournalArticle","10.33182/tmj.v9i2.1574","2041-4684","",,,,,0,0.00,0,4,4,"Today the total amount of data created, captured, and consumed in the world is increasing at a rapid rate, as digitally driven organizations continue to contribute to the ever- growing global data sphere. (Holst, Statista Report 2020). This data brings with it a plethora of opportunities for organizations across different sectors. Hence, their hiring outlook is shifting towards candidates who possess the abilities to decode data and generate actionable insights to gain a competitive advantage. A career in data science offers great scope and the demand for such candidates is expected to rise steeply. When companies hire for big data and data science roles, they often provide training. From an HR perspective, it is important to understand how many of them would work for the company in the future or how many look at the training with an upskilling perspective for new jobs. HR has the aim of reducing costs and time required to conduct trainings by designing courses aligning to the candidate’s interest and needs. In this paper, we explored the data based on features including demographics, education and prior experience of the candidates. We made use of machine learning algorithms, viz. Logistic Regression, Naive Bayes, K Nearest-Neighbours Classifier, Decision Trees, Random Forest, Support Vector Machine, Gradient Descent Boosting, and XGBoost to predict whether a candidate will look for a new job or will stay and work for the company. ","",""
0,"Prithviraj Sanjay Patil, Keertana Kappuram, Russel Rumao, Poonam Bari","Development Of AMES: Automated ML Expert System",2022,"2022 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COM-IT-CON)","","https://www.semanticscholar.org/paper/a7ed658eaf576426670930db6b90b77aae204308","",158,"2025-02-06 14:32:15","Conference","10.1109/com-it-con54601.2022.9850737","","",1,,208,213,0,0.00,0,4,3,"There has been an exponential rise in the quantity of data in the last few decades and as a consequence of this, the need for Machine Learning based applications has increased in every domain. In recent years, Machine Learning has been used in many fields to achieve significant breakthroughs. These fields include financial services, transportation, healthcare, e-commerce, retail, etc. wherein Machine Learning has been used for innovation, transformation, and optimization to get highly promising results. In today’s world, Machine Learning is not used only for research and development applications but also in the enterprise domain. However, traditional Machine Learning methods are dependent on humans and that is not a feasible option for businesses having limited resources and those which cannot invest in a highly qualified data science team. Even in the case of Machine Learning engineers who are in high demand across various industries, improving the efficiency of tasks related to Machine Learning has become a challenge. This calls for the creation of an application that can automate the end-to-end process of applying machine learning solutions to real-world problems. “AMES: Automated ML Expert System” will make Machine Learning truly available, even to people with minimal expertise in this field. Such a system will increase productivity by automating repetitive tasks, help to avoid errors that might creep in due to manual processes, and democratize Machine Learning by making the power of ML accessible to everybody. Tasks such as Hyperparameter Optimization, feature engineering, data preprocessing, visualization, and even model selection, if automated, will prove to be of great benefit to ML engineers and novice users alike. This project aims to automate all these tasks and make the process of building a model simple, quick and efficient.","",""
0,"Joohee Choi","The Effect of Role Specialization And Transactive Memory Systems On Performance in Data Science Teams",2020,"","","https://www.semanticscholar.org/paper/a7e394925b6fa07715fa41d2fe4973812329e935","",159,"2025-02-06 14:32:15","","10.13016/HDZ3-AB96","","",,,,,0,0.00,0,1,5,"","",""
0,"T. Aho, Terhi Kilamo, Lucy Ellen Lwakatare, T. Mikkonen, Outi Sievi-Korte, S. Yaman","Managing and Composing Teams in Data Science: An Empirical Study",2021,"2021 IEEE International Conference on Big Data (Big Data)","","https://www.semanticscholar.org/paper/a424f1476e9cc74ca7ac53863fe5c2a4c6d5b4bf","",160,"2025-02-06 14:32:15","JournalArticle","10.1109/BigData52589.2021.9671737","","",,,2291,2300,0,0.00,0,6,4,"Data science projects have become commonplace over the last decade. During this time, the practices of running such projects, together with the tools used to run them, have evolved considerably. Furthermore, there are various studies on data science workflows and data science project teams. However, studies looking into both workflows and teams are still scarce and comprehensive works to build a holistic view do not exist. This study bases on a prior case study on roles and processes in data science. The goal here is to create a deeper understanding of data science projects and development processes. We conducted a survey targeted at experts working in the field of data science (n=50) to understand data science projects’ team structure, roles in the teams, utilized project management practices and the challenges in data science work. Results show little difference between big data projects and other data science. The found differences, however, give pointers for future research on how agile data science projects are, and how important is the role of supporting project management personnel. The current study is work in progress and attempts to spark discussion and new research directions.","",""
0,"C. Anderson","Keynote Abstract: Inspiring Healthy Habits: Data Science at WW",2019,"","","https://www.semanticscholar.org/paper/a199de812f1fc40d82977dab1993807f99149b69","",161,"2025-02-06 14:32:15","JournalArticle","","","",,,1,,0,0.00,0,1,6,"Our purpose at WW (the new Weight Watchers) is to ""inspire healthy habits for real life. For people, families, communities, the world for everyone."" For 56 years, we’ve been a leader in weight loss. Now, however, our mission is bigger and broader: drive health and wellness, making healthy habits accessible to all, not just a few. The question is, how do you deliver on that? Humans are notoriously fickle, stubborn, and irrational. They don’t always do what is in their best interests. Moreover, behavioral change and habit forming is genuinely hard. It is all too easy to skip going to the gym, to resist that extra cookie, or to take time for yourself and reduce stress. In this session, we’ll discuss what’s involved in behavioral change and nudges, and how the WW data science team are working on personalized experiences, various recommenders, and other data products at scale to aid our members’ success. BIOGRAPHY Carl Anderson is the Director, Data Science at WW, the newWeight Watchers, in New York. His team builds predictive models and data products such as churn models, social network recommenders, search improvements, and food recommenders, all to inspire healthy habits among our millions of members around the world, as well as to positively impact their families and their communities. Passionate about all thing data, he is the author of the 2015 O’Reilly book ""Creating a Data-Driven Organization"". HealthRecSys’19, September 20, 2019, Copenhagen, Denmark © 2019 Copyright for the individual papers remains with the authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). This volume is published and copyrighted by its editors.","",""
0,"B. Robards, Bob Buttigieg","Marriage Equality, Facebook Profile Pictures, and Civic Participation",2016,"","","https://www.semanticscholar.org/paper/9e3724e26f87ad166cdcb6a21105465606a13c34","",162,"2025-02-06 14:32:15","","10.7551/mitpress/9970.003.0009","","",,,,,0,0.00,0,2,9,"On March 25, 2013, the Human Rights Campaign (HRC)-a lesbian, gay, bisexual, and transgender (LGBT) lobby-urged people to change their Facebook profile pictures to a pink-on-red equals sign to show support for marriage equality (see figure 6.1). The campaign corresponded with a U.S. Supreme Court meeting to debate the issue. Shortly after, on March 30, Eytan Bashky (2013) from the Facebook data science team reported that ""roughly 2.7 million (120%) more [users], updated their profile photo on Tuesday, March 26, compared to the previous Tuesday,"" which was roughly attributed to the HRC push. The campaign to change Facebook profile pictures spread to become a global phenomenon. Variations on the HRC profile picture emerged, some in support of the campaign, others opposing it, and others critiquing the impact changing one's profile picture can have. In this case study, we explore the campaign through the lens of the ""actualizing citizen"" (Miegel and Olsson 2007) and discourses around ""slacktivism"" (Christensen 2011).","",""
0,"","Collaborative Visual Analysis on the Web with RCloud",2015,"","","https://www.semanticscholar.org/paper/9dd289aa8770719c1263395729ca90e2f4fd560f","",163,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,0,10,"Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: technology transfer, coexistence, and discoverability. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. The biggest deployment of RCloud has been in active use for more than two years, and has about fifty active users. We report on interviews with some of these users, and discuss the design decisions, tradeoffs and limitations, comparing RCloud to other current proposals.","",""
0,"Jiao Song, Eliza Elliot, A. Morris, J. Kerssens, A. Akbari, Simon Thompson, R. Lyons","Distributed team health data science in risk of non-Vitamin K Oral Anticoagulant after Intracranial Haemorrhage",2018,"International Journal of Population Data Science","","https://www.semanticscholar.org/paper/979f11e8c333e2a1c9f77047e271e5cdfc514136","",164,"2025-02-06 14:32:15","JournalArticle","10.23889/IJPDS.V3I4.784","2399-4908","",,,,,0,0.00,0,7,7,"IntroductionNew non-vitamin K Target Specific Oral Anticoagulants (TSOACs) have a favourable risk-benefit profile and debatable cost effectiveness. Large numbers and data from multiple countries in a European study are required to investigate safety issue of TSOACs in subgroups, e.g. people with an intracranial haemorrhage. Objectives and ApproachWe developed an approach to rapidly replicate data and analyses to support cross-country distributed research within the UK/EU using Electronic Health Records (EHRs). This project was conceptualised and initialled by linking relevant datasets held in multiple data warehouses, in Scotland with the Scottish National Data Safe Haven, and in Wales through the Secure Anonymised Information Linkage (SAIL) databank. Analysts in Edinburgh and Swansea had remote access to each other’s datasets and worked collaboratively to harmonise variables and analysis scripts. . A common R code script has been produced to harmonise individual data as well as the outputs from the study. ResultsThe study screened data on 8M people to develop a cohort that included pseudonymised information of 4,153 individuals in Scotland and 2,676 individuals in Wales, 6,829 individuals in total. Standardised risk analyses were completed in both settings with ongoing work in combining the analyses. In Wales, 39.5% of the patients in the cohort had been admitted to hospitals due to serious vascular events or died caused by these events, after intracranial haemorrhage. Incident rates for male and female are 0.63 and 0.7 respectively. Within the cohort, 0.5% were prescribed with TSOACs and 3% with Warfarin (included as reference). The project is also in the process of including other European jurisdictions. Conclusion/ImplicationsThe adopted approach was the simplest, yet most efficient and cost-effective method to ensure consistency in analysis and coherence with currently available governance systems of both safe havens. It can also be considered as an initialisation of developing infrastructure to support research using EHRs across the UK and EU.","https://ijpds.org/article/download/784/700",""
0,"C. Nm","Role of Data Science in Reshaping the Business Sectors: Opportunities and Challenges for India",2021,"Electronic Journal of Social and Strategic Studies","","https://www.semanticscholar.org/paper/91eac308744b218d0c6af93836b4d81c2f9cc797","",165,"2025-02-06 14:32:15","JournalArticle","10.47362/ejsss.2021.2207","2582-9645","",,,,,0,0.00,0,1,4,"“Data is the new science. Big Data holds the answers.” Pat Gelsinger, CEO of VMware’s prophetic words speak volumes about the Data Science (DataFlair, n.d.), a field that has impacted the world. Data Science, derived from merging of computer science and statistics-two related but distinct disciplines-is being extensively used today, to transform plethora of data into useful insights and predictions, converting something seemingly vague into meaningful information. Global use of Data Science has impacted everyday lives, industries, businesses well beyond the technical world and is helping in changing the world for better. India too has made a modest beginning and has a long way to go in this field. Despite its limited use, Artificial Intelligence (AI) and Cognitive Technologies (CT), important constituents of Data Science, have helped Indian companies in reshaping their business processes and enhancing their efficiencies, analysis of which would form an important part of this paper. However, to present a holistic picture, this paper will examine status of Global use of Data Science (scope, applications and limitations), India specific scenario related to Data Science, role of Artificial Intelligence (AI) and Cognitive Technologies (CT) in reshaping business processes and their impact on various sectors-specifically analysing E-Commerce sector, existing generic challenges, probable measures, ending with some viable recommendations.","",""
0,"Theo Härder","Editorial",2017,"Datenbank-Spektrum","","https://www.semanticscholar.org/paper/8b884ff795f314b8bd96d92e8805b40ba69bfc99","",166,"2025-02-06 14:32:15","JournalArticle","10.1007/s13222-017-0269-2","1618-2162","",17,,203,205,0,0.00,0,1,8,"","https://link.springer.com/content/pdf/10.1007/s13222-017-0269-2.pdf",""
0,"","MINING DEEP INSIGHTS FROM LARGE POLAR DATA REPOSITORIES WITH APACHE OPEN-SOURCE",2019,"","","https://www.semanticscholar.org/paper/84eb476f0ce4d9bfc2fe478c1710eef1ac74a6db","",167,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,0,6,"Submitted by karanjeetsingh on Tue, 2016-12-20 03:53 Event: Winter Meeting 2017 [2] Abstract: We look to generate deep insights about trends influencing the polar domain by mining deep insights from documents in arctic data repositories like ACADIS, AMD and NSIDC. Most polar geosciences data centers have a difficult time answering analytic questions about their data repositories because of their bias toward high volume scientific data over textual data; due to the popular belief that textual data is less voluminous and hence is less meaningful. Our work is motivated by a desire to understand trends and draw insights from the neglected textual data collected in the polar geosciences community. Our studies indicate significant amounts information can be gleaned from the text in documents. We find that the literature in this text is spatially and temporally rich. It describes a wide array of issues pertaining to the arctic region like oil spills, glacier retreat, sea level rise (etc). It contains a diverse set of scientific measurements and observations captured in by field, airborne instruments and spaceborne sensors (eg ice core and weather station data, high resolution LIDAR snow depth measurements and ICESat elevations and waveform returns). We have built a scalable end-to-end analytics pipeline with Open Source technologies out of the Apache Software Foundation. This pipeline crawls data from various polar data repositories, extracts textual information and builds an index of rich features for each given document. Our visualization module then uses these enriched features to mine insights about arctic ecosystem with context from predefined semantic knowledge about the polar domain (JPL SWEET). We use Sparkler (an evolution of Apache Nutch) to crawl the polar data repositories. Sparkler is a new distributed web crawler which is developed in-house by USC Data Science team. This crawler is heavily inspired from Apache Nutch and handshakes with many other Apache projects thereby supporting the open source community and pushing the limits for further development. We use Apache Tika to extract text and metadata from any document. We convert non-textual multimedia files like audio and images into text through open source transcription and computer vision libraries integrated into Tika. We then build enriched feature sets from the Tika refined text; with locations, dates, measurements and terms-of-interest extracted out using Tika’s GeoParser, GrobidQuantitiesParser and NERParser. With Wrangler, an NSF funded supercomputer, managed by TACC (Texas Advanced Computing Center) we are able to scale our pipeline to crawl and extract insights from hundreds of thousands of documents. For multiple analytic use cases, we find that reasonable correlation between generated trends and real world data.","",""
0,"Caitlin Kearney, Jiri Hron, Helen Kosc, Miri Zilka","Beyond Use-Cases: A Participatory Approach to Envisioning Data Science in Law Enforcement",2024,"Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency","","https://www.semanticscholar.org/paper/78d3e0781a1d3265a9bb688915460f7853827ff0","",168,"2025-02-06 14:32:15","Book","10.1145/3630106.3659007","","",,,,,0,0.00,0,4,1,"With a rising number of law enforcement agencies facing budgetary cuts, many turn to data science in an attempt to maintain service quality with fewer resources. A number of thus adopted solutions–including facial recognition, predictive policing, and risk assessments–have been contested by researchers and journalists alike. Yet comparatively little research is done at the strategy level, which determines where data science will be deployed in the first place. In this study, we interview 40 practitioners from Police Scotland, investigating what they believe to be crucial to successfully incorporate data science in their ways of working. Bucking the external trend, the participants distanced themselves from tools like facial recognition and risk assessment. Instead of focusing on individual use-cases, their primary concerns for the future were around (i) systemic issues around data is collection and use, (ii) goal misalignment between leadership and operational levels, (iii) the fear that datafication may undervalue important aspects of policing, and (iv) appropriate ways of interaction between data science teams and operational officers. Alongside the insights particular to Police Scotland, our work reaffirms how participatory approaches can go beyond the technical, and uncover structural and political barriers to success.","https://dl.acm.org/doi/pdf/10.1145/3630106.3659007",""
0,"K. Ramanathan, Sara C Wolski, Zain Nensey, Raniel Marc Barcenas, William Nowel","Jabil Balancing Risk In A New Frontier",2020,"","","https://www.semanticscholar.org/paper/7575d8f527b4fef9ff51599577117b6442245a23","",169,"2025-02-06 14:32:15","","10.28945/4560","","",5,,1,22,0,0.00,0,5,5,"Candy Mitchell, Information Technology Director at Jabil Inc., sank into her desk chair and looked out the window pensively. She had just finished reading a report from her team of data scientists about a predictive model they had created. She saw huge potential in this model as a potential solution to power Jabil’s customer growth strategy. Part of the strategy was to engage with technology startup companies to be their partner of choice from ideation to supply chain management. Working with technology startups would be new for Jabil and could create huge returns (when one of those technology startups took off, so would Jabil). Typical customers for Jabil (a manufacturing solutions provider that delivers comprehensive design, manufacturing, supply chain and product management services) ranged from FORTUNE® 500s to governments. Mitchell knew how risky startup customers could be, and Jabil only wanted to work with financially stable companies. To serve Jabil’s new strategy, Mitchell placed priority on finding a way to reliably vet the startups’ creditworthiness to avoid bad debt. The third-party credit rating agencies Jabil used could only provide a score for large companies with accessible financial information and history. Mitchell’s computer pinged with a calendar reminder – it was almost time for her next update meeting with her data science team. So far, their model had achieved an accuracy rate of 86%. This was promising but not yet good enough. Mitchell knew they would have to address this – and soon. The faster a way to test their financial viability could be found, the sooner Jabil could partner with them and profit from them. Mitchell wondered what impact adding more quantitative and qualitative data would have on the creditworthiness prediction model. She knew it could lead to higher accuracy, or it could lead to a redesign, which meant more time and resources. The model had to be accurate, explainable, and auditable. Was it possible to create this model internally at Jabil?","http://pubs.mumacasereview.org/2020/MCR-05-02-Jabil-Ramanathan-p1-22.pdf",""
0,"Moruti Dunstun Langa, Clive Smith","Institutional Competencies for Big Data Analytics in the South African Financial Sector",2024,"Business &amp; IT","","https://www.semanticscholar.org/paper/726f2bf2ecfc2920e56313a0cc385e4fe49f642b","",170,"2025-02-06 14:32:15","JournalArticle","10.14311/bit.2024.02.08","","",,,,,0,0.00,0,2,1,"The South African financial sector faces challenges with big data analytics (BDA), including understanding its role, the risk of replacing managerial decision-making and identifying necessary institutional competencies (ICs). Globally, BDA is crucial for performance and competitive advantage, emphasising management’s need to comprehend BDA and related ICs. Research with 10 senior management individuals highlighted five fundamental ICs for BDA implementation: leadership, business acumen, data science knowledge, new job roles and functional governance. The theoretical frameworks included resource-based theory, social cognitive theory and the diffusion of innovation theory. The findings stress the importance of enhanced leadership engagement, governance frameworks, business acumen and stronger data science roles alongside the development of new positions in BDA. Continuous development of suitable ICs is vital for improving organisational performance in the evolving BDA landscape.","",""
0,"Y. Chen, A. Moreno, Skylar Johnson","Skillsets for Success: Careers in Big Data",2017,"","","https://www.semanticscholar.org/paper/6f405014a6cd7b1ef2a23d0d4e1a4d277719d534","",171,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,3,8,"In recent years, “big data” has exploded into the public consciousness. Businesses in virtually every industry today sit atop troves of data and are increasingly turning to data science professionals to extract their value and create insights. The Bureau of Labor Statistics projected that computer and information technology-related occupations will grow by 13% from 2016 to 2026, with demand skyrocketing for professionals in cloud computing, information security, and data science roles.","",""
0,"A. Shroufi, M. Garbuzov, M. McPherson","1895 Three-year nationwide analysis of falls risk prescribing for over 65 care home and non-care home patients",2024,"Age and Ageing","","https://www.semanticscholar.org/paper/6d8ee61b8fddbf5b98b0898f40fe84be210277ab","",172,"2025-02-06 14:32:15","JournalArticle","10.1093/ageing/afad246.097","0002-0729","",,,,,0,0.00,0,3,1,"In 2021 the NHS Business Services Authority Data Science team openly published the first comprehensive nationwide analysis of over 65 care home versus non-care home prescribing (https://nhsbsa-data-analytics.shinyapps.io/estimated-prescribing-patterns-for-care-home-patients/). The analysis has been expanded to include three years of prescribing data and key falls risk prescribing metrics, offering new insight into falls risk prescribing for the over 65s in England. Patient address information from 800m prescription forms was matched against 35m Ordnance Survey Address Base addresses. Patient addresses from prescription forms were classified as belonging to a care home or otherwise. Prescribing metrics around volume, cost, polypharmacy and falls risk were generated, with falls risk metrics informed by the STOPPFall study drug groups (https://www.prescqipp.info/umbraco/surface/authorisedmediasurface/index?url=%2fmedia%2f6019%2f300-medication-and-falls-20.pdf). These metrics were the mean number of falls risk medicines and proportion of patients prescribed three or more falls risk medicines within a given month. Over 65 care home patients received more prescribing of falls risk drugs than non-care home patients, whilst the proportion of care home patients on three or more falls risk drugs within a given month was double that of non-care home patients. Nearly 40% of care home patients aged 65-69 were prescribed three of more falls risk drugs within a given month, far more than both older care home patients and non-care home patients. Falls risk prescribing metrics displayed a great deal of variation by ICS and Local Authority. Aside from headline figures and key findings, the analysis (due for public release in September 2023) allows granular analysis of over 65 falls risk prescribing, by patient age band, gender, geography and care home setting. The exploratory nature of the analysis lends itself to further investigation by healthcare analysts and clinicians, with the aim to gather feedback, iterate and expand the content annually.","",""
0,"Marta Stelmaszak, Kelsey Kline","Managing Embedded Data Science Teams for Success: How Managers Can Navigate the Advantages and Challenges of Distributed Data Science",2023,"Issue 5.2, Spring 2023","","https://www.semanticscholar.org/paper/6d0bcb27a65ecbe52f123f8380667c0bc01517c2","",173,"2025-02-06 14:32:15","JournalArticle","10.1162/99608f92.1f068331","","",,,,,0,0.00,0,2,2,"","https://hdsr.mitpress.mit.edu/pub/wfr9k3vq/download/pdf",""
0,"P. M. Duncan, N. Smith, M. Romanchikova","DATA METROLOGY FOR LIFE SCIENCES, MEDICINE AND PHARMACEUTICAL MANUFACTURING",2022,"Proceedings of the First International IMEKO TC6 Conference on Metrology and Digital Transformation - M4Dconf2022","","https://www.semanticscholar.org/paper/6b2fdd942d0ffb319cad5cb7ee6e756e7b43711e","",174,"2025-02-06 14:32:15","Conference","10.21014/tc6-2022.025","","",,,,,0,0.00,0,3,3,": In many disciplines, such as physics and engineering, the application of tools to support data metrology is encouraged and embedded in many processes and applications while in the life sciences, medicine and pharmaceutical manufacturing sectors these tools are often added as an afterthought, if considered at all. The use of data-driven decision making and the advent of machine learning in these industries has created an urgent demand for harmonised high-quality, instantly available, datasets across domains. The Findable, Accessible, Interoperable, Reproducible principles are designed to improve overall quality of research data. However, this alone does not guarantee that data is fit-for-purpose. Issues such as missing data and metadata, insufficient knowledge of measurement conditions or data provenance are well known and can be aided by applying metrological concepts to data preparation to increase confidence. This work presents the data metrology projects conducted by the National Physical Laboratory Data Science team in healthcare applications.","https://www.imeko.org/publications/tc6-2022/IMEKO-TC6-2022-025.pdf",""
0,"Silu Huang","Effective Data Versioning for Collaborative Data Analytics",2020,"Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data","","https://www.semanticscholar.org/paper/6a6ff2f368adbb1dae48b7bebbb8e6d31a332c0f","",175,"2025-02-06 14:32:15","JournalArticle","10.1145/3318464.3394027","","",,,,,0,0.00,0,1,5,"With the massive proliferation of datasets in a variety of sec-tors, data science teams in these sectors spend vast amounts of time collaboratively constructing, curating, and analyzing these datasets. Versions of datasets are routinely generated during this data science process, via various data processing operations like data transformation and cleaning, feature engineering and normalization, among others. However, no existing systems enable us to effectively store, track, and query these versioned datasets, leading to massive redundancy in versioned data storage and making true collaboration and sharing impossible. In my PhD thesis, we develop solutions for versioned data management for collaborative data analytics. In the first part of my dissertation, we extend a relational database to support versioning of structured data. Specifically, we build a system, OrpheusDB, on top of a relational database with a carefully designed data representation and an intelligent partitioning algorithm for fast version control operations. OrpheusDB inherits much of the same benefits of relational databases, while also compactly storing, keeping track of, and recreating versions on demand. However, OrpheusDB implicitly makes a few assumptions, namely that:(a) the SQL assumption: a SQL-like language is the best fit for querying data and versioning information;(b) the structural assumption: the data is in a relational for-mat with a regular structure;(c) the from-scratch assumption: users adopt OrpheusDB from the very beginning of their project and register each data version along with full meta-data in the system. In the second part of my dissertation, we remove each of these assumptions, one at a time. First, we remove the SQL assumption and propose a generalized query language for querying data along with versioning and provenance information. Second, we remove the structural assumption and develop solutions for compact storage and fast retrieval of arbitrary data representations [4]. Finally, we remove the ""from-scratch"" assumption, by developing techniques to infer lineage relationships among versions residing in an existing data repository.","https://www.ideals.illinois.edu/items/112814/bitstreams/369753/data.pdf",""
0,"Aaron Jones, Adam McElligott, Bonnie Romeo, Eric Whiteman, Erin Williams, McElligott Cadets Jones","Co-Travel Algorithm Development: Initial Steps",2021,"","","https://www.semanticscholar.org/paper/6a13f425464bbf3c58911cc458bfdca1720bfa43","",176,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,6,4,"Author Note: Cadets Jones, McElligott, Romeo and Whiteman are Cadets at the United States Military Academy. The Cadets completed this project under supervision of advisor MAJ Erin Williams, an instructor in the Department of Systems Engineering. The USMA Cadet-led Data Science team worked in partnership with Accenture, a leading innovation company, working towards evolving intelligence capabilities in certain contracted military capacities. Abstract: The co-travel algorithm seeks to utilize Open-Source Intelligence (OSINT) to systematically compute and identify high value targets using advertising technology data sets. The OSINT discipline is a quickly evolving type of intelligence that could grant a significant advantage to ground combatants. Co-travel refers to devices moving together. It can establish critical relationships between individuals. The co-travel algorithm can be separated into four main functions: pattern of life, anomaly detection, device correlation, and co-traveler. These functions will assist the algorithm in enabling Army OSINT Enterprise to ultimately track persons of interest and uncover locations of interest. The Cadet Data Science Team uses k-means clustering and density-based spatial clustering application with noise (DBSCAN) to establish a pattern of life and detecting anomalies within an OSINT data set. The team also produces a functional R Shiny application to enable intelligence analysts to quickly analyze geotemporal dataset and visualize results. While the full Co-Travel algorithm remains unfinished, this report details the progress that was made by the Cadet Data Science team over the course of an academic year.","",""
0,"Allison Hutchison","Teaching Communication in Context: Rhetorical Moves in Data Science Reports",2024,"2024 IEEE International Professional Communication Conference (ProComm)","","https://www.semanticscholar.org/paper/647fa980e39332501946b859427b3a260ba23db0","",177,"2025-02-06 14:32:15","JournalArticle","10.1109/procomm61427.2024.00054","","",,,238,244,0,0.00,0,1,1,"This study involves a data science and machine learning course partnered with an engineering communication course—referred to here as an authentically integrated communication model—and offers insights into such a model for engineering educators. In these partnered courses, student teams apply data science and machine learning tools to conduct data analysis and write two data science reports. Through qualitative coding and corpus analysis methods, rhetorical moves that students make in the data science report genre were identified. Twelve out of 57 total final reports were randomly chosen and coded, then six corpora of excerpts related to two codes and subcodes were created to generate keyword lists. These codes were ""results,"" ""discussion,"" as well as ""ineffective"" and ""effective"" subcodes for each main code. The total codes were then compared to one another according to students' enrollment in both courses. Overall, students' reports in the engineering communication class more often contained effective results and effective discussion excerpts. Keywords along with example sentences are provided to demonstrate greater context for the use of language in the data science report genre.","",""
0,"Thanathip Chumthong, Kulsawasd Jitkajornwanich, Obada Kraishan, Kerk F. Kee, Akan Narabin","Leveraging Race Prediction Algorithms to Enhance Team Composition in Big Data Science Teams",2024,"2024 IEEE International Conference on Big Data (BigData)","","https://www.semanticscholar.org/paper/62bb1234251acd74f56e54737fe416a1302adc0e","",178,"2025-02-06 14:32:15","Conference","10.1109/BigData62323.2024.10825329","","",,,3105,3113,0,0.00,0,5,1,"As big data science projects scale in complexity, optimizing team composition has become vital for improving creativity, productivity, and project success. We explore the possibility of incorporating race prediction algorithms for enhancing racial diversity in team composition in big data science projects. This paper evaluates five race prediction algorithms—wru, ethnicolr, ethnicolr2, pyethnicity, and rethnicity—and then discuss their potential in supporting racially diverse team assembly in big data projects. Utilizing three datasets, we assess algorithm performance and applicability, emphasizing their role in building balanced teams that enhance agility, inclusivity, and bias mitigation. We present an actionable methodology for integrating demographic insights into team management. In addition, we propose ethical safeguards to ensure responsible race prediction use, recommending data privacy measures, aggregate-only data handling, and transparency in communication. We argue that when used within ethical constraints, race prediction can support robust team processes, reduce reliance on less diverse teams, and ultimately facilitate more creative and equitable big data project outcomes.","",""
0,"Ahmad Al-Taha, Tariq Al-Sulaimani, AL-Salt Al-Bahri","Wells Around Formation Issues WAFI Tool-Machine Learning Tool to Extract Field Issues from Daily Reports",2023,"Day 2 Tue, October 03, 2023","","https://www.semanticscholar.org/paper/60f0ea3005319989bc05090e13e0806d33e5983d","",179,"2025-02-06 14:32:15","Review","10.2118/216201-ms","","",,,,,0,0.00,0,3,2,"The objective of this paper is to share and introduce the Wells Around Formation Issues [WAFI] tool, which was developed by Petroleum Development Oman LLC [PDO] - collaboration between Well Engineering and Data Science teams. This tool's function is to extract Formation Issues from the Daily Drilling Operation Reports [DDOR\ & Other Reports entered by Drilling Site team and display them per formation per field. WAFI is a cutting-edge Well Engineering solution that employs Text Mining techniques to automatically provide offset well information, significantly enhancing efficiency and reducing manual labor spent on data extraction from disparate databases and analysis in Excel.This advanced solution facilitates a deeper understanding of complex relationships between neighboring wells and the well to be drilled. By optimizing this process, our approach aims to effectively pinpoint potential challenge areas, thereby augmenting drilling operations and sustaining overall project success.The tool was trialed in 3 fields in PDO, and it managed to pick up most of the drilling and formation issues identified and expected in each field and in offset wells, based on the Trained Machine Learning Model.The tool picks up the Depth at which the issue occurred, and it links it to the Formation being drilled. The results are viewed in a formation level view or at a Well level view, so it will give an overview of the field issues in offset wells. This will help Team for better planning and preparing for the upcoming wells, and of understanding of the Fields issues.The tool picks up the following Issues: Tight spots, Over Pulls, Reaming and Back Reaming, Vibrations, Stick & Slip, Bit Balling, Fish, Lost Circulation, Fluid Influx, Stuck Pipe & Drill String Failure.The parameters being picked by the model are: Loss Rate range, Flow Rate, Torque, RPM, Overpull and ROP [Rate of Penetration].This is Phase One of the Tool development, and next plan for Phase Two will include more functionalities and more features, Parameters and enhancements to the tool. Both phases will be discussed in this paper.","",""
0,"F. Grodstein","Abstract IA21: Leveraging modern data science to optimize discovery within epidemiologic treasures: Case study—the Nurses’ Health Study",2020,"Cancer Epidemiology, Biomarkers &amp; Prevention","","https://www.semanticscholar.org/paper/5f3e8e7a282a8cb959b6df15b0964ace67963032","",180,"2025-02-06 14:32:15","JournalArticle","10.1158/1538-7755.modpop19-ia21","","",,,,,0,0.00,0,1,5,"Ongoing epidemiologic studies represent national (and international) treasures of data—with information spanning behavior, environment, genetics, genomics, and heath—that are nearly impossible to replicate. Many existing cancer cohorts uniquely enable full understanding of cancer etiology and prognosis by integrating multiple data types, and providing data across years of follow-up, often both before and after cancer diagnosis. These combinations of many data types and many years of follow-up are critical to effective research and discovery, since cancers develop and progress over years, if not decades, and result from the combined influence of behavior, environment, and genomics. However, facilitating and simplifying the full utilization of complex epidemiologic data by an array of interdisciplinary scientists is a large endeavor. In particular, many cohorts still operate with data management, access, and analytic systems that date to their initiation—many years before modern data science and computing approaches existed. Updating of systems for leveraging cohorts is necessary across many fronts; as a case study, the Nurses’ Health Study has been working on the following span of projects to create new, cloud-based platforms for research: 1. Data Management: (i) organize all data into a small number of files (e.g., one for questionnaire data, one for disease data, one for biomarker data, etc.) that are easy to find and use; (ii) harmonize data across all time periods of follow-up; and (iii) clean all data to remove stray codes and notations. 2. Data Visualization: develop software that generates visualizations of participant profiles, spanning behavior, environment, genomics, and diagnoses/health outcomes. 3. Data Analysis: create a suite of interfaces to open-source tools enabling researchers to: (i) create phenotypes and behavioral variables; (ii) access, filter, and merge biologic and genomic data; (iii) integrate cancer data; and (iv) conduct statistical analyses. 4. Training/Education: develop documentation and educational materials for all data, tools, and software, designed to empower investigators and reduce extraneous efforts in scientific exploration of epidemiologic data. There have been many initial successes (examples will be presented), heavily supported by teaming with data science experts from prominent institutions and industry, who bring modern tools, software, and knowledge to epidemiology and computing. Ongoing challenges include identifying funding sources for such large infrastructure projects, especially data management tasks, which are not highly marketable. Psychological barriers exist as well in convincing multiple generations of investigators to learn new systems and skills. Overall, modernizing large cancer cohorts is an intimidating although crucial venture, which will permit fully leveraging existing cancer epidemiology cohorts to accelerate novel research into cancer prevention and treatment. Citation Format: Francine Grodstein. Leveraging modern data science to optimize discovery within epidemiologic treasures: Case study—the Nurses’ Health Study [abstract]. In: Proceedings of the AACR Special Conference on Modernizing Population Sciences in the Digital Age; 2019 Feb 19-22; San Diego, CA. Philadelphia (PA): AACR; Cancer Epidemiol Biomarkers Prev 2020;29(9 Suppl):Abstract nr IA21.","",""
0,"Brian Wright, Peter Alonzi, Ali Riveria","The Future of Data Science Education",2024,"ArXiv","","https://www.semanticscholar.org/paper/5bf704bc6bcaa719eb050957d96c5d314909fb91","",181,"2025-02-06 14:32:15","JournalArticle","10.48550/arXiv.2407.11824","2331-8422","",,,,,0,0.00,0,3,1,"The definition of Data Science is a hotly debated topic. For many, the definition is a simple shortcut to Artificial Intelligence or Machine Learning. However, there is far more depth and nuance to the field of Data Science than a simple shortcut can provide. The School of Data Science at the University of Virginia has developed a novel model for the definition of Data Science. This model is based on identifying a unified understanding of the data work done across all areas of Data Science. It represents a generational leap forward in how we understand and teach Data Science. In this paper we will present the core features of the model and explain how it unifies various concepts going far beyond the analytics component of AI. From this foundation we will present our Undergraduate Major curriculum in Data Science and demonstrate how it prepares students to be well-rounded Data Science team members and leaders. The paper will conclude with an in-depth overview of the Foundations of Data Science course designed to introduce students to the field while also implementing proven STEM oriented pedagogical methods. These include, for example, specifications grading, active learning lectures, guest lectures from industry experts and weekly gamification labs.","",""
0,"S. Gudowski, Margarete Pierce, B. Fuchs, Michael J. Frazer","Rapid Liberation From Mechanical Ventilation, the ICU and Hospital by Using an ICU Dashboard and Alert Program",2018,"Respiratory Care","","https://www.semanticscholar.org/paper/57e65886a2149dde7809443023df897495d04aec","",182,"2025-02-06 14:32:15","JournalArticle","","","",63,,,,0,0.00,0,4,7,"Background: At the Hospital of the University of Pennsylvania, respiratory therapists (RTs) are required to assess for spontaneous breathing trial (SBT) readiness on all ventilated patients every morning. The RTs manually assess for SBT readiness by gathering different parameters from the electronic health record (EHR). This can become somewhat burdensome in a busy ICU. In addition patients may be ready for SBT at any time throughout the day and more frequent readiness assessments could expedite the liberation process. Our committee looked to leverage the EHR to create a novel program that will continuously screen EHR elements to assist the care team with ongoing SBT readiness assessments. Methods: A novel computer program (called the ABC App) was created, in collaboration with the Data Science team and Penn Center for Innovation to continuously screen all vented patients in the MICU by extracting data from the EHR. The information is then displayed in real-time on an ICU Dashboard, with green indicating SBT ready and red for Not SBT ready. When patients meet criteria for SBT readiness, the system alerts the RT via text message to do an SBT. If the patient is over sedated (based on RASS) the RN and providers are also prompted via text alert to address sedation. For patients not meeting readiness criteria, the parameters limiting weaning (ie, FIO2 or PEEP) are displayed on the dashboard with icons to nudge clinicians to consider weaning that parameter. The ICU dashboard and alerts were implemented in the HUP MICU for a 6-month pilot assessment. Results: Duration of ventilation decreased from 4.6 to 4.0 d. ICU LOS decreased by 1.2 d and hospital LOS dropped by 1.4 d. Conclusions: A real-time electronic dashboard and alert system affected a reduction in duration of mechanical ventilation and ICU length of stay. The RTs have found the text alerts and dashboard to be highly beneficial in the ICU with many competing priorities. With these positive results, we plan to expand the ICU dashboard and text alerting system to all ICUs in the Penn Medicine Health System.","",""
0,"Richard Searle, P. Gururaj, S. Gaikwad, Kiran Kannur","Secure federated machine learning with flexible topology and distributed privacy controls",2023,"","","https://www.semanticscholar.org/paper/5146c848c597b9f364d01a19d9a9ab010b6425ce","",183,"2025-02-06 14:32:15","","10.1117/12.2663767","","",12542,,125420,,0,0.00,0,4,2,"Federated machine learning (FML) for training of deep neural network models is a useful technique where insufficient sample data is available at a local level. In applications where data privacy must be preserved, such as in health care, financial services, and defense contexts, it is important that there is no exchange of data between constituents of the distributed network. It may also be desirable to protect the integrity and secrecy of the algorithms and trained models deployed within the network. Demonstrating the privacy-enhancing technology of Confidential Computing, we present a novel solution for FML implementation that supports extensible graph-based network topology configuration under federated, distributed, or centralized training regimes. The presented solution provides for policy-based control of model training and automated monitoring of model convergence and network performance. Owners of private datasets can retain independent control of their data through local encryption, while global data anonymization policies can be applied over the sample data. Full auditability of the model training process is provided to distributed data owners and the model owner using hardware-based cryptographic secrets that underpin zero-trust implementation of the training network. Operation of the proposed secure FML solution is discussed in the context of model training over distributed radiological image data for weakly-supervised learning and classification of common thorax diseases. Cross-domain adaptation of the proposed solution and integrated model integrity protection against adversarial attacks reflects a breakthrough technology for data science teams working with distributed datasets.","",""
0,"G. S. Payette, J. R. Bailey, P. Pastusek, Y. Witt-Doerring, N. Kostov, K. Shukla, S. G. Haugen","Well Construction in the Era of Big Data: It's not Data Analytics, It's Engineering with Data",2024,"Day 1 Tue, March 05, 2024","","https://www.semanticscholar.org/paper/4dabd4b1d3050fc4cd09c7aa57402eef2a6c39d0","",184,"2025-02-06 14:32:15","JournalArticle","10.2118/217665-ms","","",,,,,0,0.00,0,7,1,"In this paper we make the case that data science captures value in well construction when data analysis methods, such as machine learning, are underpinned by first principles derived from physics and engineering and supported by deep domain expertise. Despite receiving wide attention in recent years, many organizations currently struggle to derive value from their data science efforts. In our experience, disappointment arises for a multitude of reasons, which we discuss in detail. Key issues that often hinder value capture include poor data management, challenges in working with WITSML data, lack of well construction domain expertise by data science teams, inadequate use of physics and engineering and failure to adopt data science solutions into existing or new well construction workflows. Although by no means comprehensive, we provide a summary of important data that pertains to the well construction process. We further discuss high-level areas where data science can add value to well construction through analysis of such data. Data science initiatives typically fit within at least one of the following categories: Historical Studies, Well Planning, Real-Time Well Construction Execution and Post-Drill Learning Capture. Historical studies are often good places for data science teams to initially focus their efforts. However, as insights are drawn and potential for value is shown, organizations should consider extending capabilities developed to carry-out historical studies to support well planning and real-time well construction execution workflows. A large portion of this paper is dedicated to discussing ways that organizations can work to improve their abilities to derive value from data science efforts. Most of the discussion focuses on steps that data science teams can take today. However, our commentary on data management and governance is more forward looking. Important topics which we cover include: Data management and governance. Serving data to data scientists. Working with WITSML data. Basic skills and technologies needed by data science teams. Importance of building common capabilities for working with data. Need for physics and engineering to inform data analysis. Importance of identifying data quality issues. Importance of activity-based data filtering when working with WITSML data. Dysfunction detection using WITSML data. Application of statistics and machine learning. We conclude by examining several historical data science case studies for well construction. Each example highlights the need to connect data and some physical or engineering process (i.e., ""engineering with data"") to deliver value through data science.","",""
0,"Joshua Noble","Measuring Services and Inferring Causes",2024,"Touchpoint","","https://www.semanticscholar.org/paper/49b7d7dcb738d38c5c8a91bca2052cc8125a32cb","",185,"2025-02-06 14:32:15","JournalArticle","10.30819/touchpoint.15-2.02","1868-6052","",,,,,0,0.00,0,1,1,"Today, designers are bringing both data and data practitioners into the design process in increasingly diverse ways. These sorts of collaborations were once orchestrated by overarching product teams without input from a design team, but now, design teams have become active collaborators. ‘Data thinking’ and quantitative reasoning can be applied in the design process itself, rather than simply to the products of the design process. This often involves partnering with analytics or data science teams throughout the design process, instead of at the end of the process when seeking to evaluate output.","",""
0,"Tianshu Sun","Monetizing Sharing Traffic through Incentive Design : Evidence from A Randomized Field Experiment 1",2015,"","","https://www.semanticscholar.org/paper/49ad9e88ace59917885c0dbebc9b283a91a67711","",186,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,1,10,"Despite the large volume of information sharing across digital platforms, no study has systematically investigated how firms can monetize such sharing traffic. Our study examines whether and how firms can engage customers involved in online sharing, through the design of novel incentive mechanisms. We design and implement a large-scale randomized field experiment to test the effectiveness of different incentive designs in converting customers in the share. We find evidence that incentive design has a significant impact on both sender's purchase and referrals, but in a different ways. Specifically, compared to the senders who receives nonshareable promotional code, senders who receives shareable code are less likely to make purchase themselves, but much more likely to make further referrals. We further leverage exogenous variation in incentive design to untangle three motives underlying the sender’s sharing -self-regarding motive (sender's interest in the product), other-regarding motive (sender's interest in the recipient), or group-regarding motive (sender's interest in purchasing the product with the recipient). We find evidence that the effect of incentive designs critically depends on the motive underlying the sender’s sharing. We discuss how firms can customize incentive design at individual level based on such sharing motive. Our findings not only provide practical implications for firms to monetize sharing traffic, but also shed light on theoretical underpinnings of sharing. 1 Tianshu Sun is a doctoral student and Siva Viswanathan is an Associate Professor at the Robert.H.Smith School of Business, University of Maryland. Elena Zheleva heads the Data Science team at LivingSocial Inc. 2 The bulk of this study is done by a doctoral student (Tianshu Sun). Monetizing Sharing Traffic through Incentive Design","",""
0,"A. Ocampo, G. Farah, Ernesto Gutiérrez","Towards a Self-Serving Big Data Analytics Platform for Oil and Gas",2019,"Day 2 Tue, November 12, 2019","","https://www.semanticscholar.org/paper/489ecce3db5b57e8381641a62d0febdaa67cdaa5","",187,"2025-02-06 14:32:15","JournalArticle","10.2118/197386-ms","","",,,,,0,0.00,0,3,6,"Organizations today, especially in the oil and gas sector, are swimming in data [1] but most of them manage to analyze only a fraction of what they collect. To help build a stronger data-driven culture, many organizations, starting with technology companies, are adopting a new approach called self-service analytics. In this paper, we present our big data and analytics architecture that has enabled our in-house and outsourced engineering, and data science teams, to develop self-serving AI models and data pipelines. Our architecture is presented to the reader in such a way that he/she can apply it using the cloud provider of their choice by translating the concepts presented here, either to native cloud PaaS or using open source products.","",""
0,"Theo Härder","Editorial",2010,"Datenbank-Spektrum","","https://www.semanticscholar.org/paper/455d2d0fedea881e515c5db5dcbbbceb062d24e5","",188,"2025-02-06 14:32:15","JournalArticle","10.1007/s13222-019-00328-5","1618-2162","",19,,161,163,0,0.00,0,1,15,"","https://link.springer.com/content/pdf/10.1007/s13222-019-00328-5.pdf",""
0,"Doug Rose","Thinking Like a Data Science Team",2016,"","","https://www.semanticscholar.org/paper/3fdd95000287e14c3f8c85d9b38bb546d9d1688b","",189,"2025-02-06 14:32:15","","10.1007/978-1-4842-2253-9_9","","",,,77,84,0,0.00,0,1,9,"","",""
0,"SK Althaf Rahaman, K. D. Priyanka, M. Likitha, G. P. Kumar, L. Madhu","Patient Admission Projection Using Facebook Prophet",2024,"International Journal of Innovative Research in Computer and Communication Engineering","","https://www.semanticscholar.org/paper/3ddc32e2946a9a7add06dea22e123f6874061b87","",190,"2025-02-06 14:32:15","JournalArticle","10.15680/ijircce.2024.1202043","2320-9798","",,,,,0,0.00,0,5,1,"Healthcare facilities face the continual challenge of managing patient admissions efficiently while maintaining high standards of care. Accurate forecasting of patient admissions is crucial for optimizing resource allocation, ensuring adequate staffing, and enhancing overall operational efficiency. To address this challenge, this research paper explores the application of Facebook Prophet, an advanced time series forecasting tool, in predicting patient admissions within healthcare facilities. Facebook Prophet, a specialized time series forecasting model developed by Facebook's Core Data Science team, is then employed to model and predict patient admissions. Facebook Prophet is particularly well-suited for handling time series data characterized by seasonality, trends, and special events. The model's flexibility and ease of use make it an ideal choice for healthcare providers seeking to leverage advanced analytics techniques for predictive purposes. In the implementation of Facebook Prophet, the model is meticulously trained and validated using the pre-processed historical admission data. The model's ability to capture complex temporal patterns, including seasonality and special events such as holidays or outbreaks, is thoroughly evaluated. By incorporating these patterns into the forecasting process, the model can provide accurate predictions of future patient admissions. By accurately predicting patient admissions, healthcare facilities can optimize resource allocation, streamline operations, and ensure adequate staffing levels to meet patient demand. Additionally, the model enables healthcare providers to proactively plan for special events or seasonal fluctuations in admission rates, further enhancing operational efficiency. The application of Facebook Prophet holds significant promise for improving patient care delivery and operational outcomes in healthcare facilities.","",""
0,"Salim Deshmukh, Tore Larsen, Shanta Seereeram","Digitalized Next Generation Mono Ethylene Glycol Regeneration Systems",2020,"Day 3 Wed, November 11, 2020","","https://www.semanticscholar.org/paper/3d2d586a211b3946640aca2f8d99b6c73cbf06f6","",191,"2025-02-06 14:32:15","JournalArticle","10.2523/iptc-19927-ms","","",,,,,0,0.00,0,3,5,"Offshore natural gas fields are normally developed based on multiphase flow. One of the key challenges for such flow lines may be the risk of gas hydrate formation. This risk can be mitigated by injecting Mono Ethylene Glycol (MEG) into the flow line as a thermodynamic hydrate inhibitor. Due to the large volumes of costly glycol required and the desire to minimise the environmental footprint, the glycol is regenerated on topside or onshore facilities. Presence of salts in the MEG systems make it more challenging to operate them and having full control over the chemistry within the MEG system is key to have successful operation. Today chemistry control within MEG system is largely done by manual sampling and lab analysis as online analysers are either not available or not qualified for the service. Having robust online analysers that can measure water, MEG, pH stabiliser and dissolved salts will minimize these challenges and enable remote operations of the MEG systems. A Digitalization platform enabling condition monitoring and remote operations system to optimise performance and maintenance efforts on the MEG Regeneration and Reclamation Systems is being developed. The system collects digital input from sensors, analysers, instruments and controllers on the onshore or offshore assets to monitor system behaviour. The uniqueness of the approach to remote operations is our unparalleled process and chemistry expertise in combination with our in-house data science team to produce a system-wide view of the MEG Regeneration and Reclamation system. Current and historical data from MEG Regeneration system are ingested into the data platform, and through custom algorithms, provides full visualisation of the system performance and condition monitoring of critical components within the system. The operating conditions are characterized to reduce downtime and operating costs and maximise production. Online monitoring of the composition of rich- and lean MEG and formation water breakthrough can improve predictability of the scaling tendency and operation of the MEG plant. This can be achieved by having a qualified set of online analysers that can measure MEG, water and ionic composition online. With this enhanced visibility of the performance and predictive analysis, the need for site visits and troubleshooting efforts can be reduced and repeat failures and unplanned downtime can be prevented. The digitalization platform and work approach has already been successfully implemented on Sulphate Removal Units/Water Injection Technologies but are new to MEG systems. Qualification programs of critical parameters such as MEG content, chloride and divalent cation ion measurements are being carried out in parallel as part of the digitization efforts. Selected results from testing of online analysers and the key features from the digitalization platform are presented in this paper. An online analyser has been tested for simultaneously measuring MEG, water, organic acids and MDEA. The analyser was able to measure these concentrations with a deviation (difference in wt.% concentration) of 0.3 to 0.5%. The impact of relevant process temperature on the MEG and water analysis was minimal. Similarly, an online analyser has been tested for measuring chloride and divalent ions in presence of MEG. The limit of detection for chloride was about 3 to 9 ppm depending upon the measurement time. The limit of detection for Ca2+and Ba2+ was 3-9ppm and for Sr2+ and Fe2+ was 0.1 to 0.5 mg/l.","",""
0,"Vanessa Hanschke, Dylan Rees, Merve Alanyali, David Hopkinson, Paul Marshall","Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams",2024,"Proceedings of the CHI Conference on Human Factors in Computing Systems","","https://www.semanticscholar.org/paper/392a1d45253930eee7d93eb714195577c684304d","",192,"2025-02-06 14:32:15","JournalArticle","10.1145/3613904.3642402","","",,,,,0,0.00,0,5,1,"Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team’s specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics and values.","https://dl.acm.org/doi/pdf/10.1145/3613904.3642402",""
0,"Patric Wicht, Alexandra Hausmann, S. Hoseini, J. Kaufmann","Aufbau eines Data-Science-Teams – „Lessons learned“",2021,"Wirtschaftsinformatik & Management","","https://www.semanticscholar.org/paper/370d62c40cdfeff320d0b0ac4028711e9380265f","",193,"2025-02-06 14:32:15","JournalArticle","10.1365/s35764-021-00350-x","1867-5905","",13,,266,275,0,0.00,0,4,4,"","https://link.springer.com/content/pdf/10.1365/s35764-021-00350-x.pdf",""
0,"Jack Smith","Activity Plant Sensor Data Toolkit Time Period Nov 2014 – Feb 2015 Episode Description Competency Element Claimed",2017,"","","https://www.semanticscholar.org/paper/331e7f9258558a145a55d42b97259d930b241268","",194,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,1,8,"Episode Description Competency Element Claimed As part of my professional practicum experience for the MPE (Mechanical Engineering), I completed HX Energy’s Summer Vacation program in their Data Science division. This work experience focused on optimising and expanding HX Energy’s capabilities through multifaceted techniques involving data analytics, predictive algorithms and cognitive computing. HX Energy operations involve the monitoring of plant performance and metrics via the use of sensors. Over my period at HX Energy, my project involved the construction of a program labeled as a toolkit to improve the process of inspecting sensor data. More specifically, my task was to improve the capabilities of the HX Energy Data Science team by deploying a resource that could be readily used to swiftly inspect the behavior, health status and correlation of a set of sensors for a given time period. Introduction","",""
0,"Bee Ching Yap","Sand Control Prediction and Advisory Automation: Malaysia's Cost-Effective Digital Transformation that's Contributing to Sustainability",2024,"APOGCE 2024","","https://www.semanticscholar.org/paper/31324906c1e63c9b8cbd5f970be6a6e101c44a71","",195,"2025-02-06 14:32:15","JournalArticle","10.2118/221301-ms","","",,,,,0,0.00,0,1,1,"Malaysia Petroleum Management (MPM) has embarked on a digital transformation journey of cloud-based sand control prediction and advisory automation with the support of PETRONAS Carigali and data science teams to address the oil and gas wells sanding pain points. Leveraging on its local regulatory advantage, consisting of petroleum engineering expertise and mass data from all the operating fields, the digitalisation of offset data into machine learning (ML) has enabled the nation's predictive solution to improve sand management strategy decision making. The intelligent sand management system is developed through reliable ML interpretation principle to tackle the nation's sand control challenges. The system is trained to analyse rock mechanic data using several key parameters to predict unconfined compressive strength (UCS) value as the pre-requisite for sand production prediction. It analyses the subsurface sand management data lake and, with the system calculated UCS value, the suitable downhole sand control (DHSC) method will be advised based on well design inputs. The proposed DHSC design's high level well cost is also generated based on benchmarking. Sand encroachment from producing sand reservoirs is one of the key issues in oil and gas wells. The erosion consequences in production facility due to sand production normally result in well integrity concern, loss of primary containment (LOPC) risk and subsequently the domino effect of undesirable health, safety and environmental (HSE) incident(s) at operators' producing asset. Conventional well completion design addressing sand control requires significant time and resources to gather and perform sanding analyses and risk ranking from scattered subsurface data. Besides that, a costly reservoir sand core sample test and time-consuming studies for its strength normally will be performed to assist in better well design sanding risk profiling. It is common for the executed downhole sand control selection to be sub-optimum, resulting in earlier end of well productivity or costly remedial works. However, the developed system can significantly reduce the sand control selection analyses and decision-making duration. It serves as a solution for the unavailability of core samples for UCS tests, or cost saving for marginal operator on rock mechanic test avoidance. The optimised DHSC algorithm provides better long-term sand control success rate and well life longevity. The system has proven data analytics result of above 0.91 R-Squared (R2) accuracy. A similar approach can be referred by the industry to minimise sand control issue in current cost saving and digital business operating rhythm. This digital transformation approach has also contributed to reducing equivalent greenhouse emission from carbon dioxide (CO2) compared to traditional UCS laboratory test and lengthy DHSC method analysis processes.","",""
0,"Sam Hume, Frederik Malfait, Julie Chason","A Linked Data Model and Hypermedia API for CDISC SHARE 2 . 0",2019,"","","https://www.semanticscholar.org/paper/3021d13768ee7132ad59066b188a76859afd8f5e","",196,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,3,6,"The CDISC SHARE Metadata Repository supports the curation and availability of the CDISC standards using a variety of media types and formats. In this paper we explain the architecture of SHARE 2.0 and its implementation of linked data principles. The SHARE 2.0 system supports a broader set of standards and content types, now including Questionnaires, Rating, Scales (QRS), value subsets, draft domains, and rules in addition to the full scope of foundational standards and controlled terminology. The SHARE 2.0 Model is based on the ISO 11179 standard for Metadata Registries (MDR) and implemented using the W3C Resource Description Framework (RDF). There is a natural fit between web-based HTTP requests for resources and information stored as resources in RDF. We show how RDF resources can be mapped and exposed through a REST based web API and how the graph-based nature of RDF translates into hypermedia capabilities of the SHARE 2.0 API. SHARE 2.0 OBJECTIVES AND SCOPE INTRODUCTION This paper introduces the technical foundations of the CDISC SHARE 2.0 metadata repository (MDR). CDISC plans to release SHARE 2.0 during the first quarter of 2019. The SHARE 2.0 release marks a significant upgrade over the first version featuring a new technology stack, an expanded model, and new content. SHARE 2.0 makes the CDISC data standards metadata available as a linked data model accessed via a hypermedia API. Software clients access the expanded model using a correspondingly expanded API. The SHARE 2.0 MDR provides a cloud-based solution that supports the curation, management, and publication of the CDISC standards metadata in several machinereadable formats (Hume et al., 2018). The new SHARE 2.0 software runs on a technology stack that will be simpler to maintain and extend. SHARE 2.0 DATA STANDARDS CONTENT The SHARE team, part of the CDISC Data Science team, ported SHARE 1.0 content to the expanded SHARE 2.0 model. The SHARE team also curated and imported new standards metadata not available in SHARE 1.0. Table 1 highlights much of the SHARE 2.0 content. Table 1. Highlights of the metadata available in SHARE 2.0 SDTM v1.2 SDTMIG v3.2 ADaM OCCDS v1.0 SDTM v1.3 SDTMIG v3.3 ADaM ADAE v1.0 SDTM v1.4 SDTMIG-AP v1.0 ADaM BDS for TTE v1.0 SDTM v1.5 SENDIG v3.0 CDASH Model v1.0 SDTM v1.6 SENDIG v3.1 CDASHIG v1.1.1 SDTM v1.7 ADaM v2.1 CDASHIG v2.0 SDTMIG v3.1.2 ADaMIG v1.0 Controlled Terminology Packages 2014Q3 2018Q4 SDTMIG v3.1.3 ADaMIG v1.1 In addition to content made available for launch, the SHARE team created a quarterly content update schedule to publish new standards metadata that includes previously unavailable standards metadata as well as new versions of existing standards content. Examples of new content scheduled for loading into SHARE 2.0 in 2019 include:","",""
0,"R. de Graaf","Data Science Team Strategy",2019,"Managing Your Data Science Projects","","https://www.semanticscholar.org/paper/2f886cd8fc58e088199cd7b7641f6fddf599bd8d","",197,"2025-02-06 14:32:15","JournalArticle","10.1007/978-1-4842-4907-9_1","","",,,,,0,0.00,0,1,6,"","",""
0,"C. Carpenter","Study Looks at Well Construction as Engineering With Data",2025,"Journal of Petroleum Technology","","https://www.semanticscholar.org/paper/2f1d0a02fa598883779b1f0971912bbf2f1553db","",198,"2025-02-06 14:32:15","JournalArticle","10.2118/0225-0063-jpt","0149-2136","",,,,,0,0.00,0,1,1,"This article, written by JPT Technology Editor Chris Carpenter, contains highlights of paper SPE 217665, “Well Construction in the Era of Big Data: It’s Not Data Analytics, It’s Engineering With Data,” by Gregory S. Payette, SPE, ExxonMobil; Jeffrey R. Bailey, SPE, consultant; and Paul E. Pastusek, SPE, ExxonMobil, et al. The paper has not been peer reviewed. The authors write that data science captures value in well construction when data-analysis methods such as machine learning are underpinned by first principles derived from physics and engineering and supported by deep domain expertise. The authors provide a summary of important data pertaining to the well-construction process and discuss high-level areas where data science can add value to well construction through analysis of such data. The authors write that it is important for organizations to grow data science and physics-based modeling solutions together; well-construction data science should be what they term an “engineering with data” endeavor. A large portion of the complete paper is dedicated to discussing ways that organizations can improve their abilities to derive value from data-science efforts. Most discussion focuses on steps that data science teams can take today. However, the provided commentary on data management and governance is forward-looking. The paper concludes by examining several historical data-science case studies for well construction. Each example highlights the need to connect data and some physical or engineering process to deliver value through data science. Data Management and Governance. A step that can be taken to enable better holistic well-construction data management is for data collectors and creators to organize their data using data models that center around what the authors term “data entities” that are common and stable across data collectors. Common well-construction data entities include items such as Wells, Wellbores, Hole Sections, Surveys, Casing Strings, Drillstrings and Bottomhole Assemblies (BHAs), Tubing Strings, and Downhole Completion Equipment. These data entities are capitalized in this paper to denote their roles as data entities. The industry is accustomed to organizing data around entities. Two common types of databases particularly relevant to data-science efforts commonly used by operators include the following: - Well Information Management Databases (WIMD)—These databases are used to document information about the life cycle of wells. - Wellsite Information Transfer Standard Markup Language (WITSML) Databases: WITSML databases are primarily used to store time- and depth-series sensor data collected during drilling and completion activities. For the purposes of their paper, the authors do not include other data entities that can be captured through WITSML data repositories. Even though WIMD and WITSML databases share common data entities, such entities typically are not linked to one another through formal relationships at the original database levels. This creates a barrier for data-science projects that require data from both source systems.","",""
0,"Y. Demchenko, Luca Comminiello, T. Wiktorski, J. Cuadrado-Gallego, O. Chertov, E. Menasalvas, A. Moreno, N. Swoboda, Steve Brewer","Use Cases and Applications",2020,"","","https://www.semanticscholar.org/paper/2809206246406130634445dc3efba7df430ec624","",199,"2025-02-06 14:32:15","","10.1007/978-3-030-51023-7_6","","",,,135,179,0,0.00,0,9,5,"","",""
0,"Tony Kuo, M. Inkelas, V. Manuel, R. Nianogo, D. Morrison, O. Arah","211 Using team science to support outbreak management in a large urban region during the COVID-19 pandemic",2022,"Journal of Clinical and Translational Science","","https://www.semanticscholar.org/paper/2152b40170ed648682aedd2fdc5bb92f58c9ae1a","",200,"2025-02-06 14:32:15","JournalArticle","10.1017/cts.2022.113","2059-8661","",6,,33,33,0,0.00,0,6,3,"OBJECTIVES/GOALS: To describe how the UCLA Clinical and Translational Science Institute (CTSI) assembled and deployed a science team in support of a local jurisdictions effort to manage and control COVID-19 outbreaks in one of the nations largest metropolitan regions, Los Angeles County (LAC). METHODS/STUDY POPULATION: During the COVID-19 pandemic (2020-21), building an efficient data infrastructure to support outbreak management became a priority for the local health department. In response, the UCLA CTSI assembled a science team with expertise across the translational continuum: epidemiology, laboratory and microbiology, machine learning, health policy, medicine and clinical care, and community engagement. The team partnered with a new LAC Data Science Team to foster a collaborative learning environment for scientists and public health personnel, employing improvement and implementation science to help mitigate COVID-19 outbreaks in sectors including healthcare, skilled nursing facilities, and K-12 education. The goal was a public health workforce that is prepared to problem-solve complex, evolving outbreaks. RESULTS/ANTICIPATED RESULTS: The science team created a learning environment with data modeling and visualization, problem-based learning, and active knowledge and skills acquisition. First, control charts and time series methods were used to visualize COVID-19 data and find signals for action. Second, a series of 16 Grand Rounds offered interactive sessions on problem-solving of outbreak challenges in different sectors. Third, a biweekly Public Health Digest provided fieldworkers with the latest scientific studies on COVID-19. All three elements guided and empowered the workforce to implement timelier, efficient outbreak mitigation strategies in the field. The partnered team also identified barriers to adoption of selected new data and management techniques, revealing areas for further skill-building and data-driven leadership. DISCUSSION/SIGNIFICANCE: The UCLA CTSI science team offered a backbone science infrastructure for helping public health and other sector agencies manage COVID-19 outbreaks and mitigation. It showed promise in bringing and translating science into public health practice. It revealed future priorities for CTSI innovation and scientific support of public agencies.","https://www.cambridge.org/core/services/aop-cambridge-core/content/view/CC66BBE5D20D630FA6EDDEBDB5A5E34B/S2059866122001133a.pdf/div-class-title-211-using-team-science-to-support-outbreak-management-in-a-large-urban-region-during-the-covid-19-pandemic-div.pdf",""
0,"A. Mindtree, Whitepaper April, A. M. Whitepaper","OVERCOMING PRACTICAL ENTERPRISE CHALLENGES FOR DEEP LEARNING",2020,"","","https://www.semanticscholar.org/paper/20e2fa00d226a34d87d88869e5eff23d117d7d89","",201,"2025-02-06 14:32:15","","","","",,,,,0,0.00,0,3,5,"We hear, see or experience AI and Machine Learning in our everyday life these days. Autonomous cars from Google, face or voice recognition to unlock your phone, or that amusing app that tells you if your friend is happy or sad when you click his or her picture. AI has been on the forefront of the technology revolution for the last half a decade. The recent developments in research and technology in this ﬁeld has given the necessary spark for enterprises to start applying AI and advanced machine-learning solutions. However, practical business problems that leading organizations are trying to solve with AI are a lot more complex than classifying an image as a cat or a dog, and with that complexity comes its own set of problems. Implementing a Deep Learning technology (de facto core of AI techniques) has many technical and functional requirements that are hard to meet when operating in the real world with businesses. In this paper, we explore the variety of challenges that a data science team can face while implementing an AI solution at the enterprise level and reveal some of the best practices to eﬃciently deliver and adopt AI solutions in an organization.","",""
0,"A. Churakova","Automating exploratory data analysis for use in predictive modeling (classification)",2017,"","","https://www.semanticscholar.org/paper/1e15dbaff3076f8fe4f3027854f361bf5da04d5a","",202,"2025-02-06 14:32:15","Review","10.18452/14293","","",,,,,0,0.00,0,1,8,"Fur diese Masterarbeit wurde ein Datenanalyse-Tool mit R entwickelt, um schnell und effizient ein erstes Verstandnis fur die Struktur und die Vorhersagekraft eines (beliebigen) Datensatzes gewinnen zu konnen. Dieses Tool wurde fur die SHS VIVEON AG, einen Business- und IT-Dienstleister fur Kundenmanagement, entwickelt und soll das Data Science-Team der Firma dabei unterstutzen, eine erste explorative Datenanalyse eines Kunden-Datensatzes durchzufuhren. Die wesentlichen Anspruche an die Software waren einerseits funktionale Vielseitigkeit (Visualisierung, Clustering, Klassifikationsverfahren, usw.) und andererseits eine intuitiven Benutzeroberflache. Folgende Punkte werden in dieser Arbeit besprochen: Zunachst werden die Bedurfnisse des Data Science-Teams wahrend der Einarbeitung in einen neuen Datensatz dargestellt. Anschliesend wird ein Uberblick uber die statistischen und analytischen Methoden im Umgang mit Daten in einem Unternehmenskontext gegeben und uber die einzelnen Schritte der Softwareentwicklung (einschlieslich der Anforderungen der SHS VIVEON AG und der Ergebnisse der Usability-Tests) berichtet. Abschliesend wird der Leser durch eine Beispielanalyse eines nicht-proprietaren Datensatzes gefuhrt. Zusammengefasst zeigt diese Masterarbeit den Hintergrund, das Design und die Implementierung der Software und erklart sowohl ihre technischen als auch ihre interaktiven Funktionen. Schlieslich beschreibt sie, wie die Benutzer die Software andern und verbessern konnen, wenn zukunftige weitere Anforderungen an die Software identifiziert werden sollten.%%%%A data analysis tool was developed using R in order to quickly and efficiently gain an initial understanding of the structure and predictive power of a dataset. This tool was developed for SHS VIVEON AG, a business and IT solution provider for customer management, and is meant to enable the firm’s Data Science team to perform initial exploratory data analysis of a client’s dataset. The two key drivers in the design of the software were versatility in the functions (visualization, clustering, classification, etc.) and an intuitive interface. This work will do the following: outline the needs of the firm’s Data Science team when faced with a new dataset, review the statistical and analytic methods for engaging with data in a business setting, recount the steps taken to create the tool in question (including the full considerations of SHS VIVEON AG and the results of usability testing), and take the reader through a step-by-step mock analysis of a non-proprietary dataset. Overall, the current work shows the background, design, and implementation of this software, explaining both its technical and interactive features. Finally, it points to ways that users can modify and improve upon the software if other requirements are identified in the future.","",""
0,"Maike Holtkemper, Christian Beecks","Empowering Data Science Teams: How Automation Frameworks Address Competency Gaps Across Project Lifecycles",2024,"2024 IEEE International Conference on Big Data (BigData)","","https://www.semanticscholar.org/paper/1b0d7a9f511d86c996641c1ffabfb284c161f8c7","",203,"2025-02-06 14:32:15","Conference","10.1109/BigData62323.2024.10825556","","",,,3134,3142,0,0.00,0,2,1,"In the fast-evolving field of data science, the combination of the right team competencies has a major impact on a successful project execution. These competencies, ranging from data acquisition to model deployment, are increasingly difficult to maintain due to widespread competency shortages. This puts data science projects at risk of delays, inefficiencies, and failure, as organizations struggle to find skilled professionals. Automation frameworks - software tools designed to automate repetitive or complex tasks - offer a solution to this challenge. While these frameworks provide benefits such as reducing manual labor and improving project efficiency, they have notable limitations, particularly in covering critical phases like business understanding and deployment. Additionally, training programs also struggle to fully address the competency gap due to time, cost and scalability constraints. This paper investigates how existing automation frameworks can fill these competency gaps within data science teams more effectively. Using the CRISP-DM model as an example of a structured process, this study first identifies tasks required in each phase. Then, it matches these tasks with relevant automation frameworks to assess the extent of automation possible. Finally, these tasks are mapped to the EDISON Data Science Competence Framework to highlight which competencies automation frameworks can address. The findings suggest that automation frameworks effectively bridge competency gaps, enabling teams to complete projects more efficiently and effectively where human expertise may be lacking. In this manner, our findings serve as a reference point for data scientists and practitioners alike.","",""
0,"R. David, C. Pizzigatti, Rorie Edmunds, D. Vellenich, Ana Heredia, Jeaneth Machicao, L. Mabile, Y. Murayama, M. O’Brien, Solange Santos, S. Stall, A. Specht, L. Wyborn","Challenges in data and software management and sharing at the global level: the case of the PARSEC project.",2020,"","","https://www.semanticscholar.org/paper/186272cfc7c5a198423684e41e8dc47224bc16a1","",204,"2025-02-06 14:32:15","","10.5281/ZENODO.4276640","","",,,,,0,0.00,0,13,5,"In the PARSEC project, our team of data science experts are partnering with our multi-country synthesis science research team to build relevant tools and processes for better data and software management that integrate into the research lifecycle and are to be shared with the wider research community. This poster articulates the technology challenges prompted by the many aspects of team diversity and physical location as well as the cultural challenges where we seek better understanding and embrace the value of different team dynamics, methods of communication, and preference to research approach.","https://hal.science/hal-03014752/document",""
0,"Nicolas Fiorini","Find Relevant Cases in All Cases: Your Journey at Doctrine",2019,"Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval","","https://www.semanticscholar.org/paper/149ada4e5b6f4abd236021008085c924d238f3b0","",205,"2025-02-06 14:32:15","Book","10.1145/3331184.3331441","","",,,,,0,0.00,0,1,6,"Domain-specific Information Retrieval (IR) is generally challenging because of the rare datasets or benchmarks, niche vocabularies and more limited literature coverage. Legal IR is no exception and presents other obstacles, reinforcing the need for innovation and, sometimes, paradigm shifts. Doctrine, one of the largest Legaltech companies in Europe, dedicates an entire data science team to advance on these problems and identify new opportunities. In this presentation, we provide some intuition regarding the specificities of legal IR (e.g., what is relevance?), and we introduce some of the solutions currently used on doctrine.fr. Particularly, we show how we use named entity recognition in the various forms of contents we host, and how it enhances the search engine. With knowledge extracted from documents, we may built large enough datasets and train learning-to-rank algorithms. This, combined with several specific-domain vocabulary enrichments to increase recall, dramatically improves the search experience for our users.","",""
0,"Shelley A. Rusincovitch, Ricardo Henao, M. Gao, L. Carin, Ursula A. Rogers, N. Neely, M. Schilder, D. Costello, E. Komives, Erich S. Huang","Rationale and Design for the Duke Connected Care Predictive Modeling Pilot with a Medicare Shared Savings Program Population",2017,"American Medical Informatics Association Annual Symposium","","https://www.semanticscholar.org/paper/11e95a95432fe72f18002e6105b94268e1e6f35f","",206,"2025-02-06 14:32:15","JournalArticle","","","",,,,,0,0.00,0,10,8,"In this abstract, we discuss the rationale and design for a machine learning pilot undertaken by Duke Connected Care, an ACO participating in the Medicare Shared Savings Program (MSSP), in conjunction with a data science team of informaticists and machine learning experts. The result of the pilot is expected to be twofold: (1) development of a clinically-informed and actionable predictive model that can be assessed for potential implementation within Duke Health, (2) synthesis of experiences arising from an ACO’s engagement and collaboration with machine learning expertise.","",""
0,"Alison L Gibbs","Reading to Write, Writing to Read, and the Development of Skills in Data Translation",2022,"Bridging the Gap: Empowering and Educating Today’s Learners in Statistics. Proceedings of the Eleventh International Conference on Teaching Statistics","","https://www.semanticscholar.org/paper/0facdef41ba8b9ba19cacc79e95111aec6958242","",207,"2025-02-06 14:32:15","Conference","10.52041/iase.icots11.t13b2","","",,,,,0,0.00,0,1,3,"There have been many discussions about the nature of data science and the training of data scientists. Common to these discussions is the recognized demand for data scientists who can communicate effectively to stakeholders. More recently, data translator has been identified as a needed role on data science teams for which it is difficult to find appropriately skilled people. Students in our undergraduate programs in statistics and data science typically enroll in these programs because of their interest and aptitude in mathematical and computational problem solving. How do we improve their communication skills to help fill the need for data translators? We describe ways we have integrated reading and writing in an undergraduate capstone course with the goal of developing the required skills.","",""
0,"","Gina Neff Discusses Interdisciplinary Data Science Teams",2019,"","","https://www.semanticscholar.org/paper/0360bfec7133c2b0467efb0ffdb9e0029724f9f8","",208,"2025-02-06 14:32:15","","10.4135/9781526494672","","",,,,,0,0.00,0,0,6,"","",""
